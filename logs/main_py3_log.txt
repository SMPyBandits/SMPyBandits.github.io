 - Setting dpi of all figures to 110 ...
 - Setting 'figsize' of all figures to (19.8, 10.8) ...
Info: Using the regular tqdm() decorator ...
Info: numba.jit seems to be available.
Info: numba.jit seems to be available.
Apparently, the arms have rewards in [0, 1] (lower = 0, amplitude = 1)
Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [{'params': {'horizon': 5000, 'unbiased': False, 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.CORRAL.CORRAL'>}, {'params': {'horizon': 5000, 'unbiased': False, 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.CORRAL.CORRAL'>}, {'params': {'update_like_exp4': True, 'update_all_children': True, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'update_like_exp4': False, 'update_all_children': True, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'update_like_exp4': True, 'update_all_children': False, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'update_like_exp4': False, 'update_all_children': False, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]

Sleeping for 0 seconds secondsbefore starting the simulation...
Done Sleeping for 0 seconds seconds... Now I can start the simulation...
====> TURNING DEBUG MODE ON <=====
plots/ is already a directory here...
Number of policies in this comparison: 12
Time horizon: 5000
Number of repetitions: 4
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'params': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'arm_type': <class 'Arms.Bernoulli.Bernoulli'>} ...
 - with 'arm_type' = <class 'Arms.Bernoulli.Bernoulli'>
 - with 'params' = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
 - with 'arms' = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]
 - with 'means' = [ 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9]
 - with 'nbArms' = 9
 - with 'maxArm' = 0.9
 - with 'minArm' = 0.1

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 7.52 ... 
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
 - with 'arms' represented as: $[B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)^*]$
Number of environments to try: 1


Evaluating environment: MAB(nbArms: 9, arms: [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)], minArm: 0.1, maxArm: 0.9)
- Adding policy #1 = {'params': {'horizon': 5000, 'unbiased': False, 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.CORRAL.CORRAL'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][0]' = {'params': {'horizon': 5000, 'unbiased': False, 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.CORRAL.CORRAL'>} ...
  Creating this child player from a dictionnary 'children[0]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[1]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...
- Adding policy #2 = {'params': {'horizon': 5000, 'unbiased': False, 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.CORRAL.CORRAL'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][1]' = {'params': {'horizon': 5000, 'unbiased': False, 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.CORRAL.CORRAL'>} ...
  Creating this child player from a dictionnary 'children[0]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[1]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...
- Adding policy #3 = {'params': {'update_like_exp4': True, 'update_all_children': True, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][2]' = {'params': {'update_like_exp4': True, 'update_all_children': True, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this child player from a dictionnary 'children[0]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[1]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...
- Adding policy #4 = {'params': {'update_like_exp4': False, 'update_all_children': True, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][3]' = {'params': {'update_like_exp4': False, 'update_all_children': True, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this child player from a dictionnary 'children[0]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[1]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...
- Adding policy #5 = {'params': {'update_like_exp4': True, 'update_all_children': False, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][4]' = {'params': {'update_like_exp4': True, 'update_all_children': False, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this child player from a dictionnary 'children[0]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[1]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...
- Adding policy #6 = {'params': {'update_like_exp4': False, 'update_all_children': False, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][5]' = {'params': {'update_like_exp4': False, 'update_all_children': False, 'unbiased': False, 'decreaseRate': 'auto', 'children': [{'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>}, {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>}, {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>}]}, 'archtype': <class 'Policies.Aggr.Aggr'>} ...
  Creating this child player from a dictionnary 'children[0]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this child player from a dictionnary 'children[1]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[2]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[3]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this child player from a dictionnary 'children[4]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this child player from a dictionnary 'children[5]' = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...
- Adding policy #7 = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][6]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.Thompson.Thompson'>} ...
- Adding policy #8 = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][7]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbBern>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
- Adding policy #9 = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][8]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <built-in function klucbExp>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
- Adding policy #10 = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][9]' = {'params': {'amplitude': 1, 'lower': 0, 'klucb': <function klucbGauss at 0x7fc6653b59d8>}, 'archtype': <class 'Policies.klUCBPlus.klUCBPlus'>} ...
- Adding policy #11 = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][10]' = {'params': {'amplitude': 1, 'lower': 0}, 'archtype': <class 'Policies.BayesUCB.BayesUCB'>} ...
- Adding policy #12 = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][11]' = {'params': {'horizon': 5500.0, 'alpha': 0.5}, 'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>} ...

===> Pre-computing the rewards ... Of shape (9, 4, 5000) ...
    In order for all simulated algorithms to face the same random rewards (robust comparison of A1,..,An vs Aggr(A1,..,An)) ...




- Evaluating policy #1/12: CORRAL($N=6$, $\gamma=0.0002$, $\beta=1.12$, $\rho=[12, 12, 12, 12, 12, 12]$, $\eta=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]$) ...

Estimated order by the policy CORRAL($N=6$, $\gamma=0.0002$, $\beta=1.12$, $\rho=[12, 12, 12, 12, 12, 12]$, $\eta=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]$) after 5000 steps: [6 4 5 3 0 2 7 1 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 35.80% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 16.52% (relative success)...
  ==> Spearman    distance from optimal ordering: 6.78% (relative success)...
  ==> Gestalt     distance from optimal ordering: 44.44% (relative success)...
  ==> Mean distance from optimal ordering: 25.89% (relative success)...



- Evaluating policy #2/12: CORRAL($N=6$, $\gamma=0.0002$, $\beta=1.12$, $\rho=[12, 12, 12, 12, 12, 12]$, $\eta=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]$) ...

Estimated order by the policy CORRAL($N=6$, $\gamma=0.0002$, $\beta=1.12$, $\rho=[12, 12, 12, 12, 12, 12]$, $\eta=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]$) after 5000 steps: [1 6 2 3 7 0 4 5 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 55.56% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 85.56% (relative success)...
  ==> Spearman    distance from optimal ordering: 75.60% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 70.85% (relative success)...



- Evaluating policy #3/12: Aggr($N=6$, Exp4, updateAll) ...

Estimated order by the policy Aggr($N=6$, Exp4, updateAll) after 5000 steps: [0 2 3 4 6 5 7 1 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 97.82% (relative success)...
  ==> Spearman    distance from optimal ordering: 93.29% (relative success)...
  ==> Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==> Mean distance from optimal ordering: 84.81% (relative success)...



- Evaluating policy #4/12: Aggr($N=6$, updateAll) ...

Estimated order by the policy Aggr($N=6$, updateAll) after 5000 steps: [2 3 0 1 4 6 5 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 75.31% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.33% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.63% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 85.23% (relative success)...



- Evaluating policy #5/12: Aggr($N=6$, Exp4) ...

Estimated order by the policy Aggr($N=6$, Exp4) after 5000 steps: [0 1 2 5 3 4 6 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 90.12% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.92% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.99% (relative success)...
  ==> Gestalt     distance from optimal ordering: 88.89% (relative success)...
  ==> Mean distance from optimal ordering: 94.73% (relative success)...



- Evaluating policy #6/12: Aggr($N=6$) ...

Estimated order by the policy Aggr($N=6$) after 5000 steps: [3 1 2 0 4 6 5 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.47% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 86.29% (relative success)...



- Evaluating policy #7/12: Thompson ...

Estimated order by the policy Thompson after 5000 steps: [0 6 4 3 2 1 5 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 65.43% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 85.56% (relative success)...
  ==> Spearman    distance from optimal ordering: 90.08% (relative success)...
  ==> Gestalt     distance from optimal ordering: 44.44% (relative success)...
  ==> Mean distance from optimal ordering: 71.38% (relative success)...



- Evaluating policy #8/12: KL-UCB+(Bern) ...

Estimated order by the policy KL-UCB+(Bern) after 5000 steps: [0 2 1 4 6 5 7 3 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 75.31% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.04% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 84.94% (relative success)...



- Evaluating policy #9/12: KL-UCB+(Exp) ...

Estimated order by the policy KL-UCB+(Exp) after 5000 steps: [0 1 6 5 2 4 7 3 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 65.43% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 93.94% (relative success)...
  ==> Spearman    distance from optimal ordering: 94.19% (relative success)...
  ==> Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==> Mean distance from optimal ordering: 77.28% (relative success)...



- Evaluating policy #10/12: KL-UCB+(Gauss) ...

Estimated order by the policy KL-UCB+(Gauss) after 5000 steps: [0 1 4 2 3 5 6 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 90.12% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 99.92% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.99% (relative success)...
  ==> Gestalt     distance from optimal ordering: 88.89% (relative success)...
  ==> Mean distance from optimal ordering: 94.73% (relative success)...



- Evaluating policy #11/12: BayesUCB ...

Estimated order by the policy BayesUCB after 5000 steps: [2 4 0 1 3 6 5 7 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==> Spearman    distance from optimal ordering: 99.04% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 83.71% (relative success)...



- Evaluating policy #12/12: ApproximatedFHGittins($\alpha=0.5$) ...

Estimated order by the policy ApproximatedFHGittins($\alpha=0.5$) after 5000 steps: [1 5 0 2 3 4 7 6 8] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==> Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==> Spearman    distance from optimal ordering: 98.75% (relative success)...
  ==> Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==> Mean distance from optimal ordering: 83.64% (relative success)...
Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'ApproximatedFHGittins($\alpha=0.5$)'	was ranked	1 / 12 for this simulation (last regret = 31.9).
- Policy 'BayesUCB'	was ranked	2 / 12 for this simulation (last regret = 40.15).
- Policy 'Aggr($N=6$, updateAll)'	was ranked	3 / 12 for this simulation (last regret = 40.4).
- Policy 'Aggr($N=6$)'	was ranked	4 / 12 for this simulation (last regret = 41.9).
- Policy 'Thompson'	was ranked	5 / 12 for this simulation (last regret = 44.65).
- Policy 'KL-UCB+(Bern)'	was ranked	6 / 12 for this simulation (last regret = 47.15).
- Policy 'Aggr($N=6$, Exp4, updateAll)'	was ranked	7 / 12 for this simulation (last regret = 58.15).
- Policy 'Aggr($N=6$, Exp4)'	was ranked	8 / 12 for this simulation (last regret = 68.65).
- Policy 'KL-UCB+(Gauss)'	was ranked	9 / 12 for this simulation (last regret = 72.9).
- Policy 'KL-UCB+(Exp)'	was ranked	10 / 12 for this simulation (last regret = 87.65).
- Policy 'CORRAL($N=6$, $\gamma=0.0002$, $\beta=1.12$, $\rho=[12, 12, 12, 12, 12, 12]$, $\eta=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]$)'	was ranked	11 / 12 for this simulation (last regret = 1965.9).
- Policy 'CORRAL($N=6$, $\gamma=0.0002$, $\beta=1.12$, $\rho=[12, 12, 12, 12, 12, 12]$, $\eta=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]$)'	was ranked	12 / 12 for this simulation (last regret = 1974.9).

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 7.52 for 1-player problem... 
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
