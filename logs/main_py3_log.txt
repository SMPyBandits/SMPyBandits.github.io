Apparently, the arms have rewards in [-1.0, 1.0] (lower = -1.0, amplitude = 2.0)
Loaded experiments configuration from 'configuration.py' :
configuration['policies'] = [{'archtype': <class 'Policies.UCBalpha.UCBalpha'>, 'params': {'alpha': 1, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {'posterior': <class 'Policies.Posterior.Gauss.Gauss'>, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {'klucb': <built-in function klucbBern>, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {'klucb': <function klucbGauss at 0x7f557556b6a8>, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>, 'params': {'horizon': 33.0, 'alpha': 1, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.SparseklUCB.SparseklUCB'>, 'params': {'sparsity': 3, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.SparseUCB.SparseUCB'>, 'params': {'alpha': 1, 'sparsity': 3, 'lower': -1.0, 'amplitude': 2.0}}, {'archtype': <class 'Policies.OSSB.OSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0}}, {'archtype': <class 'Policies.OSSB.GaussianOSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0, 'variance': 0.1}}, {'archtype': <class 'Policies.OSSB.SparseOSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0, 'sparsity': 3}}]
====> TURNING DEBUG MODE ON <=====
plots/ is already a directory here...
Number of policies in this comparison: 12
Time horizon: 30
Number of repetitions: 1
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 1


Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary 'configuration' = {'arm_type': <class 'Arms.Gaussian.Gaussian'>, 'params': [(0.8, 0.1, -1.0, 1.0), (-0.8, 0.1, -1.0, 1.0), (-0.4181818181818181, 0.1, -1.0, 1.0), (-0.19999999999999996, 0.1, -1.0, 1.0), (0.2, 0.1, -1.0, 1.0), (-0.5818181818181818, 0.1, -1.0, 1.0), (-0.36363636363636354, 0.1, -1.0, 1.0), (-0.5272727272727272, 0.1, -1.0, 1.0), (-0.6363636363636364, 0.1, -1.0, 1.0), (-0.7454545454545454, 0.1, -1.0, 1.0), (-0.6909090909090909, 0.1, -1.0, 1.0), (0.5, 0.1, -1.0, 1.0), (-0.2545454545454544, 0.1, -1.0, 1.0), (-0.47272727272727266, 0.1, -1.0, 1.0), (-0.30909090909090897, 0.1, -1.0, 1.0)]} ...
 - with 'arm_type' = <class 'Arms.Gaussian.Gaussian'>
 - with 'params' = [(0.8, 0.1, -1.0, 1.0), (-0.8, 0.1, -1.0, 1.0), (-0.4181818181818181, 0.1, -1.0, 1.0), (-0.19999999999999996, 0.1, -1.0, 1.0), (0.2, 0.1, -1.0, 1.0), (-0.5818181818181818, 0.1, -1.0, 1.0), (-0.36363636363636354, 0.1, -1.0, 1.0), (-0.5272727272727272, 0.1, -1.0, 1.0), (-0.6363636363636364, 0.1, -1.0, 1.0), (-0.7454545454545454, 0.1, -1.0, 1.0), (-0.6909090909090909, 0.1, -1.0, 1.0), (0.5, 0.1, -1.0, 1.0), (-0.2545454545454544, 0.1, -1.0, 1.0), (-0.47272727272727266, 0.1, -1.0, 1.0), (-0.30909090909090897, 0.1, -1.0, 1.0)]
 - with 'arms' = [N(0.8, 0.1), N(-0.8, 0.1), N(-0.418, 0.1), N(-0.2, 0.1), N(0.2, 0.1), N(-0.582, 0.1), N(-0.364, 0.1), N(-0.527, 0.1), N(-0.636, 0.1), N(-0.745, 0.1), N(-0.691, 0.1), N(0.5, 0.1), N(-0.255, 0.1), N(-0.473, 0.1), N(-0.309, 0.1)]
 - with 'means' = [ 0.8        -0.8        -0.41818182 -0.2         0.2        -0.58181818
 -0.36363636 -0.52727273 -0.63636364 -0.74545455 -0.69090909  0.5
 -0.25454545 -0.47272727 -0.30909091]
 - with 'nbArms' = 15
 - with 'maxArm' = 0.8
 - with 'minArm' = -0.8

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 2.89 ... 
 - a Optimal Arm Identification factor H_OI(mu) = -16.67% ...
 - with 'arms' represented as: $[N(0.8)^*, N(-0.8), N(-0.418), N(-0.2), N(0.2), N(-0.582), N(-0.364), N(-0.527), N(-0.636),$
$N(-0.745), N(-0.691), N(0.5), N(-0.255), N(-0.473), N(-0.309)], \sigma^2=0.1$
Number of environments to try: 1


Evaluating environment: MAB(nbArms: 15, arms: [N(0.8, 0.1), N(-0.8, 0.1), N(-0.418, 0.1), N(-0.2, 0.1), N(0.2, 0.1), N(-0.582, 0.1), N(-0.364, 0.1), N(-0.527, 0.1), N(-0.636, 0.1), N(-0.745, 0.1), N(-0.691, 0.1), N(0.5, 0.1), N(-0.255, 0.1), N(-0.473, 0.1), N(-0.309, 0.1)], minArm: -0.8, maxArm: 0.8)
- Adding policy #1 = {'archtype': <class 'Policies.UCBalpha.UCBalpha'>, 'params': {'alpha': 1, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][0]' = {'archtype': <class 'Policies.UCBalpha.UCBalpha'>, 'params': {'alpha': 1, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #2 = {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][1]' = {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #3 = {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {'posterior': <class 'Policies.Posterior.Gauss.Gauss'>, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][2]' = {'archtype': <class 'Policies.Thompson.Thompson'>, 'params': {'posterior': <class 'Policies.Posterior.Gauss.Gauss'>, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #4 = {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {'klucb': <built-in function klucbBern>, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][3]' = {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {'klucb': <built-in function klucbBern>, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #5 = {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {'klucb': <function klucbGauss at 0x7f557556b6a8>, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][4]' = {'archtype': <class 'Policies.klUCB.klUCB'>, 'params': {'klucb': <function klucbGauss at 0x7f557556b6a8>, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #6 = {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][5]' = {'archtype': <class 'Policies.BayesUCB.BayesUCB'>, 'params': {'posterior': <class 'Policies.Posterior.Beta.Beta'>, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #7 = {'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>, 'params': {'horizon': 33.0, 'alpha': 1, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][6]' = {'archtype': <class 'Policies.ApproximatedFHGittins.ApproximatedFHGittins'>, 'params': {'horizon': 33.0, 'alpha': 1, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #8 = {'archtype': <class 'Policies.SparseklUCB.SparseklUCB'>, 'params': {'sparsity': 3, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][7]' = {'archtype': <class 'Policies.SparseklUCB.SparseklUCB'>, 'params': {'sparsity': 3, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #9 = {'archtype': <class 'Policies.SparseUCB.SparseUCB'>, 'params': {'alpha': 1, 'sparsity': 3, 'lower': -1.0, 'amplitude': 2.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][8]' = {'archtype': <class 'Policies.SparseUCB.SparseUCB'>, 'params': {'alpha': 1, 'sparsity': 3, 'lower': -1.0, 'amplitude': 2.0}} ...
- Adding policy #10 = {'archtype': <class 'Policies.OSSB.OSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][9]' = {'archtype': <class 'Policies.OSSB.OSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0}} ...
- Adding policy #11 = {'archtype': <class 'Policies.OSSB.GaussianOSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0, 'variance': 0.1}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][10]' = {'archtype': <class 'Policies.OSSB.GaussianOSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0, 'variance': 0.1}} ...
- Adding policy #12 = {'archtype': <class 'Policies.OSSB.SparseOSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0, 'sparsity': 3}} ...
  Creating this policy from a dictionnary 'self.cfg['policies'][11]' = {'archtype': <class 'Policies.OSSB.SparseOSSB'>, 'params': {'epsilon': 0.0, 'gamma': 0.0, 'sparsity': 3}} ...



- Evaluating policy #1/12: UCB($\alpha=1$) ...

Estimated order by the policy UCB($\alpha=1$) after 30 steps: [ 5 13  2 14 12  6  7  3  9  1  8  0  4 10 11] ...
  ==> Optimal arm identification: 62.50% (relative success)...
  ==> Manhattan   distance from optimal ordering: 30.67% (relative success)...
  ==> Gestalt     distance from optimal ordering: 40.00% (relative success)...
  ==> Mean distance from optimal ordering: 35.33% (relative success)...



- Evaluating policy #2/12: Thompson ...

Estimated order by the policy Thompson after 30 steps: [ 6 13  1 14 11 10  2  9  5  4 12  8  3  7  0] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 20.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 20.00% (relative success)...
  ==> Mean distance from optimal ordering: 20.00% (relative success)...



- Evaluating policy #3/12: Thompson(Gauss) ...

Estimated order by the policy Thompson(Gauss) after 30 steps: [14  3 10  2 13  8 11  7  1  0  4 12  6  9  5] ...
  ==> Optimal arm identification: -72.73% (relative success)...
  ==> Manhattan   distance from optimal ordering: 25.33% (relative success)...
  ==> Gestalt     distance from optimal ordering: 6.67% (relative success)...
  ==> Mean distance from optimal ordering: 16.00% (relative success)...



- Evaluating policy #4/12: kl-UCB ...

Estimated order by the policy kl-UCB after 30 steps: [14  5 10  8  1  9 13  4  2 11  7  3  6 12  0] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 21.78% (relative success)...
  ==> Gestalt     distance from optimal ordering: 6.67% (relative success)...
  ==> Mean distance from optimal ordering: 14.22% (relative success)...



- Evaluating policy #5/12: kl-UCB(Gauss) ...

Estimated order by the policy kl-UCB(Gauss) after 30 steps: [ 5  7 14  2  6  3 12  1  9  4 13 11  0  8 10] ...
  ==> Optimal arm identification: -86.36% (relative success)...
  ==> Manhattan   distance from optimal ordering: 37.78% (relative success)...
  ==> Gestalt     distance from optimal ordering: 20.00% (relative success)...
  ==> Mean distance from optimal ordering: 28.89% (relative success)...



- Evaluating policy #6/12: BayesUCB ...

Estimated order by the policy BayesUCB after 30 steps: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14  0] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 75.11% (relative success)...
  ==> Gestalt     distance from optimal ordering: 93.33% (relative success)...
  ==> Mean distance from optimal ordering: 84.22% (relative success)...



- Evaluating policy #7/12: ApprFHG($T=33$, $\alpha=1$) ...

Estimated order by the policy ApprFHG($T=33$, $\alpha=1$) after 30 steps: [ 9  1  5 13  2 14  7  6  3 12 11  4 10  0  8] ...
  ==> Optimal arm identification: -79.55% (relative success)...
  ==> Manhattan   distance from optimal ordering: 36.00% (relative success)...
  ==> Gestalt     distance from optimal ordering: 20.00% (relative success)...
  ==> Mean distance from optimal ordering: 28.00% (relative success)...



- Evaluating policy #8/12: Sparse-kl-UCB($s=3$, Bern) ...

Estimated order by the policy Sparse-kl-UCB($s=3$, Bern) after 30 steps: [ 1  9 10  8  5  7  6  2  4 13 14  0 12 11  3] ...
  ==> Optimal arm identification: -25.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 41.33% (relative success)...
  ==> Gestalt     distance from optimal ordering: 33.33% (relative success)...
  ==> Mean distance from optimal ordering: 37.33% (relative success)...



- Evaluating policy #9/12: SparseUCB($s=3$, $\alpha=1$) ...

Estimated order by the policy SparseUCB($s=3$, $\alpha=1$) after 30 steps: [ 9  1  5  8 13  7 14  2  6  3 12 11 10  4  0] ...
  ==> Optimal arm identification: 100.00% (relative success)...
  ==> Manhattan   distance from optimal ordering: 32.44% (relative success)...
  ==> Gestalt     distance from optimal ordering: 20.00% (relative success)...
  ==> Mean distance from optimal ordering: 26.22% (relative success)...



- Evaluating policy #10/12: OSSB($\varepsilon=0$, $\gamma=0$, Bernoulli) ...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
Using ratio of pulls / values_c_x_mt = [0.         2.23750405 2.23750405 2.23750405 1.6615211  2.23750405
 2.23750405 2.23750405 2.23750405 2.23750405 2.23750405 0.617628
 2.23750405 2.23750405 2.23750405], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 15 : choice = 0 ...
Using ratio of pulls / values_c_x_mt = [0.         1.90373359 1.90373359 1.90373359 1.36941564 1.90373359
 1.90373359 1.90373359 1.90373359 1.90373359 1.90373359 0.45190992
 1.90373359 1.90373359 1.90373359], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 16 : choice = 13 ...
Using ratio of pulls / values_c_x_mt = [0.         1.6652846  1.6652846  1.6652846  1.16222071 1.6652846
 1.6652846  1.6652846  1.6652846  1.6652846  1.6652846  0.33952162
 1.6652846  1.6652846  1.6652846 ], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 17 : choice = 10 ...
Using ratio of pulls / values_c_x_mt = [0.         1.47162221 1.47162221 1.47162221 0.99523918 1.47162221
 1.47162221 1.47162221 1.47162221 1.47162221 1.47162221 0.25347431
 1.47162221 1.47162221 1.47162221], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 18 : choice = 1 ...
Using ratio of pulls / values_c_x_mt = [0.         1.47508481 1.47508481 1.47508481 0.99821218 1.47508481
 1.47508481 1.47508481 1.47508481 1.47508481 1.47508481 0.25496215
 1.47508481 1.47508481 1.47508481], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 19 : choice = 14 ...
Using ratio of pulls / values_c_x_mt = [0.         1.49111473 1.49111473 1.49111473 1.01198203 1.49111473
 1.49111473 1.49111473 1.49111473 1.49111473 1.49111473 0.26187627
 1.49111473 1.49111473 1.49111473], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 20 : choice = 3 ...
Using ratio of pulls / values_c_x_mt = [0.         1.49893611 1.49893611 1.49893611 1.01870449 1.49893611
 1.49893611 1.49893611 1.49893611 1.49893611 1.49893611 0.26526527
 1.49893611 1.49893611 1.49893611], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 21 : choice = 12 ...
Using ratio of pulls / values_c_x_mt = [0.         1.43208249 1.43208249 1.43208249 0.96132677 1.43208249
 1.43208249 1.43208249 1.43208249 1.43208249 1.43208249 0.2366319
 1.43208249 1.43208249 1.43208249], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 22 : choice = 6 ...
Using ratio of pulls / values_c_x_mt = [0.         1.42778097 1.42778097 1.42778097 0.9576416  1.42778097
 1.42778097 1.42778097 1.42778097 1.42778097 1.42778097 0.23481638
 1.42778097 1.42778097 1.42778097], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 23 : choice = 9 ...
Using ratio of pulls / values_c_x_mt = [0.         1.42677817 1.42677817 1.42677817 0.95678261 1.42677817
 1.42677817 1.42677817 1.42677817 1.42677817 1.42677817 0.23439362
 1.42677817 1.42677817 1.42677817], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 24 : choice = 2 ...
Using ratio of pulls / values_c_x_mt = [0.         1.38630925 1.38630925 1.38630925 0.92215606 1.38630925
 1.38630925 1.38630925 1.38630925 1.38630925 1.38630925 0.21748942
 1.38630925 1.38630925 1.38630925], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 25 : choice = 10 ...
Using ratio of pulls / values_c_x_mt = [0.         1.39908285 1.39908285 1.39908285 0.93307725 1.39908285
 1.39908285 1.39908285 1.39908285 1.39908285 1.39908285 0.2227915
 1.39908285 1.39908285 1.39908285], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 26 : choice = 5 ...
Using ratio of pulls / values_c_x_mt = [0.         1.40025994 1.40025994 1.40025994 0.93408403 1.40025994
 1.40025994 1.40025994 1.40025994 1.40025994 1.40025994 0.22328167
 1.40025994 1.40025994 1.40025994], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 27 : choice = 7 ...
Using ratio of pulls / values_c_x_mt = [0.         1.4139598  1.4139598  1.4139598  0.94580652 1.4139598
 1.4139598  1.4139598  1.4139598  1.4139598  1.4139598  0.22900593
 1.4139598  1.4139598  1.4139598 ], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 28 : choice = 10 ...
Using ratio of pulls / values_c_x_mt = [0.         1.45963082 1.45963082 1.45963082 0.98494725 1.45963082
 1.45963082 1.45963082 1.45963082 1.45963082 1.45963082 0.24833757
 1.45963082 1.45963082 1.45963082], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 29 : choice = 9 ...

Estimated order by the policy OSSB($\varepsilon=0$, $\gamma=0$, Bernoulli) after 30 steps: [ 7 11  4  1  0 14 10  5  3  9  6  2 12  8 13] ...
  ==> Optimal arm identification: -59.09% (relative success)...
  ==> Manhattan   distance from optimal ordering: 43.11% (relative success)...
  ==> Gestalt     distance from optimal ordering: 20.00% (relative success)...
  ==> Mean distance from optimal ordering: 31.56% (relative success)...



- Evaluating policy #11/12: OSSB($\varepsilon=0$, $\gamma=0$, Gaussian) ...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
Using ratio of pulls / values_c_x_mt = [ 0.         12.85407063  5.75251201  4.73051736  1.16688877 10.36104942
  7.57340889  7.0230217  10.3120365  15.83706171 13.30958625  0.38202887
  5.70669966  6.25212306  6.43214829], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 15 : choice = 7 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.35893259  5.4228877   4.43205739  1.0211026   9.91700942
  7.19447941  6.65830102  9.86905952 15.28693133 12.80566596  0.30069298
  5.37840992  5.9082759   6.08331635], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 16 : choice = 5 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.97850887  5.83585701  4.80612497  1.20459102 10.4728012
  7.66899523  7.11508033 10.42352435 15.97515328 13.43620491  0.4037296
  5.78971332  6.33899927  6.52026211], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 17 : choice = 1 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.86222504  5.75796751  4.73546469  1.16934657 10.36837061
  7.57966837  7.0290495  10.31934036 15.84611284 13.31788386  0.38343573
  5.7121334   6.25781048  6.437917  ], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 18 : choice = 13 ...
Using ratio of pulls / values_c_x_mt = [ 0.         13.09522452  5.91420833  4.87725272  1.2403306  10.57767286
  7.75877496  7.20156661 10.52814962 16.10461558 13.55495619  0.42453028
  5.8677553   6.42064729  6.60306555], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 19 : choice = 5 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.91118854  5.79074329  4.7651925   1.18414245 10.41233658
  7.61726634  7.0652578  10.36320235 15.90045475 13.36770629  0.39192818
  5.74477865  6.2919773   6.47257134], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 20 : choice = 2 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.55187553  5.55094668  4.54789946  1.07709418 10.08992113
  7.34186678  6.80011832 10.04155451 15.50143211 13.00205167  0.33141904
  5.50594573  6.04191046  6.21890502], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 21 : choice = 14 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.56892709  5.56228811  4.55816574  1.08209328 10.10520984
  7.35490921  6.81267056 10.05680654 15.52038089 13.01940622  0.33419465
  5.51724111  6.05374257  6.2309091 ], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 22 : choice = 9 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.57494526  5.56629187  4.56179021  1.08385962 10.11060611
  7.35951305  6.81710146 10.06218988 15.52706835 13.02553128  0.33517658
  5.52122863  6.05791943  6.23514663], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 23 : choice = 7 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.58512904  5.57306802  4.56792474  1.08685087 10.11973787
  7.3673043   6.82460018 10.07129975 15.53838432 13.03589586  0.33684092
  5.52797731  6.0649884   6.24231823], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 24 : choice = 8 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.72915769  5.6690496   4.65485961  1.12946599 10.24893324
  7.47759871  6.93076991 10.20018654 15.69837672 13.18247391  0.36074673
  5.62357147  6.16509874  6.3438756 ], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 25 : choice = 3 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.60681165  5.58749993  4.58099143  1.09322934 10.13918202
  7.38389614  6.84056957 10.09069733 15.56247599 13.0579632   0.340396
  5.54235075  6.08004338  6.25759157], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 26 : choice = 13 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.67105258  5.63029512  4.61974863  1.11220448 10.19680213
  7.43307983  6.88791222 10.14817971 15.63384232 13.12334205  0.35102027
  5.58497302  6.12468143  6.30287551], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 27 : choice = 12 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.68674129  5.64075468  4.62922361  1.11685598 10.21087649
  7.44509712  6.89948061 10.16222048 15.65126843 13.13930823  0.35363556
  5.59539043  6.13559035  6.31394191], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 28 : choice = 7 ...
Using ratio of pulls / values_c_x_mt = [ 0.         12.73744749  5.67458227  4.65987314  1.13193627 10.25637186
  7.48395271  6.93688722 10.20760745 15.7075826  13.19091001  0.3621434
  5.62908191  6.17086834  6.34972824], and least probable arm(s) are 0...
[exploration phase] Choosing the arm the least probable at time t = 29 : choice = 4 ...

Estimated order by the policy OSSB($\varepsilon=0$, $\gamma=0$, Gaussian) after 30 steps: [ 3 10  0  5  8  2  6  9  1 13  4 11 14  7 12] ...
  ==> Optimal arm identification: -31.82% (relative success)...
  ==> Manhattan   distance from optimal ordering: 53.78% (relative success)...
  ==> Gestalt     distance from optimal ordering: 26.67% (relative success)...
  ==> Mean distance from optimal ordering: 40.22% (relative success)...



- Evaluating policy #12/12: OSSB($\varepsilon=0$, $\gamma=0$, sparse Gaussian) ...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...
[initial phase] force exploration of an arm that was never pulled...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3 14  2  6  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.36125379
 -0.37955388 -0.39073925 -0.49752676 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.12815705
 1.14645714 1.15764251 1.26443002 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.09615945
 7.46785796 0.13522267 0.13391612 0.10041232 0.12260623 0.11174746
 0.13741615 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016 10.39939379
  0.13390721  7.39520965  7.46736077  9.95893704  8.15619248  8.94874957
  7.2771651   8.63849193  0.33528322], and least probable arm(s) are 6...
[exploration phase] Choosing the arm the least probable at time t = 15 : choice = 11 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3  6 14  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.33295298
 -0.36125379 -0.37955388 -0.49752676 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09985624
 1.12815705 1.14645714 1.26443002 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.13741615
 0.09615945 7.46785796 0.13522267 0.10041232 0.12260623 0.11174746
 0.14095205 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016  7.2771651
 20.79878757  0.13390721  7.39520965  9.95893704  8.15619248  8.94874957
  7.09461105  8.63849193  0.33528322], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 16 : choice = 8 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3  6 14  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.33295298
 -0.36125379 -0.37955388 -0.57005138 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09985624
 1.12815705 1.14645714 1.33695464 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.13741615
 0.09615945 7.46785796 0.13522267 0.10041232 0.11595531 0.11174746
 0.14095205 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016  7.2771651
 20.79878757  0.26781441  7.39520965  9.95893704  8.62401177  8.94874957
  7.09461105  8.63849193  0.33528322], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 17 : choice = 11 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3  6 14  2 13  7  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.33295298
 -0.36125379 -0.37955388 -0.5722962  -0.57359618 -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09985624
 1.12815705 1.14645714 1.33919946 1.34049944 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.13741615
 0.09615945 7.46785796 0.10041232 0.13522267 0.11576095 0.11174746
 0.14095205 0.11564868 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016  7.2771651
 20.79878757  0.40172162  9.95893704  7.39520965  8.63849193  8.94874957
  7.09461105  8.64687742  0.33528322], and least probable arm(s) are 14...
[exploration phase] Choosing the arm the least probable at time t = 18 : choice = 10 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3  6 14  2 13  7  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.33295298
 -0.34684652 -0.37955388 -0.5722962  -0.57359618 -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09985624
 1.11374978 1.14645714 1.33919946 1.34049944 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.13919374
 0.09615945 7.46785796 0.10041232 0.13522267 0.11576095 0.11174746
 0.14095205 0.11564868 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016  7.18423115
 20.79878757  0.40172162  9.95893704  7.39520965  8.63849193  8.94874957
  7.09461105  8.64687742  0.67056644], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 19 : choice = 8 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3  6 14  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.33295298
 -0.34684652 -0.37955388 -0.50512573 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09985624
 1.11374978 1.14645714 1.27202899 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.13919374
 0.09615945 7.46785796 0.13522267 0.10041232 0.12187379 0.11174746
 0.14095205 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016  7.18423115
 20.79878757  0.53562883  7.39520965  9.95893704  8.2052095   8.94874957
  7.09461105  8.63849193  0.67056644], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 20 : choice = 4 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3  6 14  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.33295298
 -0.34684652 -0.37955388 -0.48827977 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09985624
 1.11374978 1.14645714 1.25518303 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.13919374
 0.09615945 7.46785796 0.13522267 0.10041232 0.12350947 0.11174746
 0.14095205 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016  7.18423115
 20.79878757  0.66953603  7.39520965  9.95893704  8.09654487  8.94874957
  7.09461105  8.63849193  0.67056644], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 21 : choice = 13 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3  6 14  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.33295298
 -0.34684652 -0.37955388 -0.50919155 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09985624
 1.11374978 1.14645714 1.27609481 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.13919374
 0.09615945 7.46785796 0.13522267 0.10041232 0.12148548 0.11174746
 0.14095205 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016  7.18423115
 20.79878757  0.80344324  7.39520965  9.95893704  8.23143606  8.94874957
  7.09461105  8.63849193  0.67056644], and least probable arm(s) are 14...
[exploration phase] Choosing the arm the least probable at time t = 22 : choice = 5 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3 14  6  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.3244055
 -0.33295298 -0.37955388 -0.50919155 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09130876
 1.09985624 1.14645714 1.27609481 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.09615945
 0.14095205 7.46785796 0.13522267 0.10041232 0.12148548 0.11174746
 0.14205604 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016 10.39939379
 14.1892221   0.80344324  7.39520965  9.95893704  8.23143606  8.94874957
  7.03947562  8.63849193  1.00584965], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 23 : choice = 8 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3 14  6  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.3244055
 -0.33295298 -0.37955388 -0.47754817 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09130876
 1.09985624 1.14645714 1.24445143 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.09615945
 0.14095205 7.46785796 0.13522267 0.10041232 0.12457457 0.11174746
 0.14205604 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016 10.39939379
 14.1892221   0.93735045  7.39520965  9.95893704  8.02732081  8.94874957
  7.03947562  8.63849193  1.00584965], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 24 : choice = 12 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12  3 14  6  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.32274729 -0.3244055
 -0.33295298 -0.37955388 -0.48134183 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.08965055 1.09130876
 1.09985624 1.14645714 1.24824509 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14227221 0.10540039 0.18781388 0.09615945
 0.14095205 7.46785796 0.13522267 0.10041232 0.12419596 0.11174746
 0.14205604 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  7.02877931  9.48763099  5.32442016 10.39939379
 14.1892221   1.07125765  7.39520965  9.95893704  8.05179173  8.94874957
  7.03947562  8.63849193  1.00584965], and least probable arm(s) are 14...
[exploration phase] Choosing the arm the least probable at time t = 25 : choice = 8 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12 14  3  6  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.3018968  -0.32274729
 -0.33295298 -0.37955388 -0.48134183 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.06880006 1.08965055
 1.09985624 1.14645714 1.24824509 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14504771 0.10540039 0.09615945 0.18781388
 0.14095205 7.46785796 0.13522267 0.10041232 0.12419596 0.11174746
 0.14227221 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  6.89428349  9.48763099 10.39939379  5.32442016
 14.1892221   1.07125765  7.39520965  9.95893704  8.05179173  8.94874957
  7.02877931  8.63849193  1.34113287], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 26 : choice = 3 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12 14  3  6  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.3018968  -0.32274729
 -0.33295298 -0.37955388 -0.47960815 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.06880006 1.08965055
 1.09985624 1.14645714 1.24651141 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14504771 0.10540039 0.09615945 0.18781388
 0.14095205 7.46785796 0.13522267 0.10041232 0.12436869 0.11174746
 0.14227221 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  6.89428349  9.48763099 10.39939379  5.32442016
 14.1892221   1.20516486  7.39520965  9.95893704  8.04060867  8.94874957
  7.02877931  8.63849193  1.34113287], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 27 : choice = 2 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12 14  3  6  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.3018968  -0.32274729
 -0.33295298 -0.37955388 -0.46926568 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.06880006 1.08965055
 1.09985624 1.14645714 1.23616894 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14504771 0.10540039 0.09615945 0.18781388
 0.14095205 7.46785796 0.13522267 0.10041232 0.12540923 0.11174746
 0.14227221 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  6.89428349  9.48763099 10.39939379  5.32442016
 14.1892221   1.33907207  7.39520965  9.95893704  7.97389466  8.94874957
  7.02877931  8.63849193  1.34113287], and least probable arm(s) are 7...
[exploration phase] Choosing the arm the least probable at time t = 28 : choice = 3 ...

    We have d = 15 sparsity = 3 permutation = [ 0 11  4 12 14  3  6  2  7 13  8 10  5  9  1]
    and sorted_thetas = [ 0.76690326  0.35746265  0.14991302 -0.05852561 -0.3018968  -0.32274729
 -0.33295298 -0.37955388 -0.46711249 -0.5722962  -0.62039451 -0.63617557
 -0.70393568 -0.77700084 -0.84528352] with best_theta = 0.7669032599301479
    gaps = [0.         0.40944061 0.61699024 0.82542887 1.06880006 1.08965055
 1.09985624 1.14645714 1.23401575 1.33919946 1.38729777 1.40307883
 1.47083894 1.5439041  1.61218678]
       for k = 1 strong_sparsity(k) = -15.010544994797634
Warning: we only have weak sparsity! With d = 15 arms and s = 3, µ1 = 0.7669032599301479, and (d-s)/µ1 - sum(Delta_i/µi², i=k=1...s) = -15 < 0...
So we have ci = [0.         0.11049058 0.14504771 0.10540039 0.09615945 0.18781388
 0.14095205 7.46785796 0.13522267 0.10041232 0.12562805 0.11174746
 0.14227221 0.11576095 2.98255309]
Using ratio of pulls / values_c_x_mt = [        inf  9.05054514  6.89428349  9.48763099 10.39939379  5.32442016
 14.1892221   1.47297927  7.39520965  9.95893704  7.96000553  8.94874957
  7.02877931  8.63849193  1.34113287], and least probable arm(s) are 14...
[exploration phase] Choosing the arm the least probable at time t = 29 : choice = 10 ...

Estimated order by the policy OSSB($\varepsilon=0$, $\gamma=0$, sparse Gaussian) after 30 steps: [ 3 10  2  7 13  0  4 14  1  5 12  8  9  6 11] ...
  ==> Optimal arm identification: 62.50% (relative success)...
  ==> Manhattan   distance from optimal ordering: 39.56% (relative success)...
  ==> Gestalt     distance from optimal ordering: 33.33% (relative success)...
  ==> Mean distance from optimal ordering: 36.44% (relative success)...


Giving the vector of final regrets ...

  For policy #0 called 'UCB($\alpha=1$)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 27.2
Mean of   last regrets R_T = 27.2
Median of last regrets R_T = 27.2
Max of    last regrets R_T = 27.2
STD of    last regrets R_T = 0

  For policy #1 called 'Thompson' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 29.5
Mean of   last regrets R_T = 29.5
Median of last regrets R_T = 29.5
Max of    last regrets R_T = 29.5
STD of    last regrets R_T = 0

  For policy #2 called 'Thompson(Gauss)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 35.3
Mean of   last regrets R_T = 35.3
Median of last regrets R_T = 35.3
Max of    last regrets R_T = 35.3
STD of    last regrets R_T = 0

  For policy #3 called 'kl-UCB' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 19.1
Mean of   last regrets R_T = 19.1
Median of last regrets R_T = 19.1
Max of    last regrets R_T = 19.1
STD of    last regrets R_T = 0

  For policy #4 called 'kl-UCB(Gauss)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 26.6
Mean of   last regrets R_T = 26.6
Median of last regrets R_T = 26.6
Max of    last regrets R_T = 26.6
STD of    last regrets R_T = 0

  For policy #5 called 'BayesUCB' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 0
Mean of   last regrets R_T = 0
Median of last regrets R_T = 0
Max of    last regrets R_T = 0
STD of    last regrets R_T = 0

  For policy #6 called 'ApprFHG($T=33$, $\alpha=1$)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 30.4
Mean of   last regrets R_T = 30.4
Median of last regrets R_T = 30.4
Max of    last regrets R_T = 30.4
STD of    last regrets R_T = 0

  For policy #7 called 'Sparse-kl-UCB($s=3$, Bern)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 17.7
Mean of   last regrets R_T = 17.7
Median of last regrets R_T = 17.7
Max of    last regrets R_T = 17.7
STD of    last regrets R_T = 0

  For policy #8 called 'SparseUCB($s=3$, $\alpha=1$)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 32.1
Mean of   last regrets R_T = 32.1
Median of last regrets R_T = 32.1
Max of    last regrets R_T = 32.1
STD of    last regrets R_T = 0

  For policy #9 called 'OSSB($\varepsilon=0$, $\gamma=0$, Bernoulli)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 16.5
Mean of   last regrets R_T = 16.5
Median of last regrets R_T = 16.5
Max of    last regrets R_T = 16.5
STD of    last regrets R_T = 0

  For policy #10 called 'OSSB($\varepsilon=0$, $\gamma=0$, Gaussian)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 16.5
Mean of   last regrets R_T = 16.5
Median of last regrets R_T = 16.5
Max of    last regrets R_T = 16.5
STD of    last regrets R_T = 0

  For policy #11 called 'OSSB($\varepsilon=0$, $\gamma=0$, sparse Gaussian)' ...
  Last regrets vector (for all repetitions) is:
Shape of  last regrets R_T = (1,)
Min of    last regrets R_T = 35.4
Mean of   last regrets R_T = 35.4
Median of last regrets R_T = 35.4
Max of    last regrets R_T = 35.4
STD of    last regrets R_T = 0


Giving the final ranks ...

Final ranking for this environment #0 :
- Policy 'BayesUCB'	was ranked	1 / 12 for this simulation (last regret = 0).
- Policy 'Sparse-kl-UCB($s=3$, Bern)'	was ranked	2 / 12 for this simulation (last regret = 0).
- Policy 'SparseUCB($s=3$, $\alpha=1$)'	was ranked	3 / 12 for this simulation (last regret = 0).
- Policy 'Thompson(Gauss)'	was ranked	4 / 12 for this simulation (last regret = 0.3).
- Policy 'kl-UCB'	was ranked	5 / 12 for this simulation (last regret = 0.3).
- Policy 'kl-UCB(Gauss)'	was ranked	6 / 12 for this simulation (last regret = 0.3).
- Policy 'ApprFHG($T=33$, $\alpha=1$)'	was ranked	7 / 12 for this simulation (last regret = 0.3).
- Policy 'OSSB($\varepsilon=0$, $\gamma=0$, Bernoulli)'	was ranked	8 / 12 for this simulation (last regret = 0.3).
- Policy 'UCB($\alpha=1$)'	was ranked	9 / 12 for this simulation (last regret = 1.2182).
- Policy 'OSSB($\varepsilon=0$, $\gamma=0$, Gaussian)'	was ranked	10 / 12 for this simulation (last regret = 1.5455).
- Policy 'OSSB($\varepsilon=0$, $\gamma=0$, sparse Gaussian)'	was ranked	11 / 12 for this simulation (last regret = 1.5455).
- Policy 'Thompson'	was ranked	12 / 12 for this simulation (last regret = 1.6).

This MAB problem has: 
 - a [Lai & Robbins] complexity constant C(mu) = 2.89 for 1-player problem... 
 - a Optimal Arm Identification factor H_OI(mu) = -16.67% ...
Warning: forcing to use putatright = True because there is 13 items in the legend.
