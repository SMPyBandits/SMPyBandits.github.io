

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-38514290-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Table of Contents &mdash; SMPyBandits 0.9.5 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Table of Contents" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html" />
    <link rel="prev" title="Table of Contents" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SMPyBandits
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html"><em>SMPyBandits</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/modules.html">SMPyBandits modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../How_to_run_the_code.html">How to run the code ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PublicationsWithSMPyBandits.html">List of research publications using Lilian Besson’s SMPyBandits project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Aggregation.html"><strong>Policy aggregation algorithms</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../MultiPlayers.html"><strong>Multi-players simulation environment</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../DoublingTrick.html"><strong>Doubling Trick for Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../SparseBandits.html"><strong>Structure and Sparsity of Stochastic Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../NonStationaryBandits.html"><strong>Non-Stationary Stochastic Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../API.html">Short documentation of the API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TODO.html">💥 TODO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plots/README.html">Some illustrations for this project</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">Jupyter Notebooks 📓 by Naereen &#64; GitHub</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="list.html">List of notebooks for SMPyBandits</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html#Easily-creating-MAB-problems">Easily creating MAB problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="Do_we_even_need_UCB.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Do_we_even_need_UCB.html#Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?"><em>Do we even need a smart learning algorithm? Is UCB useless?</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html#An-example-of-a-small-Single-Player-simulation">An example of a small Single-Player simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-Centralized-Algorithms">An example of a small Multi-Player simulation, with Centralized Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-rhoRand-and-Selfish,-for-different-algorithms">An example of a small Multi-Player simulation, with rhoRand and Selfish, for different algorithms</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Trying-to-use-Unsupervised-Learning-algorithms-for-a-Gaussian-bandit-problem">Trying to use Unsupervised Learning algorithms for a Gaussian bandit problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Creating-the-Gaussian-bandit-problem">Creating the Gaussian bandit problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Getting-data-from-a-first-phase-of-uniform-exploration">Getting data from a first phase of uniform exploration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Fitting-an-Unsupervised-Learning-algorithm">Fitting an Unsupervised Learning algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Using-the-prediction-to-decide-the-next-arm-to-sample">Using the prediction to decide the next arm to sample</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Manual-implementation-of-basic-Gaussian-kernel-fitting">Manual implementation of basic Gaussian kernel fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Implementing-a-Policy-from-that-idea">Implementing a Policy from that idea</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Basic-algorithm">Basic algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#A-variant,-by-aggregating-samples">A variant, by aggregating samples</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Implementation">Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Comparing-its-performance-on-this-Gaussian-problem">Comparing its performance on this Gaussian problem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Configuring-an-experiment">Configuring an experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Running-an-experiment">Running an experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Visualizing-the-results">Visualizing the results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Another-experiment,-with-just-more-Gaussian-arms">Another experiment, with just more Gaussian arms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Running-the-experiment">Running the experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Visualizing-the-results">Visualizing the results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Very-good-performance!">Very good performance!</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Another-experiment,-with-Bernoulli-arms">Another experiment, with Bernoulli arms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Running-the-experiment">Running the experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Visualizing-the-results">Visualizing the results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Conclusion">Conclusion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Non-logarithmic-regret">Non-logarithmic regret</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Comparing-time-complexity">Comparing <em>time complexity</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="#Not-so-efficient-for-Bernoulli-arms">Not so efficient for Bernoulli arms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html#Trying-to-use-Black-Box-Bayesian-optimization-algorithms-for-a-Gaussian-bandit-problem">Trying to use Black-Box Bayesian optimization algorithms for a Gaussian bandit problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.html#Lai-&amp;-Robbins-lower-bound-for-stochastic-bandit-with-full-restart-points">Lai &amp; Robbins lower-bound for stochastic bandit with full restart points</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exploring_different_doubling_tricks_for_different_kinds_of_regret_bounds.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exploring_different_doubling_tricks_for_different_kinds_of_regret_bounds.html#Exploring-different-doubling-tricks-for-different-kinds-of-regret-bounds">Exploring different doubling tricks for different kinds of regret bounds</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Requirements-and-helper-functions">Requirements and helper functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Python-implementations-of-some-statistical-tests">Python implementations of some statistical tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Comparing-the-different-implementations">Comparing the different implementations</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#More-simulations-and-some-plots">More simulations and some plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Exploring-the-parameters-of-change-point-detection-algorithms:-how-to-tune-them?">Exploring the parameters of change point detection algorithms: how to tune them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Conclusions">Conclusions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Demonstrations_of_Single-Player_Simulations_for_Non-Stationary-Bandits.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Demonstrations_of_Single-Player_Simulations_for_Non-Stationary-Bandits.html#Demonstrations-of-Single-Player-Simulations-for-Non-Stationary-Bandits">Demonstrations of Single-Player Simulations for Non-Stationary-Bandits</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Profiling.html">A note on execution times, speed and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uml_diagrams/README.html">UML diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logs/README.html"><code class="docutils literal notranslate"><span class="pre">logs</span></code> files</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SMPyBandits</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="list.html">List of notebooks for SMPyBandits</a> &raquo;</li>
        
      <li>Table of Contents</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Unsupervised_Learning_for_Bandit_problem.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Table-of-Contents">
<h1>Table of Contents<a class="headerlink" href="#Table-of-Contents" title="Permalink to this headline">¶</a></h1>
<p><div class="lev1 toc-item"><p>1&nbsp;&nbsp;Trying to use Unsupervised Learning algorithms for a Gaussian bandit problem</p>
</div><div class="lev2 toc-item"><p>1.1&nbsp;&nbsp;Creating the Gaussian bandit problem</p>
</div><div class="lev2 toc-item"><p>1.2&nbsp;&nbsp;Getting data from a first phase of uniform exploration</p>
</div><div class="lev2 toc-item"><p>1.3&nbsp;&nbsp;Fitting an Unsupervised Learning algorithm</p>
</div><div class="lev2 toc-item"><p>1.4&nbsp;&nbsp;Using the prediction to decide the next arm to sample</p>
</div><div class="lev2 toc-item"><p>1.5&nbsp;&nbsp;Manual implementation of basic Gaussian kernel fitting</p>
</div><div class="lev2 toc-item"><p>1.6&nbsp;&nbsp;Implementing a Policy from that idea</p>
</div><div class="lev3 toc-item"><p>1.6.1&nbsp;&nbsp;Basic algorithm</p>
</div><div class="lev3 toc-item"><p>1.6.2&nbsp;&nbsp;A variant, by aggregating samples</p>
</div><div class="lev3 toc-item"><p>1.6.3&nbsp;&nbsp;Implementation</p>
</div><div class="lev2 toc-item"><p>1.7&nbsp;&nbsp;Comparing its performance on this Gaussian problem</p>
</div><div class="lev3 toc-item"><p>1.7.1&nbsp;&nbsp;Configuring an experiment</p>
</div><div class="lev3 toc-item"><p>1.7.2&nbsp;&nbsp;Running an experiment</p>
</div><div class="lev3 toc-item"><p>1.7.3&nbsp;&nbsp;Visualizing the results</p>
</div><div class="lev2 toc-item"><p>1.8&nbsp;&nbsp;Another experiment, with just more Gaussian arms</p>
</div><div class="lev3 toc-item"><p>1.8.1&nbsp;&nbsp;Running the experiment</p>
</div><div class="lev3 toc-item"><p>1.8.2&nbsp;&nbsp;Visualizing the results</p>
</div><div class="lev3 toc-item"><p>1.8.3&nbsp;&nbsp;Very good performance!</p>
</div><div class="lev2 toc-item"><p>1.9&nbsp;&nbsp;Another experiment, with Bernoulli arms</p>
</div><div class="lev3 toc-item"><p>1.9.1&nbsp;&nbsp;Running the experiment</p>
</div><div class="lev3 toc-item"><p>1.9.2&nbsp;&nbsp;Visualizing the results</p>
</div><div class="lev2 toc-item"><p>1.10&nbsp;&nbsp;Conclusion</p>
</div><div class="lev3 toc-item"><p>1.10.1&nbsp;&nbsp;Non-logarithmic regret</p>
</div><div class="lev3 toc-item"><p>1.10.2&nbsp;&nbsp;Comparing time complexity</p>
</div><div class="lev3 toc-item"><p>1.10.3&nbsp;&nbsp;Not so efficient for Bernoulli arms</p>
</div></div>
<hr class="docutils" />
<div class="section" id="Trying-to-use-Unsupervised-Learning-algorithms-for-a-Gaussian-bandit-problem">
<h1>Trying to use Unsupervised Learning algorithms for a Gaussian bandit problem<a class="headerlink" href="#Trying-to-use-Unsupervised-Learning-algorithms-for-a-Gaussian-bandit-problem" title="Permalink to this headline">¶</a></h1>
<p>This small <a class="reference external" href="https://www.jupyter.org/">Jupyter notebook</a> presents an experiment, in the context of <a class="reference external" href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-Armed Bandit problems</a> (MAB).</p>
<p><a class="reference external" href="http://perso.crans.org/besson/">I am</a> trying to answer a simple question:</p>
<blockquote>
<div>“Can we use generic unsupervised learning algorithm, like <a class="reference external" href="http://scikit-learn.org/stable/modules/density.html">Kernel Density estimation</a> or <a class="reference external" href="http://scikit-learn.org/stable/modules/linear_model.html">Ridge Regression</a>, instead of MAB algorithms like <a class="reference external" href="http://sbubeck.com/SurveyBCB12.pdf">UCB</a> or <a class="reference external" href="https://en.wikipedia.org/wiki/Thompson_sampling">Thompson Sampling</a> ?</div></blockquote>
<p>I will use my <a class="reference external" href="https://smpybandits.github.io/">SMPyBandits</a> library, for which a complete documentation is available, <a class="reference external" href="https://smpybandits.github.io/">here at https://smpybandits.github.io/</a>, and the <a class="reference external" href="http://scikit-learn.org/">scikit-learn package</a>.</p>
<div class="section" id="Creating-the-Gaussian-bandit-problem">
<h2>Creating the Gaussian bandit problem<a class="headerlink" href="#Creating-the-Gaussian-bandit-problem" title="Permalink to this headline">¶</a></h2>
<p>First, be sure to be in the main folder, or to have installed <code class="docutils literal notranslate"><span class="pre">`SMPyBandits</span></code> &lt;<a class="reference external" href="https://github.com/SMPyBandits/SMPyBandits">https://github.com/SMPyBandits/SMPyBandits</a>&gt;`__, and import the <code class="docutils literal notranslate"><span class="pre">`MAB</span></code> class &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Environment.MAB.html#Environment.MAB.MAB">https://smpybandits.github.io/docs/Environment.MAB.html#Environment.MAB.MAB</a>&gt;`__ from <cite>the ``Environment`</cite> package &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Environment.html#module-Environment">https://smpybandits.github.io/docs/Environment.html#module-Environment</a>&gt;`__:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>pip install SMPyBandits watermark
<span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -v -m -p SMPyBandits -a &quot;Lilian Besson&quot;
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requirement already satisfied: SMPyBandits in ./venv3/lib/python3.6/site-packages (0.9.4)
Requirement already satisfied: watermark in ./venv3/lib/python3.6/site-packages (1.7.0)
Requirement already satisfied: scikit-optimize in ./venv3/lib/python3.6/site-packages (from SMPyBandits) (0.5.2)
Requirement already satisfied: matplotlib&gt;=2 in ./venv3/lib/python3.6/site-packages (from SMPyBandits) (3.0.2)
Requirement already satisfied: scikit-learn in ./venv3/lib/python3.6/site-packages (from SMPyBandits) (0.20.0)
Requirement already satisfied: numpy in ./venv3/lib/python3.6/site-packages (from SMPyBandits) (1.15.4)
Requirement already satisfied: joblib in ./venv3/lib/python3.6/site-packages (from SMPyBandits) (0.13.0)
Requirement already satisfied: seaborn in ./venv3/lib/python3.6/site-packages (from SMPyBandits) (0.9.0)
Requirement already satisfied: scipy&gt;0.9 in ./venv3/lib/python3.6/site-packages (from SMPyBandits) (1.1.0)
Requirement already satisfied: ipython in ./venv3/lib/python3.6/site-packages (from watermark) (7.1.1)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in ./venv3/lib/python3.6/site-packages (from matplotlib&gt;=2-&gt;SMPyBandits) (2.3.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in ./venv3/lib/python3.6/site-packages (from matplotlib&gt;=2-&gt;SMPyBandits) (2.7.5)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in ./venv3/lib/python3.6/site-packages (from matplotlib&gt;=2-&gt;SMPyBandits) (1.0.1)
Requirement already satisfied: cycler&gt;=0.10 in ./venv3/lib/python3.6/site-packages (from matplotlib&gt;=2-&gt;SMPyBandits) (0.10.0)
Requirement already satisfied: pandas&gt;=0.15.2 in ./venv3/lib/python3.6/site-packages (from seaborn-&gt;SMPyBandits) (0.23.4)
Requirement already satisfied: pygments in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (2.2.0)
Requirement already satisfied: pexpect; sys_platform != &#34;win32&#34; in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (4.6.0)
Requirement already satisfied: jedi&gt;=0.10 in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (0.13.1)
Requirement already satisfied: decorator in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (4.3.0)
Requirement already satisfied: setuptools&gt;=18.5 in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (40.6.2)
Requirement already satisfied: prompt-toolkit&lt;2.1.0,&gt;=2.0.0 in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (2.0.7)
Requirement already satisfied: pickleshare in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (0.7.5)
Requirement already satisfied: backcall in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (0.1.0)
Requirement already satisfied: traitlets&gt;=4.2 in ./venv3/lib/python3.6/site-packages (from ipython-&gt;watermark) (4.3.2)
Requirement already satisfied: six&gt;=1.5 in ./venv3/lib/python3.6/site-packages (from python-dateutil&gt;=2.1-&gt;matplotlib&gt;=2-&gt;SMPyBandits) (1.11.0)
Requirement already satisfied: pytz&gt;=2011k in ./venv3/lib/python3.6/site-packages (from pandas&gt;=0.15.2-&gt;seaborn-&gt;SMPyBandits) (2018.7)
Requirement already satisfied: ptyprocess&gt;=0.5 in ./venv3/lib/python3.6/site-packages (from pexpect; sys_platform != &#34;win32&#34;-&gt;ipython-&gt;watermark) (0.6.0)
Requirement already satisfied: parso&gt;=0.3.0 in ./venv3/lib/python3.6/site-packages (from jedi&gt;=0.10-&gt;ipython-&gt;watermark) (0.3.1)
Requirement already satisfied: wcwidth in ./venv3/lib/python3.6/site-packages (from prompt-toolkit&lt;2.1.0,&gt;=2.0.0-&gt;ipython-&gt;watermark) (0.1.7)
Requirement already satisfied: ipython-genutils in ./venv3/lib/python3.6/site-packages (from traitlets&gt;=4.2-&gt;ipython-&gt;watermark) (0.2.0)
Lilian Besson

CPython 3.6.6
IPython 7.1.1

SMPyBandits 0.9.4

compiler   : GCC 8.0.1 20180414 (experimental) [trunk revision 259383
system     : Linux
release    : 4.15.0-38-generic
machine    : x86_64
processor  : x86_64
CPU cores  : 4
interpreter: 64bit
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">SMPyBandits.Environment</span> <span class="k">import</span> <span class="n">MAB</span>
</pre></div>
</div>
</div>
<p>And also, import the <code class="docutils literal notranslate"><span class="pre">`Gaussian</span></code> class &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Arms.Gaussian.html#Arms.Gaussian.Gaussian">https://smpybandits.github.io/docs/Arms.Gaussian.html#Arms.Gaussian.Gaussian</a>&gt;`__ to create Gaussian-distributed arms.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">SMPyBandits.Arms</span> <span class="k">import</span> <span class="n">Gaussian</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Just improving the ?? in Jupyter. Thanks to https://nbviewer.jupyter.org/gist/minrk/7715212</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">IPython.core</span> <span class="k">import</span> <span class="n">page</span>
<span class="k">def</span> <span class="nf">myprint</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;text/plain&#39;</span><span class="p">])</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">KeyError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">page</span><span class="o">.</span><span class="n">page</span> <span class="o">=</span> <span class="n">myprint</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>Gaussian<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> Gaussian<span class="ansi-blue-fg">(</span>mu<span class="ansi-blue-fg">,</span> sigma<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.05</span><span class="ansi-blue-fg">,</span> mini<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> maxi<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>
Gaussian distributed arm, possibly truncated.

- Default is to truncate into [0, 1] (so Gaussian.draw() is in [0, 1]).
<span class="ansi-red-fg">Init docstring:</span> New arm.
<span class="ansi-red-fg">File:</span>           /tmp/SMPyBandits/notebooks/venv3/lib/python3.6/site-packages/SMPyBandits/Arms/Gaussian.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<p>Let create a simple bandit problem, with 3 arms, and visualize an histogram showing the repartition of rewards.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">MAB</span><span class="p">(</span><span class="n">Gaussian</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="n">means</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


Creating a new MAB problem ...
  Taking arms of this MAB problem from a list of arms &#39;configuration&#39; = &lt;generator object &lt;genexpr&gt; at 0x7f96e931c3b8&gt; ...
 - with &#39;arms&#39; = [N(0.45, 0.2), N(0.5, 0.2), N(0.55, 0.2)]
 - with &#39;means&#39; = [0.45 0.5  0.55]
 - with &#39;nbArms&#39; = 3
 - with &#39;maxArm&#39; = 0.55
 - with &#39;minArm&#39; = 0.45

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 12 ...
 - a Optimal Arm Identification factor H_OI(mu) = 61.67% ...
 - with &#39;arms&#39; represented as: $[N(0.45), N(0.5), N(0.55)^*], \sigma^2=0.2$
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">_</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">plotHistogram</span><span class="p">(</span><span class="n">horizon</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Warning: forcing to use putatright = False because there is 3 items in the legend.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_12_1.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_12_1.png" />
<p>As we can see, the rewards of the different arms are close. It won’t be easy to distinguish them.</p>
</div>
</div>
<p>Then we can generate some draws, from all arms, from time <span class="math notranslate nohighlight">\(t=1\)</span> to <span class="math notranslate nohighlight">\(t=T_0\)</span>, for let say <span class="math notranslate nohighlight">\(T_0 = 1000\)</span> :</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">T_0</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">T_0</span><span class="p">,)</span>
<span class="n">draws</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="n">b</span><span class="o">.</span><span class="n">draw_nparray</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">M</span><span class="o">.</span><span class="n">arms</span> <span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">draws</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[0.        , 0.47923905, 0.20472672, ..., 0.210323  , 0.46904632,
        0.57008369],
       [0.31612832, 0.43663395, 0.37957678, ..., 0.5698547 , 1.        ,
        0.60503855],
       [0.57721804, 0.51655436, 0.31143485, ..., 0.21849785, 0.37846134,
        0.28097044]])
</pre></div>
</div>
</div>
<p>The <em>empirical means</em> of each arm can be estimated, quite easily, and could be used to make all the decisions from <span class="math notranslate nohighlight">\(t \geq T_0 + 1\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">empirical_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">draws</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">empirical_means</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([0.44049468, 0.48758654, 0.55018788])
</pre></div>
</div>
</div>
<p>Clearly, the last arm is the best. And the empirical means <span class="math notranslate nohighlight">\(\hat{\mu}_k(t)\)</span> for <span class="math notranslate nohighlight">\(k=1,\dots,K\)</span>, are really close to the true one, as <span class="math notranslate nohighlight">\(T_0 = 1000\)</span> is quite large.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">relative_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">relative_error</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">empirical_means</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([0.02112293, 0.02482692, 0.0003416 ])
</pre></div>
</div>
</div>
<p>That’s less than <span class="math notranslate nohighlight">\(3\%\)</span> error, it’s already quite good!</p>
<p><em>Conclusion</em> : If we have “enough” samples, and the distribution are not too close, there is no need to do any learning: just pick the arm with highest mean, from now on, and you will be good!</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">best_arm_estimated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">empirical_means</span><span class="p">)</span>
<span class="n">best_arm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">best_arm_estimated</span> <span class="o">==</span> <span class="n">best_arm</span><span class="p">,</span> <span class="s2">&quot;Error: the best arm is wrongly estimated, even after </span><span class="si">{}</span><span class="s2"> samples.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">T_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Getting-data-from-a-first-phase-of-uniform-exploration">
<h2>Getting data from a first phase of uniform exploration<a class="headerlink" href="#Getting-data-from-a-first-phase-of-uniform-exploration" title="Permalink to this headline">¶</a></h2>
<p>But maybe <span class="math notranslate nohighlight">\(T_0 = 1000\)</span> was really too large…</p>
<p>Let assume that the initial data was obtained from an algorithm which starts playing by exploring every arm, uniformly at random, until it gets “enough” data.</p>
<ul class="simple">
<li>On the one hand, if we ask him to sample each arm <span class="math notranslate nohighlight">\(1000\)</span> times, of course the empirical mean <span class="math notranslate nohighlight">\(\hat{\mu_k(t)}\)</span> will correctly estimate the true mean <span class="math notranslate nohighlight">\(\mu_k\)</span> (if the gap <span class="math notranslate nohighlight">\(\Delta = \min_{i \neq j} |\mu_i - \mu_j|\)</span> is not too small).</li>
<li>But on the other hand, starting with a long phase of uniform exploration will increase dramatically the regret.</li>
</ul>
<p>What if we want to use the same technique on very few data? Let see with <span class="math notranslate nohighlight">\(T_0 = 10\)</span>, if the empirical means are still as close to the true ones.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>  <span class="c1"># for reproducibility of the error best_arm_estimated = 1</span>
<span class="n">T_0</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">draws</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="n">b</span><span class="o">.</span><span class="n">draw_nparray</span><span class="p">((</span><span class="n">T_0</span><span class="p">,</span> <span class="p">))</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">M</span><span class="o">.</span><span class="n">arms</span> <span class="p">])</span>
<span class="n">empirical_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">draws</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">empirical_means</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([0.42070333, 0.51071708, 0.50317952])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">relative_error</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">empirical_means</span><span class="p">)</span>
<span class="n">best_arm_estimated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">empirical_means</span><span class="p">)</span>
<span class="n">best_arm_estimated</span>
<span class="k">assert</span> <span class="n">best_arm_estimated</span> <span class="o">==</span> <span class="n">best_arm</span><span class="p">,</span> <span class="s2">&quot;Error: the best arm is wrongly estimated, even after </span><span class="si">{}</span><span class="s2"> samples.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">T_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([0.06510371, 0.02143416, 0.08512815])
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>1
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AssertionError</span>                            Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-20-d6b11bbf71cf&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> best_arm_estimated <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>argmax<span class="ansi-blue-fg">(</span>empirical_means<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> best_arm_estimated
<span class="ansi-green-fg">----&gt; 4</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">assert</span> best_arm_estimated <span class="ansi-blue-fg">==</span> best_arm<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#34;Error: the best arm is wrongly estimated, even after {} samples.&#34;</span><span class="ansi-blue-fg">.</span>format<span class="ansi-blue-fg">(</span>T_0<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">AssertionError</span>: Error: the best arm is wrongly estimated, even after 10 samples.
</pre></div></div>
</div>
<p>Clearly, if there is not enough sample, the <a class="reference external" href="https://smpybandits.github.io/docs/Policies.EmpiricalMeans.html#Policies.EmpiricalMeans.EmpiricalMeans">*empirical mean* estimator</a> <em>can</em> be wrong. It will not always be wrong with so few samples, but it can.</p>
</div>
<hr class="docutils" />
<div class="section" id="Fitting-an-Unsupervised-Learning-algorithm">
<h2>Fitting an Unsupervised Learning algorithm<a class="headerlink" href="#Fitting-an-Unsupervised-Learning-algorithm" title="Permalink to this headline">¶</a></h2>
<p>We should use the initial data for more than just getting empirical means.</p>
<p>Let use a simple <em>Unsupervised Learning</em> algorithm, implemented in the <cite>scikit-learn (``sklearn`</cite>) &lt;<a class="reference external" href="http://scikit-learn.org/">http://scikit-learn.org/</a>&gt;`__ package: <a class="reference external" href="http://scikit-learn.org/stable/modules/density.html">1D Kernel Density estimation</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors.kde</span> <span class="k">import</span> <span class="n">KernelDensity</span>
</pre></div>
</div>
</div>
<p>First, we need to create a model.</p>
<p>Here we assume to know that the arms are Gaussian, so fitting a Gaussian kernel will probably work the best. The <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code> parameter should be of the order of the variances <span class="math notranslate nohighlight">\(\sigma_k\)</span> of each arm (we used <span class="math notranslate nohighlight">\(0.2\)</span>).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">kde</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="n">bandwidth</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">kde</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>KernelDensity(algorithm=&#39;auto&#39;, atol=0, bandwidth=0.2, breadth_first=True,
       kernel=&#39;gaussian&#39;, leaf_size=40, metric=&#39;euclidean&#39;,
       metric_params=None, rtol=0)
</pre></div>
</div>
</div>
<p>Then, we will feed it the initial data, obtained from the initial phase of uniform exploration, from <span class="math notranslate nohighlight">\(t = 1, \dots, T_0\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">draws</span>
<span class="n">draws</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[ 0.19578187,  0.48522741,  0.39075672,  0.51538576,  0.25531612,
         0.4955362 ,  0.28613439,  0.47144451,  0.64505553,  0.46639478],
       [ 0.40467549,  0.20156569,  0.41930701,  0.63895565,  0.54243056,
         0.51819797,  0.19022907,  0.49103453,  0.81135267,  0.88942214],
       [ 0.39297198,  0.12215761,  0.29714829,  0.60899744,  0.71129785,
         0.60553406,  0.30123099,  0.70745487,  0.70040608,  0.584596  ]])
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>(3, 10)
</pre></div>
</div>
</div>
<p>We need to use the transpose of this array, as the data should have shape <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_features)</span></code>, i.e., of shape <code class="docutils literal notranslate"><span class="pre">(10,</span> <span class="pre">3)</span></code> here.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>kde.fit<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Signature:</span> kde<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>
Fit the Kernel Density model on the data.

Parameters
----------
X : array_like, shape (n_samples, n_features)
    List of n_features-dimensional data points.  Each row
    corresponds to a single data point.
<span class="ansi-red-fg">File:</span>      /usr/local/lib/python3.5/dist-packages/sklearn/neighbors/kde.py
<span class="ansi-red-fg">Type:</span>      method

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">kde</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">draws</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>KernelDensity(algorithm=&#39;auto&#39;, atol=0, bandwidth=0.2, breadth_first=True,
       kernel=&#39;gaussian&#39;, leaf_size=40, metric=&#39;euclidean&#39;,
       metric_params=None, rtol=0)
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">`score_samples(X)</span></code> &lt;<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity.score_samples">http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html#sklearn.neighbors.KernelDensity.score_samples</a>&gt;`__ method can be used to evaluate the density on sample data (i.e., the likelihood of each observation).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">draws</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([ 0.74775249,  0.38689241,  0.8415668 ,  1.15395093,  0.78990714,
        1.14875055,  0.65704831,  1.05109219,  0.69428901,  0.64198648])
</pre></div>
</div>
</div>
<p>For instance, based on the means <span class="math notranslate nohighlight">\([0.45, 0.5, 0.55]\)</span>, the sample <span class="math notranslate nohighlight">\([10, -10, 0]\)</span> should be <em>very</em> unlikely, while <span class="math notranslate nohighlight">\([0.4, 0.5, 0.6]\)</span> will be <em>more</em> likely. And the vector of empirical means is a very likely observation as well.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">kde</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">kde</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">kde</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">empirical_means</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>-2432.9531169042129
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>1.1497424000393375
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>1.1001537768074523
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Using-the-prediction-to-decide-the-next-arm-to-sample">
<h2>Using the prediction to decide the next arm to sample<a class="headerlink" href="#Using-the-prediction-to-decide-the-next-arm-to-sample" title="Permalink to this headline">¶</a></h2>
<p>Now that we have a model of <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html">Kernel Density</a> estimation, we can use it to <em>generate some random samples</em>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>kde.sample<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Signature:</span> kde<span class="ansi-blue-fg">.</span>sample<span class="ansi-blue-fg">(</span>n_samples<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> random_state<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>
Generate random samples from the model.

Currently, this is implemented only for gaussian and tophat kernels.

Parameters
----------
n_samples : int, optional
    Number of samples to generate. Defaults to 1.

random_state : RandomState or an int seed (0 by default)
    A random number generator instance.

Returns
-------
X : array_like, shape (n_samples, n_features)
    List of samples.
<span class="ansi-red-fg">File:</span>      /usr/local/lib/python3.5/dist-packages/sklearn/neighbors/kde.py
<span class="ansi-red-fg">Type:</span>      method

</pre></div></div>
</div>
<p>Basically, that means we can use this model to predict what the next output of the 3 arms (constituting the Gaussian problem) will be.</p>
<p>Let see this with one example.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">one_sample</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">one_sample</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([[ 0.38558697,  0.23762342,  0.92208452]])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">one_draw</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">draw_each</span><span class="p">()</span>
<span class="n">one_draw</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>array([ 0.48799428,  0.38957079,  0.69945781])
</pre></div>
</div>
</div>
<p>Of course, the next random rewards from the arms have no reason to be close to predicted ones…</p>
<p>But maybe we can use the prediction to choose the arm with highest sample? And hopefully this will be the best arm, <em>at least in average</em>!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">best_arm_sampled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">one_sample</span><span class="p">)</span>
<span class="n">best_arm_sampled</span>
<span class="k">assert</span> <span class="n">best_arm_sampled</span> <span class="o">==</span> <span class="n">best_arm</span><span class="p">,</span> <span class="s2">&quot;Error: the best arm is wrongly estimated from a random sample, even after </span><span class="si">{}</span><span class="s2"> observations.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">T_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>2
</pre></div>
</div>
</div>
</div>
<div class="section" id="Manual-implementation-of-basic-Gaussian-kernel-fitting">
<h2>Manual implementation of basic Gaussian kernel fitting<a class="headerlink" href="#Manual-implementation-of-basic-Gaussian-kernel-fitting" title="Permalink to this headline">¶</a></h2>
<p>We can also implement manually a simple 1D Unsupervised Learning algorithm, which fits a Gaussian kernel (i.e., a distribution <span class="math notranslate nohighlight">\(\mathcal{N}(\mu,\sigma)\)</span>) on the 1D data, for each arm.</p>
<p>Let start with a base class, showing the signature any Unsupervised Learning should have to be used in our policy (defined below).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># --- Unsupervised fitting models</span>

<span class="k">class</span> <span class="nc">FittingModel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Base class for any fitting model&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Nothing to do here.&quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Nothing to do here.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always 0., for instance.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">0.</span>

    <span class="k">def</span> <span class="nf">score_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Always 1., for instance.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">1.</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Log likelihood of the point (or the vector of data), under the current Gaussian model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<p>And then, the <code class="docutils literal notranslate"><span class="pre">SimpleGaussianKernel</span></code> class, using <code class="docutils literal notranslate"><span class="pre">`scipy.stats.norm.pdf</span></code> &lt;<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html</a>&gt;`__ to evaluate the log-probability of an observation.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>


<span class="k">class</span> <span class="nc">SimpleGaussianKernel</span><span class="p">(</span><span class="n">FittingModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Basic Unsupervised Learning algorithm, which simply fits a 1D Gaussian on some 1D data.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot; Starts with :math:`\mathcal{N}(0, 1)`, by default.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;N(</span><span class="si">{:.3g}</span><span class="s2">, </span><span class="si">{:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Use the mean and variance from the 1D vector data (of shape `n_samples` or `(n_samples, 1)`).&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Return one or more sample, from the current Gaussian model.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">score_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Likelihood of the point (or the vector of data), under the current Gaussian model, component-wise.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Implementing-a-Policy-from-that-idea">
<h2>Implementing a Policy from that idea<a class="headerlink" href="#Implementing-a-Policy-from-that-idea" title="Permalink to this headline">¶</a></h2>
<p>Based on that idea, we can implement a policy, following the <a class="reference external" href="https://smpybandits.github.io/docs/Policies.BasePolicy.html#Policies.BasePolicy.BasePolicy">common API of all the policies</a> of my framework.</p>
<div class="section" id="Basic-algorithm">
<h3>Basic algorithm<a class="headerlink" href="#Basic-algorithm" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p class="first">Initially : create <span class="math notranslate nohighlight">\(K\)</span> Unsupervised Learning algorithms <span class="math notranslate nohighlight">\(\mathcal{U}_k(0)\)</span>, <span class="math notranslate nohighlight">\(k\in\{1,\dots,K\}\)</span>, for instance <code class="docutils literal notranslate"><span class="pre">KernelDensity</span></code> estimators.</p>
</li>
<li><p class="first">For the first <span class="math notranslate nohighlight">\(K \times T_0\)</span> time steps, each arm <span class="math notranslate nohighlight">\(k \in \{1, \dots, K\}\)</span> is sampled exactly <span class="math notranslate nohighlight">\(T_0\)</span> times, to get a lot of initial observations for each arm.</p>
</li>
<li><p class="first">With these first <span class="math notranslate nohighlight">\(T_0\)</span> (e.g., <span class="math notranslate nohighlight">\(50\)</span>) observations, train a first version of the Unsupervised Learning algorithms <span class="math notranslate nohighlight">\(\mathcal{U}_k(t)\)</span>, <span class="math notranslate nohighlight">\(k\in\{1,\dots,K\}\)</span>.</p>
</li>
<li><p class="first">Then, for the following time steps, <span class="math notranslate nohighlight">\(t \geq T_0 + 1\)</span> :</p>
<ul>
<li><p class="first">Once in a while (every <span class="math notranslate nohighlight">\(T_1 =\)</span> <code class="docutils literal notranslate"><span class="pre">fit_every</span></code> steps, e.g., <span class="math notranslate nohighlight">\(100\)</span>), retrain all the Unsupervised Learning algorithms :</p>
<ul class="simple">
<li>For each arm <span class="math notranslate nohighlight">\(k\in\{1,\dots,K\}\)</span>, use all the previous observations of that arm to train the model <span class="math notranslate nohighlight">\(\mathcal{U}_k(t)\)</span>.</li>
</ul>
</li>
<li><p class="first">Otherwise, use the previously trained model :</p>
<ul>
<li><p class="first">Get a random sample, <span class="math notranslate nohighlight">\(s_k(t)\)</span> from the <span class="math notranslate nohighlight">\(K\)</span> Unsupervised Learning algorithms <span class="math notranslate nohighlight">\(\mathcal{U}_k(t)\)</span>, <span class="math notranslate nohighlight">\(k\in\{1,\dots,K\}\)</span> :</p>
<div class="math notranslate nohighlight">
\[\forall k\in\{1,\dots,K\}, \;\; s_k(t) \sim \mathcal{U}_k(t).\]</div>
</li>
<li><p class="first">Chose the arm <span class="math notranslate nohighlight">\(A(t)\)</span> with <em>highest</em> sample :</p>
<div class="math notranslate nohighlight">
\[A(t) \in \arg\max_{k\in\{1,\dots,K\}} s_k(t).\]</div>
</li>
<li><p class="first">Play that arm <span class="math notranslate nohighlight">\(A(t)\)</span>, receive a reward <span class="math notranslate nohighlight">\(r_{A(t)}(t)\)</span> from its (unknown) distribution, and store it.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="A-variant,-by-aggregating-samples">
<h3>A variant, by aggregating samples<a class="headerlink" href="#A-variant,-by-aggregating-samples" title="Permalink to this headline">¶</a></h3>
<p>A more robust (and so more correct) variant could be to use a bunch of samples, and use their mean to give <span class="math notranslate nohighlight">\(s_k(t)\)</span> :</p>
<ul>
<li><p class="first">Get a bunch of <span class="math notranslate nohighlight">\(M\)</span> random samples (e.g., <span class="math notranslate nohighlight">\(50\)</span>), <span class="math notranslate nohighlight">\(s_k^i(t)\)</span> from the <span class="math notranslate nohighlight">\(K\)</span> Unsupervised Learning algorithms <span class="math notranslate nohighlight">\(\mathcal{U}_k(t)\)</span>, <span class="math notranslate nohighlight">\(k\in\{1,\dots,K\}\)</span> :</p>
<div class="math notranslate nohighlight">
\[\forall k\in\{1,\dots,K\}, \;\; \forall i\in\{1,\dots,M\}, \;\; s_k^i(t) \sim \mathcal{U}_k(t).\]</div>
</li>
<li><p class="first">Average them to get <span class="math notranslate nohighlight">\(\hat{s_k}(t)\)</span> :</p>
<div class="math notranslate nohighlight">
\[\forall k\in\{1,\dots,K\}, \;\; \hat{s_k}(t) := \frac{1}{M} \sum_{i=1}^{M} s_k^i(t).\]</div>
</li>
<li><p class="first">Chose the arm <span class="math notranslate nohighlight">\(A(t)\)</span> with <em>highest</em> mean sample :</p>
<div class="math notranslate nohighlight">
\[A(t) \in \arg\max_{k\in\{1,\dots,K\}} \hat{s_k}(t).\]</div>
</li>
</ul>
</div>
<div class="section" id="Implementation">
<h3>Implementation<a class="headerlink" href="#Implementation" title="Permalink to this headline">¶</a></h3>
<p>In code, this gives the following:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">UnsupervisedLearning</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Generic policy using an Unsupervised Learning algorithm, from scikit-learn.</span>

<span class="sd">    - Warning: still highly experimental!</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nbArms</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="n">KernelDensity</span><span class="p">,</span>
                 <span class="n">T_0</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">fit_every</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">meanOf</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                 <span class="n">lower</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">amplitude</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>  <span class="c1"># not used, but needed for my framework</span>
                 <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nbArms</span> <span class="o">=</span> <span class="n">nbArms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">T_0</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">T_0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T_0</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">T_0</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_every</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fit_every</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">meanOf</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">meanOf</span><span class="p">)</span>
        <span class="c1"># Unsupervised Learning algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_was_fitted</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_estimator</span> <span class="o">=</span> <span class="n">estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ests</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimator</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbArms</span><span class="p">)</span> <span class="p">]</span>
        <span class="c1"># Store all the observations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observations</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nbArms</span><span class="p">)</span> <span class="p">]</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;UnsupervisedLearning({.__name__}, $T_0=</span><span class="si">{:.3g}</span><span class="s2">$, $T_1=</span><span class="si">{:.3g}</span><span class="s2">$, $M=</span><span class="si">{:.3g}</span><span class="s2">$)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_estimator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T_0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_every</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">meanOf</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">startGame</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Reinitialize everything.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ests</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimator</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nbArms</span><span class="p">)</span> <span class="p">]</span>

    <span class="k">def</span> <span class="nf">getReward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">armId</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Store this observation.&quot;&quot;&quot;</span>
        <span class="c1"># print(&quot;   - At time {}, we saw {} from arm {} ...&quot;.format(self.t, reward, armId))  # DEBUG</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">[</span><span class="n">armId</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">choice</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Choose an arm.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Start by sampling each arm a certain number of times</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">nbArms</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">T_0</span><span class="p">:</span>
            <span class="c1"># print(&quot;- First phase: exploring arm {} at time {} ...&quot;.format(self.t % self.nbArms, self.t))  # DEBUG</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">nbArms</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># print(&quot;- Second phase: at time {} ...&quot;.format(self.t))  # DEBUG</span>
            <span class="c1"># 1. Fit the Unsupervised Learning on *all* the data observed so far, but do it once in a while only</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_was_fitted</span><span class="p">:</span>
                <span class="c1"># print(&quot;   - Need to first fit the model of each arm with the first {} observations, now of shape {} ...&quot;.format(self.fit_every, np.shape(self.observations)))  # DEBUG</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_was_fitted</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">t</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># print(&quot;   - Need to refit the model of each arm with {} more observations, now of shape {} ...&quot;.format(self.fit_every, np.shape(self.observations)))  # DEBUG</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observations</span><span class="p">)</span>
            <span class="c1"># 2. Sample a random prediction for next output of the arms</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_with_mean</span><span class="p">()</span>
            <span class="c1"># 3. Use this sample to select next arm to play</span>
            <span class="n">best_arm_predicted</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
            <span class="c1"># print(&quot;   - So the best arm seems to be = {} ...&quot;.format(best_arm_predicted))  # DEBUG</span>
            <span class="k">return</span> <span class="n">best_arm_predicted</span>

    <span class="c1"># --- Shortcut methods</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Fit each of the K models, with the data accumulated up-to now.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">armId</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nbArms</span><span class="p">):</span>
            <span class="c1"># print(&quot; - Fitting the #{} model, with observations of shape {} ...&quot;.format(armId + 1, np.shape(self.observations[armId])))  # DEBUG</span>
            <span class="n">est</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ests</span><span class="p">[</span><span class="n">armId</span><span class="p">]</span>
            <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">armId</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ests</span><span class="p">[</span><span class="n">armId</span><span class="p">]</span> <span class="o">=</span> <span class="n">est</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Return a vector of random sample from each of the K models.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span> <span class="nb">float</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ests</span> <span class="p">]</span>

    <span class="k">def</span> <span class="nf">sample_with_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">meanOf</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Return a vector of random sample from each of the K models, by averaging a lot of samples (reduce variance).&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">meanOf</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">meanOf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">meanOf</span>
        <span class="k">return</span> <span class="p">[</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">meanOf</span><span class="p">)))</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ests</span> <span class="p">]</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Return a vector of scores, for each of the K models on its observation.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span> <span class="nb">float</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">est</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ests</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span> <span class="p">]</span>

    <span class="k">def</span> <span class="nf">estimatedOrder</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Return the estimate order of the arms, as a permutation on [0..K-1] that would order the arms by increasing means.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_with_mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>UnsupervisedLearning<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> UnsupervisedLearning<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> estimator<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&lt;</span><span class="ansi-green-fg">class</span> <span class="ansi-blue-fg">&#39;sklearn.neighbors.kde.KernelDensity&#39;</span><span class="ansi-blue-fg">&gt;</span><span class="ansi-blue-fg">,</span> T_0<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">10</span><span class="ansi-blue-fg">,</span> fit_every<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">100</span><span class="ansi-blue-fg">,</span> meanOf<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">50</span><span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>
Generic policy using an Unsupervised Learning algorithm, from scikit-learn.

- Warning: still highly experimental!
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<p>For example, we can chose these values for the numerical parameters :</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">nbArms</span> <span class="o">=</span> <span class="n">M</span><span class="o">.</span><span class="n">nbArms</span>
<span class="n">T_0</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">fit_every</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">meanOf</span> <span class="o">=</span> <span class="mi">200</span>
</pre></div>
</div>
</div>
<p>And use the same Unsupervised Learning algorithm as previously.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">estimator</span> <span class="o">=</span> <span class="n">KernelDensity</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="n">bandwidth</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">estimator2</span> <span class="o">=</span> <span class="n">SimpleGaussianKernel</span>
<span class="n">kwargs2</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>This gives the following policy:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">policy</span> <span class="o">=</span> <span class="n">UnsupervisedLearning</span><span class="p">(</span><span class="n">nbArms</span><span class="p">,</span> <span class="n">T_0</span><span class="o">=</span><span class="n">T_0</span><span class="p">,</span> <span class="n">fit_every</span><span class="o">=</span><span class="n">fit_every</span><span class="p">,</span> <span class="n">meanOf</span><span class="o">=</span><span class="n">meanOf</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
policy<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Type:</span>        UnsupervisedLearning
<span class="ansi-red-fg">String form:</span> UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$)
<span class="ansi-red-fg">Docstring:</span>
Generic policy using an Unsupervised Learning algorithm, from scikit-learn.

- Warning: still highly experimental!

</pre></div></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Comparing-its-performance-on-this-Gaussian-problem">
<h2>Comparing its performance on this Gaussian problem<a class="headerlink" href="#Comparing-its-performance-on-this-Gaussian-problem" title="Permalink to this headline">¶</a></h2>
<p>We can compare the performance of this <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning(kde)</span></code> policy, on the same Gaussian problem, against three strategies:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">`EmpiricalMeans</span></code> &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Policies.EmpiricalMeans.html#Policies.EmpiricalMeans.EmpiricalMeans">https://smpybandits.github.io/docs/Policies.EmpiricalMeans.html#Policies.EmpiricalMeans.EmpiricalMeans</a>&gt;`__, which only uses the empirical mean estimators <span class="math notranslate nohighlight">\(\hat{\mu_k}(t)\)</span>. It is known to be insufficient.</li>
<li><code class="docutils literal notranslate"><span class="pre">`UCB</span></code> &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Policies.UCB.html#Policies.UCB.UCB">https://smpybandits.github.io/docs/Policies.UCB.html#Policies.UCB.UCB</a>&gt;`__, the UCB1 algorithm. It is known to be quite efficient.</li>
<li><code class="docutils literal notranslate"><span class="pre">`Thompson</span></code> &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Policies.Thompson.html#Policies.Thompson.Thompson">https://smpybandits.github.io/docs/Policies.Thompson.html#Policies.Thompson.Thompson</a>&gt;`__, the Thompson Sampling algorithm. It is known to be very efficient.</li>
<li><code class="docutils literal notranslate"><span class="pre">`klUCB</span></code> &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Policies.klUCB.html#Policies.klUCB.klUCB">https://smpybandits.github.io/docs/Policies.klUCB.html#Policies.klUCB.klUCB</a>&gt;`__, the kl-UCB algorithm, for Gaussian arms (<code class="docutils literal notranslate"><span class="pre">klucb</span> <span class="pre">=</span> <span class="pre">klucbGauss</span></code>). It is also known to be very efficient.</li>
</ul>
<div class="section" id="Configuring-an-experiment">
<h3>Configuring an experiment<a class="headerlink" href="#Configuring-an-experiment" title="Permalink to this headline">¶</a></h3>
<p>I implemented in the <code class="docutils literal notranslate"><span class="pre">`Environment</span></code> &lt;<a class="reference external" href="http://https://smpybandits.github.io/docs/Environment.html">http://https://smpybandits.github.io/docs/Environment.html</a>&gt;`__ module an <code class="docutils literal notranslate"><span class="pre">`Evaluator</span></code> &lt;<a class="reference external" href="http://https://smpybandits.github.io/docs/Environment.Evaluator.html#Environment.Evaluator.Evaluator">http://https://smpybandits.github.io/docs/Environment.Evaluator.html#Environment.Evaluator.Evaluator</a>&gt;`__ class, very convenient to run experiments of Multi-Armed Bandit games without a sweat.</p>
<p>Let us use it!</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">SMPyBandits.Environment</span> <span class="k">import</span> <span class="n">Evaluator</span>
</pre></div>
</div>
</div>
<p>We will start with a small experiment, with a small horizon.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">30000</span>
<span class="n">REPETITIONS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">N_JOBS</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">REPETITIONS</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">]</span>
<span class="n">ENVIRONMENTS</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[</span><span class="n">Gaussian</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> <span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="n">means</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">SMPyBandits.Policies</span> <span class="k">import</span> <span class="n">EmpiricalMeans</span><span class="p">,</span> <span class="n">UCB</span><span class="p">,</span> <span class="n">Thompson</span><span class="p">,</span> <span class="n">klUCB</span>
<span class="kn">from</span> <span class="nn">SMPyBandits.Policies</span> <span class="k">import</span> <span class="n">klucb_mapping</span><span class="p">,</span> <span class="n">klucbGauss</span> <span class="k">as</span> <span class="n">_klucbGauss</span>

<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="c1"># Custom klucb function</span>
<span class="k">def</span> <span class="nf">klucbGauss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;klucbGauss(x, d, sig2) with the good variance (= sigma).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_klucbGauss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

<span class="n">klucb</span> <span class="o">=</span> <span class="n">klucbGauss</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">POLICIES</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># --- Naive algorithms</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">EmpiricalMeans</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- Our algorithm, with two Unsupervised Learning algorithms</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UnsupervisedLearning</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">KernelDensity</span><span class="p">,</span>
                <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                <span class="s2">&quot;bandwidth&quot;</span><span class="p">:</span> <span class="n">sigma</span><span class="p">,</span>
                <span class="s2">&quot;T_0&quot;</span><span class="p">:</span> <span class="n">T_0</span><span class="p">,</span>
                <span class="s2">&quot;fit_every&quot;</span><span class="p">:</span> <span class="n">fit_every</span><span class="p">,</span>
                <span class="s2">&quot;meanOf&quot;</span><span class="p">:</span> <span class="n">meanOf</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UnsupervisedLearning</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">SimpleGaussianKernel</span><span class="p">,</span>
                <span class="s2">&quot;T_0&quot;</span><span class="p">:</span> <span class="n">T_0</span><span class="p">,</span>
                <span class="s2">&quot;fit_every&quot;</span><span class="p">:</span> <span class="n">fit_every</span><span class="p">,</span>
                <span class="s2">&quot;meanOf&quot;</span><span class="p">:</span> <span class="n">meanOf</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="c1"># --- Basic UCB1 algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UCB</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- Thompson sampling algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">Thompson</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- klUCB algorithm, with Gaussian klucb function</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">klUCB</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;klucb&quot;</span><span class="p">:</span> <span class="n">klucb</span>
            <span class="p">}</span>
        <span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># --- Duration of the experiment</span>
    <span class="s2">&quot;horizon&quot;</span><span class="p">:</span> <span class="n">HORIZON</span><span class="p">,</span>
    <span class="c1"># --- Number of repetition of the experiment (to have an average)</span>
    <span class="s2">&quot;repetitions&quot;</span><span class="p">:</span> <span class="n">REPETITIONS</span><span class="p">,</span>
    <span class="c1"># --- Parameters for the use of joblib.Parallel</span>
    <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="n">N_JOBS</span><span class="p">,</span>    <span class="c1"># = nb of CPU cores</span>
    <span class="s2">&quot;verbosity&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>      <span class="c1"># Max joblib verbosity</span>
    <span class="c1"># --- Arms</span>
    <span class="s2">&quot;environment&quot;</span><span class="p">:</span> <span class="n">ENVIRONMENTS</span><span class="p">,</span>
    <span class="c1"># --- Algorithms</span>
    <span class="s2">&quot;policies&quot;</span><span class="p">:</span> <span class="n">POLICIES</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of policies in this comparison: 6
Time horizon: 30000
Number of repetitions: 100
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 50
Number of jobs for parallelization: 4
Creating a new MAB problem ...
  Taking arms of this MAB problem from a list of arms &#39;configuration&#39; = [G(0.45, 0.2), G(0.5, 0.2), G(0.55, 0.2)] ...
 - with &#39;arms&#39; = [G(0.45, 0.2), G(0.5, 0.2), G(0.55, 0.2)]
 - with &#39;means&#39; = [ 0.45  0.5   0.55]
 - with &#39;nbArms&#39; = 3
 - with &#39;maxArm&#39; = 0.55
 - with &#39;minArm&#39; = 0.45

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 12 ...
 - a Optimal Arm Identification factor H_OI(mu) = 61.67% ...
 - with &#39;arms&#39; represented as: $[G(0.45, 0.2), G(0.5, 0.2), G(0.55, 0.2)^*]$
Number of environments to try: 1
</pre></div></div>
</div>
</div>
<div class="section" id="Running-an-experiment">
<h3>Running an experiment<a class="headerlink" href="#Running-an-experiment" title="Permalink to this headline">¶</a></h3>
<p>We asked to repeat the experiment <span class="math notranslate nohighlight">\(100\)</span> times, so it will take a while… (about 10 minutes maximum).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">SMPyBandits.Environment</span> <span class="k">import</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="k">for</span> <span class="n">envId</span><span class="p">,</span> <span class="n">env</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">envs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Problems&quot;</span><span class="p">):</span>
    <span class="c1"># Evaluate just that env</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">startOneEnv</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a3c0a416295d45aa8030295cc88c2c41"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Evaluating environment: MAB(nbArms: 3, arms: [G(0.45, 0.2), G(0.5, 0.2), G(0.55, 0.2)], minArm: 0.45, maxArm: 0.55)
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;bandwidth&#39;: 0.2, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100, &#39;kernel&#39;: &#39;gaussian&#39;, &#39;estimator&#39;: &lt;class &#39;sklearn.neighbors.kde.KernelDensity&#39;&gt;, &#39;fit_every&#39;: 1000}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;bandwidth&#39;: 0.2, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100, &#39;kernel&#39;: &#39;gaussian&#39;, &#39;estimator&#39;: &lt;class &#39;sklearn.neighbors.kde.KernelDensity&#39;&gt;, &#39;fit_every&#39;: 1000}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;estimator&#39;: &lt;class &#39;__main__.SimpleGaussianKernel&#39;&gt;, &#39;fit_every&#39;: 1000, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;estimator&#39;: &lt;class &#39;__main__.SimpleGaussianKernel&#39;&gt;, &#39;fit_every&#39;: 1000, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100}} ...
- Adding policy #4 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][3]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #5 = {&#39;archtype&#39;: &lt;class &#39;Policies.Thompson.Thompson&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][4]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.Thompson.Thompson&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #6 = {&#39;archtype&#39;: &lt;class &#39;Policies.klUCB.klUCB&#39;&gt;, &#39;params&#39;: {&#39;klucb&#39;: &lt;function klucbGauss at 0x7f835bfd9488&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][5]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.klUCB.klUCB&#39;&gt;, &#39;params&#39;: {&#39;klucb&#39;: &lt;function klucbGauss at 0x7f835bfd9488&gt;}} ...

- Evaluating policy #1/6: EmpiricalMeans ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "60f33e1935ad4dddb37d0af3576fcc0d"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy EmpiricalMeans after 30000 steps: [1 0 2] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 39.85% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 33.33% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 48.85% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.4s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   13.7s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #2/6: UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   30.9s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "74305e3723fd42b9b1f87ab56fa94c52"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$) after 30000 steps: [0 1 2] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 88.28% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Mean distance from optimal ordering: 97.07% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   20.7s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.8min
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #3/6: UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  4.2min finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "382e9b608f044c1ab27ffcafa2077096"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$) after 30000 steps: [0 1 2] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 88.28% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Mean distance from optimal ordering: 97.07% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    8.5s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   50.7s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #4/6: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.9min finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "4403217ad6d646cc9d996a8243d0c83d"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB after 30000 steps: [1 0 2] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 39.85% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 33.33% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 48.85% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.9s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.1s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   36.9s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #5/6: Thompson ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "dfbcc922c76b46e293777b6910ca0a37"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy Thompson after 30000 steps: [0 1 2] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 88.28% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Mean distance from optimal ordering: 97.07% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.6s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   14.8s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #6/6: KL-UCB(Gauss) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   37.2s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "8daabe1eb8c640dfa41a172514c3029c"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy KL-UCB(Gauss) after 30000 steps: [0 1 2] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 88.28% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Mean distance from optimal ordering: 97.07% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    8.7s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   42.2s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

CPU times: user 2.66 s, sys: 588 ms, total: 3.25 s
Wall time: 9min 25s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.5min finished
</pre></div></div>
</div>
</div>
<div class="section" id="Visualizing-the-results">
<h3>Visualizing the results<a class="headerlink" href="#Visualizing-the-results" title="Permalink to this headline">¶</a></h3>
<p>Now, we can plot some performance measures, like the regret, the best arm selection rate, the average reward etc.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="n">envId</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">printFinalRanking</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">semilogx</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">meanRegret</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotBestArmPulls</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>evaluation<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Type:</span>        Evaluator
<span class="ansi-red-fg">String form:</span> &lt;Environment.Evaluator.Evaluator object at 0x7f8357929978&gt;
<span class="ansi-red-fg">File:</span>        ~/ownCloud/cloud.openmailbox.org/Thèse_2016-17/src/SMPyBandits.git/Environment/Evaluator.py
<span class="ansi-red-fg">Docstring:</span>   Evaluator class to run the simulations.

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[63]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #0 :
- Policy &#39;UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$)&#39;  was ranked      1 / 6 for this simulation (last regret = 42.8587).
- Policy &#39;Thompson&#39;     was ranked      2 / 6 for this simulation (last regret = 79.6796).
- Policy &#39;UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$)&#39; was ranked      3 / 6 for this simulation (last regret = 94.4365).
- Policy &#39;KL-UCB(Gauss)&#39;        was ranked      4 / 6 for this simulation (last regret = 101.951).
- Policy &#39;UCB&#39;  was ranked      5 / 6 for this simulation (last regret = 312.357).
- Policy &#39;EmpiricalMeans&#39;       was ranked      6 / 6 for this simulation (last regret = 723.75).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 12 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 61.67% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_1.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 12 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 61.67% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_3.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 12 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 61.67% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_5.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_6.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_81_6.png" />
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Another-experiment,-with-just-more-Gaussian-arms">
<h2>Another experiment, with just more Gaussian arms<a class="headerlink" href="#Another-experiment,-with-just-more-Gaussian-arms" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[89]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">30000</span>
<span class="n">REPETITIONS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">N_JOBS</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">REPETITIONS</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.30</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.40</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.60</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">]</span>
<span class="n">ENVIRONMENTS</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[</span><span class="n">Gaussian</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span> <span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="n">means</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[90]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">POLICIES</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># --- Our algorithm, with two Unsupervised Learning algorithms</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UnsupervisedLearning</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">KernelDensity</span><span class="p">,</span>
                <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                <span class="s2">&quot;bandwidth&quot;</span><span class="p">:</span> <span class="n">sigma</span><span class="p">,</span>
                <span class="s2">&quot;T_0&quot;</span><span class="p">:</span> <span class="n">T_0</span><span class="p">,</span>
                <span class="s2">&quot;fit_every&quot;</span><span class="p">:</span> <span class="n">fit_every</span><span class="p">,</span>
                <span class="s2">&quot;meanOf&quot;</span><span class="p">:</span> <span class="n">meanOf</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UnsupervisedLearning</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">SimpleGaussianKernel</span><span class="p">,</span>
                <span class="s2">&quot;T_0&quot;</span><span class="p">:</span> <span class="n">T_0</span><span class="p">,</span>
                <span class="s2">&quot;fit_every&quot;</span><span class="p">:</span> <span class="n">fit_every</span><span class="p">,</span>
                <span class="s2">&quot;meanOf&quot;</span><span class="p">:</span> <span class="n">meanOf</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="c1"># --- Basic UCB1 algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UCB</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- Thompson sampling algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">Thompson</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- klUCB algorithm, with Gaussian klucb function</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">klUCB</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;klucb&quot;</span><span class="p">:</span> <span class="n">klucb</span>
            <span class="p">}</span>
        <span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[91]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># --- Duration of the experiment</span>
    <span class="s2">&quot;horizon&quot;</span><span class="p">:</span> <span class="n">HORIZON</span><span class="p">,</span>
    <span class="c1"># --- Number of repetition of the experiment (to have an average)</span>
    <span class="s2">&quot;repetitions&quot;</span><span class="p">:</span> <span class="n">REPETITIONS</span><span class="p">,</span>
    <span class="c1"># --- Parameters for the use of joblib.Parallel</span>
    <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="n">N_JOBS</span><span class="p">,</span>    <span class="c1"># = nb of CPU cores</span>
    <span class="s2">&quot;verbosity&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>      <span class="c1"># Max joblib verbosity</span>
    <span class="c1"># --- Arms</span>
    <span class="s2">&quot;environment&quot;</span><span class="p">:</span> <span class="n">ENVIRONMENTS</span><span class="p">,</span>
    <span class="c1"># --- Algorithms</span>
    <span class="s2">&quot;policies&quot;</span><span class="p">:</span> <span class="n">POLICIES</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[92]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation2</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of policies in this comparison: 5
Time horizon: 30000
Number of repetitions: 100
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 50
Number of jobs for parallelization: 4
Creating a new MAB problem ...
  Taking arms of this MAB problem from a list of arms &#39;configuration&#39; = [G(0.3, 0.25), G(0.35, 0.25), G(0.4, 0.25), G(0.45, 0.25), G(0.5, 0.25), G(0.55, 0.25), G(0.6, 0.25), G(0.65, 0.25), G(0.7, 0.25)] ...
 - with &#39;arms&#39; = [G(0.3, 0.25), G(0.35, 0.25), G(0.4, 0.25), G(0.45, 0.25), G(0.5, 0.25), G(0.55, 0.25), G(0.6, 0.25), G(0.65, 0.25), G(0.7, 0.25)]
 - with &#39;means&#39; = [ 0.3   0.35  0.4   0.45  0.5   0.55  0.6   0.65  0.7 ]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.7
 - with &#39;minArm&#39; = 0.3

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 27.2 ...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
 - with &#39;arms&#39; represented as: $[G(0.3, 0.25), G(0.35, 0.25), G(0.4, 0.25), G(0.45, 0.25), G(0.5, 0.25), G(0.55, 0.25), G(0.6, 0.25), G(0.65,$
$0.25), G(0.7, 0.25)^*]$
Number of environments to try: 1
</pre></div></div>
</div>
<div class="section" id="Running-the-experiment">
<h3>Running the experiment<a class="headerlink" href="#Running-the-experiment" title="Permalink to this headline">¶</a></h3>
<p>We asked to repeat the experiment <span class="math notranslate nohighlight">\(100\)</span> times, so it will take a while…</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[93]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="k">for</span> <span class="n">envId</span><span class="p">,</span> <span class="n">env</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">evaluation2</span><span class="o">.</span><span class="n">envs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Problems&quot;</span><span class="p">):</span>
    <span class="c1"># Evaluate just that env</span>
    <span class="n">evaluation2</span><span class="o">.</span><span class="n">startOneEnv</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2f7efddfcb814e7fafc93b55aa15da84"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Evaluating environment: MAB(nbArms: 9, arms: [G(0.3, 0.25), G(0.35, 0.25), G(0.4, 0.25), G(0.45, 0.25), G(0.5, 0.25), G(0.55, 0.25), G(0.6, 0.25), G(0.65, 0.25), G(0.7, 0.25)], minArm: 0.3, maxArm: 0.7)
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;bandwidth&#39;: 0.2, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100, &#39;kernel&#39;: &#39;gaussian&#39;, &#39;estimator&#39;: &lt;class &#39;sklearn.neighbors.kde.KernelDensity&#39;&gt;, &#39;fit_every&#39;: 1000}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;bandwidth&#39;: 0.2, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100, &#39;kernel&#39;: &#39;gaussian&#39;, &#39;estimator&#39;: &lt;class &#39;sklearn.neighbors.kde.KernelDensity&#39;&gt;, &#39;fit_every&#39;: 1000}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;estimator&#39;: &lt;class &#39;__main__.SimpleGaussianKernel&#39;&gt;, &#39;fit_every&#39;: 1000, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;estimator&#39;: &lt;class &#39;__main__.SimpleGaussianKernel&#39;&gt;, &#39;fit_every&#39;: 1000, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #4 = {&#39;archtype&#39;: &lt;class &#39;Policies.Thompson.Thompson&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][3]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.Thompson.Thompson&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #5 = {&#39;archtype&#39;: &lt;class &#39;Policies.klUCB.klUCB&#39;&gt;, &#39;params&#39;: {&#39;klucb&#39;: &lt;function klucbGauss at 0x7f835bfd9488&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][4]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.klUCB.klUCB&#39;&gt;, &#39;params&#39;: {&#39;klucb&#39;: &lt;function klucbGauss at 0x7f835bfd9488&gt;}} ...

- Evaluating policy #1/5: UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "6d1e0fc2626041cd9b8f8f16d279c7e2"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$) after 30000 steps: [0 1 2 3 4 5 6 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 99.98% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Mean distance from optimal ordering: 100.00% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   48.7s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  4.3min
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #2/5: UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  9.8min finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "fbac51d39cf5448f919e0ad86e941b35"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$) after 30000 steps: [0 2 1 3 4 6 5 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 90.12% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 99.92% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==&gt; Mean distance from optimal ordering: 91.95% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   19.8s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.9min
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #3/5: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed: 477.2min finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "eebe982feb414415b31989e59d5a21e1"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB after 30000 steps: [0 2 6 5 4 1 7 3 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 60.49% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 85.56% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 87.50% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Mean distance from optimal ordering: 72.28% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.9s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   16.1s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   38.7s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #4/5: Thompson ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "53b9309a7aad49dfbdd50b7165835fec"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy Thompson after 30000 steps: [2 0 4 3 1 5 6 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 99.33% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 99.63% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 86.47% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    4.1s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   22.4s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   52.8s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #5/5: KL-UCB(Gauss) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "95a3986261784e56b0e00e58bbc1f71a"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy KL-UCB(Gauss) after 30000 steps: [0 2 3 1 5 7 6 4 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 75.31% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 99.47% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 85.05% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    7.2s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   40.4s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

CPU times: user 2.56 s, sys: 656 ms, total: 3.22 s
Wall time: 8h 10min 4s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.6min finished
</pre></div></div>
</div>
</div>
<div class="section" id="Visualizing-the-results">
<h3>Visualizing the results<a class="headerlink" href="#Visualizing-the-results" title="Permalink to this headline">¶</a></h3>
<p>Now, we can plot some performance measures, like the regret, the best arm selection rate, the average reward etc.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[94]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #0 :
- Policy &#39;Thompson&#39;     was ranked      1 / 5 for this simulation (last regret = 541.01).
- Policy &#39;KL-UCB(Gauss)&#39;        was ranked      2 / 5 for this simulation (last regret = 599.75).
- Policy &#39;UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$)&#39;  was ranked      3 / 5 for this simulation (last regret = 612.761).
- Policy &#39;UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$)&#39; was ranked      4 / 5 for this simulation (last regret = 674.086).
- Policy &#39;UCB&#39;  was ranked      5 / 5 for this simulation (last regret = 1111.22).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 27.2 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_1.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 27.2 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_3.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 27.2 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_5.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_6.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_90_6.png" />
</div>
</div>
</div>
<div class="section" id="Very-good-performance!">
<h3>Very good performance!<a class="headerlink" href="#Very-good-performance!" title="Permalink to this headline">¶</a></h3>
<p>Whoo, on this last experiment, the simple <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning(SimpleGaussianKernel)</span></code> works as well as Thompson Sampling (<code class="docutils literal notranslate"><span class="pre">Thompson</span></code>) !!</p>
<p>… In fact, it was almost obvious : Thompson Sampling uses a Gamma posterior, while <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning(SimpleGaussianKernel)</span></code> works very similarly to Thompson Sampling (start with a flat kernel, fit it to the data, and to take decision, sample it and play the arm with the highest sample). <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning(SimpleGaussianKernel)</span></code> basically uses a Gaussian posterior, which is obviously better than a Gamma posterior for Gaussian arms!</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Another-experiment,-with-Bernoulli-arms">
<h2>Another experiment, with Bernoulli arms<a class="headerlink" href="#Another-experiment,-with-Bernoulli-arms" title="Permalink to this headline">¶</a></h2>
<p>Let also try the same algorithms but on Bernoulli arms.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[95]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">SMPyBandits.Arms</span> <span class="k">import</span> <span class="n">Bernoulli</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[96]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">30000</span>
<span class="n">REPETITIONS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">N_JOBS</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">REPETITIONS</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">means</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.30</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.40</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.60</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">]</span>
<span class="n">ENVIRONMENTS</span> <span class="o">=</span> <span class="p">[</span> <span class="p">[</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="n">means</span><span class="p">]</span> <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[97]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">POLICIES</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># --- Our algorithm, with two Unsupervised Learning algorithms</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UnsupervisedLearning</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">KernelDensity</span><span class="p">,</span>
                <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="s1">&#39;gaussian&#39;</span><span class="p">,</span>
                <span class="s2">&quot;bandwidth&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
                <span class="s2">&quot;T_0&quot;</span><span class="p">:</span> <span class="n">T_0</span><span class="p">,</span>
                <span class="s2">&quot;fit_every&quot;</span><span class="p">:</span> <span class="n">fit_every</span><span class="p">,</span>
                <span class="s2">&quot;meanOf&quot;</span><span class="p">:</span> <span class="n">meanOf</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UnsupervisedLearning</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">SimpleGaussianKernel</span><span class="p">,</span>
                <span class="s2">&quot;T_0&quot;</span><span class="p">:</span> <span class="n">T_0</span><span class="p">,</span>
                <span class="s2">&quot;fit_every&quot;</span><span class="p">:</span> <span class="n">fit_every</span><span class="p">,</span>
                <span class="s2">&quot;meanOf&quot;</span><span class="p">:</span> <span class="n">meanOf</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="c1"># --- Basic UCB1 algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UCB</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- Thompson sampling algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">Thompson</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[98]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># --- Duration of the experiment</span>
    <span class="s2">&quot;horizon&quot;</span><span class="p">:</span> <span class="n">HORIZON</span><span class="p">,</span>
    <span class="c1"># --- Number of repetition of the experiment (to have an average)</span>
    <span class="s2">&quot;repetitions&quot;</span><span class="p">:</span> <span class="n">REPETITIONS</span><span class="p">,</span>
    <span class="c1"># --- Parameters for the use of joblib.Parallel</span>
    <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="n">N_JOBS</span><span class="p">,</span>    <span class="c1"># = nb of CPU cores</span>
    <span class="s2">&quot;verbosity&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>      <span class="c1"># Max joblib verbosity</span>
    <span class="c1"># --- Arms</span>
    <span class="s2">&quot;environment&quot;</span><span class="p">:</span> <span class="n">ENVIRONMENTS</span><span class="p">,</span>
    <span class="c1"># --- Algorithms</span>
    <span class="s2">&quot;policies&quot;</span><span class="p">:</span> <span class="n">POLICIES</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[99]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation3</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of policies in this comparison: 4
Time horizon: 30000
Number of repetitions: 100
Sampling rate for saving, delta_t_save: 1
Sampling rate for plotting, delta_t_plot: 50
Number of jobs for parallelization: 4
Creating a new MAB problem ...
  Taking arms of this MAB problem from a list of arms &#39;configuration&#39; = [B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.65), B(0.7)] ...
 - with &#39;arms&#39; = [B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.65), B(0.7)]
 - with &#39;means&#39; = [ 0.3   0.35  0.4   0.45  0.5   0.55  0.6   0.65  0.7 ]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.7
 - with &#39;minArm&#39; = 0.3

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 24.3 ...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
 - with &#39;arms&#39; represented as: $[B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.65), B(0.7)^*]$
Number of environments to try: 1
</pre></div></div>
</div>
<div class="section" id="Running-the-experiment">
<h3>Running the experiment<a class="headerlink" href="#Running-the-experiment" title="Permalink to this headline">¶</a></h3>
<p>We asked to repeat the experiment <span class="math notranslate nohighlight">\(100\)</span> times, so it will take a while…</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[100]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%time</span>
<span class="k">for</span> <span class="n">envId</span><span class="p">,</span> <span class="n">env</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">evaluation3</span><span class="o">.</span><span class="n">envs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Problems&quot;</span><span class="p">):</span>
    <span class="c1"># Evaluate just that env</span>
    <span class="n">evaluation3</span><span class="o">.</span><span class="n">startOneEnv</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a0c35e66cb834d4a80b33ac3da1965c0"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Evaluating environment: MAB(nbArms: 9, arms: [B(0.3), B(0.35), B(0.4), B(0.45), B(0.5), B(0.55), B(0.6), B(0.65), B(0.7)], minArm: 0.3, maxArm: 0.7)
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;bandwidth&#39;: 0.1, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100, &#39;kernel&#39;: &#39;gaussian&#39;, &#39;estimator&#39;: &lt;class &#39;sklearn.neighbors.kde.KernelDensity&#39;&gt;, &#39;fit_every&#39;: 1000}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;bandwidth&#39;: 0.1, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100, &#39;kernel&#39;: &#39;gaussian&#39;, &#39;estimator&#39;: &lt;class &#39;sklearn.neighbors.kde.KernelDensity&#39;&gt;, &#39;fit_every&#39;: 1000}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;estimator&#39;: &lt;class &#39;__main__.SimpleGaussianKernel&#39;&gt;, &#39;fit_every&#39;: 1000, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.UnsupervisedLearning&#39;&gt;, &#39;params&#39;: {&#39;estimator&#39;: &lt;class &#39;__main__.SimpleGaussianKernel&#39;&gt;, &#39;fit_every&#39;: 1000, &#39;meanOf&#39;: 200, &#39;T_0&#39;: 100}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #4 = {&#39;archtype&#39;: &lt;class &#39;Policies.Thompson.Thompson&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][3]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.Thompson.Thompson&#39;&gt;, &#39;params&#39;: {}} ...

- Evaluating policy #1/4: UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a2305c72ac9b41ec99ac45d9e0c572e5"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$) after 30000 steps: [0 2 1 3 4 5 6 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 95.06% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 99.96% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 88.89% (relative success)...
  ==&gt; Mean distance from optimal ordering: 95.98% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   59.6s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  5.4min
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #2/4: UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed: 12.4min finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "864325dc89314d9d8dc04ef814ec0040"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$) after 30000 steps: [0 2 3 1 4 5 6 7 8] ...  ==&gt; Kendell Tau distance from optimal ordering: 99.92% (relative success)...

  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 90.12% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 99.99% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 88.89% (relative success)...
  ==&gt; Mean distance from optimal ordering: 94.73% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   20.4s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  2.0min
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #3/4: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  4.6min finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "eda2ab6dc05d4ac7bb91fecc40409aa2"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB after 30000 steps: [0 4 2 3 1 6 5 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 99.47% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 86.29% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.7s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   15.6s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   35.9s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #4/4: Thompson ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e1bc5793b95e4295a5c809959d13482b"}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy Thompson after 30000 steps: [2 4 0 3 1 5 6 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 75.31% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 98.75% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 84.87% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    3.5s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   20.3s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   48.7s finished
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

CPU times: user 2.21 s, sys: 584 ms, total: 2.79 s
Wall time: 18min 25s
</pre></div></div>
</div>
</div>
<div class="section" id="Visualizing-the-results">
<h3>Visualizing the results<a class="headerlink" href="#Visualizing-the-results" title="Permalink to this headline">¶</a></h3>
<p>Now, we can plot some performance measures, like the regret, the best arm selection rate, the average reward etc.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[101]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #0 :
- Policy &#39;Thompson&#39;     was ranked      1 / 4 for this simulation (last regret = 117.25).
- Policy &#39;UnsupervisedLearning(SimpleGaussianKernel, $T_0=100$, $T_1=1e+03$, $M=200$)&#39;  was ranked      2 / 4 for this simulation (last regret = 425.23).
- Policy &#39;UnsupervisedLearning(KernelDensity, $T_0=100$, $T_1=1e+03$, $M=200$)&#39; was ranked      3 / 4 for this simulation (last regret = 441.91).
- Policy &#39;UCB&#39;  was ranked      4 / 4 for this simulation (last regret = 661.27).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 24.3 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_1.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 24.3 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_3.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 24.3 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 68.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_5.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_6.png" src="../_images/notebooks_Unsupervised_Learning_for_Bandit_problem_101_6.png" />
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¶</a></h2>
<p>This small simulation shows that with the appropriate tweaking of parameters, and on reasonably easy Gaussian Multi-Armed Bandit problems, one can use a <strong>Unsupervised Learning</strong> learning algorithm, being a <strong>non on-line</strong> algorithm (i.e., updating it at time step <span class="math notranslate nohighlight">\(t\)</span> has a time complexity about <span class="math notranslate nohighlight">\(\mathcal{O}(K t)\)</span> instead of <span class="math notranslate nohighlight">\(\mathcal{O}(K)\)</span>).</p>
<p>By tweaking cleverly the algorithm, mainly without refitting the model at every steps (e.g., but once every <span class="math notranslate nohighlight">\(T_1 = 1000\)</span> steps), it works as well as the best-possible algorithm, here we compared against <code class="docutils literal notranslate"><span class="pre">Thompson</span></code> (Thompson Sampling) and <code class="docutils literal notranslate"><span class="pre">klUCB</span></code> (kl-UCB with Gaussian <span class="math notranslate nohighlight">\(\mathrm{KL}(x,y)\)</span> function).</p>
<p>When comparing in terms of mean rewards, accumulated rewards, best-arm selection, and regret (loss against the best fixed-arm policy), this <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning(KernelDensity,</span> <span class="pre">...)</span></code> algorithm performs as well as the others.</p>
<div class="section" id="Non-logarithmic-regret">
<h3>Non-logarithmic regret<a class="headerlink" href="#Non-logarithmic-regret" title="Permalink to this headline">¶</a></h3>
<p>But in terms of regret, it seems that the profile for <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning(KernelDensity,</span> <span class="pre">...)</span></code> is <strong>not</strong> <em>asymptotically logarithmic</em>, contrarily to <code class="docutils literal notranslate"><span class="pre">Thompson</span></code> and <code class="docutils literal notranslate"><span class="pre">klUCB</span></code> (<em>cf.</em> see the first curve above, at the end on the right).</p>
<ul class="simple">
<li>Note that the horizon is not that large, <span class="math notranslate nohighlight">\(T = 30000\)</span> is not very long.</li>
<li>And note that the four parameters, <span class="math notranslate nohighlight">\(T_0, T_1, M\)</span> for the <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning</span></code> part, and <span class="math notranslate nohighlight">\(\mathrm{bandwidth}\)</span> for the <code class="docutils literal notranslate"><span class="pre">KernelDensity</span></code> part, have all been (manually) <em>tweaked</em> for this setting. For instance, <span class="math notranslate nohighlight">\(\mathrm{bandwidth} = \sigma = 0.2\)</span> is the same as the one used for the arms (but in a real-world scenario, this would be unknown), <span class="math notranslate nohighlight">\(T_0,T_1\)</span> is adapted to <span class="math notranslate nohighlight">\(T\)</span>, and <span class="math notranslate nohighlight">\(M\)</span> is adapted to <span class="math notranslate nohighlight">\(\sigma\)</span> also (to reduce variance of the samples for the
models).</li>
</ul>
</div>
<div class="section" id="Comparing-time-complexity">
<h3>Comparing <em>time complexity</em><a class="headerlink" href="#Comparing-time-complexity" title="Permalink to this headline">¶</a></h3>
<p>Another aspect is the <em>time complexity</em> of the <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning(KernelDensity,</span> <span class="pre">...)</span></code> algorithm. In the simulation above, we saw that it took about <span class="math notranslate nohighlight">\(42\;\mathrm{min}\)</span> to do <span class="math notranslate nohighlight">\(1000\)</span> experiments of horizon <span class="math notranslate nohighlight">\(T = 30000\)</span> (about <span class="math notranslate nohighlight">\(8.4 10^{-5} \; \mathrm{s}\)</span> by time step), against <span class="math notranslate nohighlight">\(5.5\;\mathrm{min}\)</span> for Thompson Sampling : even with fitting the unsupervised learning model only <em>once every :math:`T_1 = 1000` steps</em>, it is still about <span class="math notranslate nohighlight">\(8\)</span> times slower than
Thompson Sampling or UCB !</p>
<p>It is not that much, but still…</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[102]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">time_by_loop_UL_KD</span> <span class="o">=</span> <span class="p">(</span><span class="mi">42</span> <span class="o">*</span> <span class="mf">60.</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">REPETITIONS</span> <span class="o">*</span> <span class="n">HORIZON</span><span class="p">)</span>
<span class="n">time_by_loop_UL_KD</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[102]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.00084
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[103]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">time_by_loop_TS</span> <span class="o">=</span> <span class="p">(</span><span class="mf">5.5</span> <span class="o">*</span> <span class="mf">60.</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">REPETITIONS</span> <span class="o">*</span> <span class="n">HORIZON</span><span class="p">)</span>
<span class="n">time_by_loop_TS</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[103]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>0.00011
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[104]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="mi">42</span> <span class="o">/</span> <span class="mf">5.5</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[104]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>7.636363636363637
</pre></div>
</div>
</div>
</div>
<div class="section" id="Not-so-efficient-for-Bernoulli-arms">
<h3>Not so efficient for Bernoulli arms<a class="headerlink" href="#Not-so-efficient-for-Bernoulli-arms" title="Permalink to this headline">¶</a></h3>
<p>Similarly, the last experiment showed that this <code class="docutils literal notranslate"><span class="pre">UnsupervisedLearning</span></code> policy was not so efficient on Bernoulli problems, with a Gaussian kernel.</p>
<p>A better approach could have been to use a Bernoulli “kernel”, i.e., fitting a Bernoulli distribution on each arm.</p>
<blockquote>
<div>I implemented this for my framework, see <cite>here the documentation for ``SimpleBernoulliKernel`</cite> &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Policies.UnsupervisedLearning.html#Policies.UnsupervisedLearning.SimpleBernoulliKernel">https://smpybandits.github.io/docs/Policies.UnsupervisedLearning.html#Policies.UnsupervisedLearning.SimpleBernoulliKernel</a>&gt;`__, but I will not present it here.</div></blockquote>
<hr class="docutils" />
<p>This notebook is here to illustrate my <a class="reference external" href="https://smpybandits.github.io/">SMPyBandits</a> library, for which a complete documentation is available, <a class="reference external" href="https://smpybandits.github.io/">here at https://smpybandits.github.io/</a>.</p>
<blockquote>
<div>That’s it for this demo! See you, folks!</div></blockquote>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html" class="btn btn-neutral float-right" title="Table of Contents" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html" class="btn btn-neutral float-left" title="Table of Contents" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2018, Lilian Besson (Naereen)
      <span class="lastupdated">
        Last updated on 26 Mar 2019, 16h.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>