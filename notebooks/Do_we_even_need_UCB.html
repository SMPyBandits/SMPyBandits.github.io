

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <script type="text/javascript">

            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-38514290-2']);
            _gaq.push(['_trackPageview']);

            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
            </script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Table of Contents &mdash; SMPyBandits 0.9.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="SMPyBandits 0.9.2 documentation" href="../index.html"/>
        <link rel="up" title="List of notebooks for SMPyBandits documentation" href="list.html"/>
        <link rel="next" title="Table of Contents" href="Example_of_a_small_Single-Player_Simulation.html"/>
        <link rel="prev" title="Table of Contents" href="Easily_creating_MAB_problems.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> SMPyBandits
          

          
            
            <img src="../_static/logo.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html"><em>SMPyBandits</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/modules.html">SMPyBandits modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../How_to_run_the_code.html">How to run the code ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PublicationsWithSMPyBandits.html">List of research publications using Lilian Besson&#8217;s SMPyBandits project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Aggregation.html"><strong>Policy aggregation algorithms</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../MultiPlayers.html"><strong>Multi-players simulation environment</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../DoublingTrick.html"><strong>Doubling Trick for Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../API.html">Short documentation of the API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TODO.html">üí• TODO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plots/README.html">Some illustrations for this project</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">Jupyter Notebooks üìì by Naereen &#64; GitHub</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="list.html">List of notebooks for SMPyBandits documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html#Easily-creating-MAB-problems">Easily creating MAB problems</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?"><em>Do we even need a smart learning algorithm? Is UCB useless?</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Notations-for-the-arms">Notations for the arms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Importing-the-algorithms">Importing the algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-UCB-algorithm">The <code class="docutils literal"><span class="pre">UCB</span></code> algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-EmpiricalMeans-algorithm">The <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Creating-some-MAB-problems">Creating some MAB problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Parameters-for-the-simulation">Parameters for the simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Some-MAB-problem-with-Bernoulli-arms">Some MAB problem with Bernoulli arms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Some-RL-algorithms">Some RL algorithms</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Creating-the-Evaluator-object">Creating the <code class="docutils literal"><span class="pre">Evaluator</span></code> object</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Solving-the-problem">Solving the problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Plotting-the-results">Plotting the results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#First-problem">First problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Second-problem">Second problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Third-problem">Third problem</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html#An-example-of-a-small-Single-Player-simulation">An example of a small Single-Player simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-Centralized-Algorithms">An example of a small Multi-Player simulation, with Centralized Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-rhoRand-and-Selfish,-for-different-algorithms">An example of a small Multi-Player simulation, with rhoRand and Selfish, for different algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="Unsupervised_Learning_for_Bandit_problem.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Unsupervised_Learning_for_Bandit_problem.html#Trying-to-use-Unsupervised-Learning-algorithms-for-a-Gaussian-bandit-problem">Trying to use Unsupervised Learning algorithms for a Gaussian bandit problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html#Trying-to-use-Black-Box-Bayesian-optimization-algorithms-for-a-Gaussian-bandit-problem">Trying to use Black-Box Bayesian optimization algorithms for a Gaussian bandit problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.html#Lai-&amp;-Robbins-lower-bound-for-stochastic-bandit-with-full-restart-points">Lai &amp; Robbins lower-bound for stochastic bandit with full restart points</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Profiling.html">A note on execution times, speed and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uml_diagrams/README.html">UML diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logs/README.html"><code class="docutils literal"><span class="pre">logs/</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">On Github Issues and Pull Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SMPyBandits</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="list.html">List of notebooks for SMPyBandits documentation</a> &raquo;</li>
        
      <li>Table of Contents</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Do_we_even_need_UCB.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="Table-of-Contents">
<h1>Table of Contents<a class="headerlink" href="#Table-of-Contents" title="Permalink to this headline">¬∂</a></h1>
<p><div class="lev1 toc-item"><p>1&nbsp;&nbsp;Do we even need a smart learning algorithm? Is UCB useless?</p>
</div><div class="lev2 toc-item"><p>1.1&nbsp;&nbsp;Notations for the arms</p>
</div><div class="lev2 toc-item"><p>1.2&nbsp;&nbsp;Importing the algorithms</p>
</div><div class="lev2 toc-item"><p>1.3&nbsp;&nbsp;The UCB algorithm</p>
</div><div class="lev2 toc-item"><p>1.4&nbsp;&nbsp;The EmpiricalMeans algorithm</p>
</div><div class="lev2 toc-item"><p>1.5&nbsp;&nbsp;Creating some MAB problems</p>
</div><div class="lev3 toc-item"><p>1.5.1&nbsp;&nbsp;Parameters for the simulation</p>
</div><div class="lev3 toc-item"><p>1.5.2&nbsp;&nbsp;Some MAB problem with Bernoulli arms</p>
</div><div class="lev3 toc-item"><p>1.5.3&nbsp;&nbsp;Some RL algorithms</p>
</div><div class="lev2 toc-item"><p>1.6&nbsp;&nbsp;Creating the Evaluator object</p>
</div><div class="lev2 toc-item"><p>1.7&nbsp;&nbsp;Solving the problem</p>
</div><div class="lev2 toc-item"><p>1.8&nbsp;&nbsp;Plotting the results</p>
</div><div class="lev3 toc-item"><p>1.8.1&nbsp;&nbsp;First problem</p>
</div><div class="lev3 toc-item"><p>1.8.2&nbsp;&nbsp;Second problem</p>
</div><div class="lev3 toc-item"><p>1.8.3&nbsp;&nbsp;Third problem</p>
</div><div class="lev2 toc-item"><p>1.9&nbsp;&nbsp;Conclusion</p>
</div></div>
<div class="section" id="Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?">
<h1><em>Do we even need a smart learning algorithm? Is UCB useless?</em><a class="headerlink" href="#Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?" title="Permalink to this headline">¬∂</a></h1>
<p>This short notebook demonstrates that ‚Äúsmart‚Äù Multi-Armed Bandits
learning algorithms, like UCB, are indeed needed to learn the
distribution of arms, even in the simplest case.</p>
<p>We will use an example of a small Single-Player simulation, and compare
the <code class="docutils literal"><span class="pre">UCB</span></code> algorithm with a naive ‚Äúmax empirical reward‚Äù algorithm. The
goal is to illustrate that introducing an exploration term (the
confidence width), like what is done in UCB and similar algorithms,
really helps learning and improves performance.</p>
<hr class="docutils" />
<div class="section" id="Notations-for-the-arms">
<h2>Notations for the arms<a class="headerlink" href="#Notations-for-the-arms" title="Permalink to this headline">¬∂</a></h2>
<p>To remind the usual notations, there is a fixed number <span class="math">\(K \geq 1\)</span>
of levers, or ‚Äúarms‚Äù, and a player has to select one lever at each
discrete times <span class="math">\(t \geq 1, t \in \mathbb{N}\)</span>, ie <span class="math">\(k = A(t)\)</span>.
Selecting an arm <span class="math">\(k\)</span> at time <span class="math">\(t\)</span> will yield a (random)
<em>reward</em>, <span class="math">\(r_k(t)\)</span>, and the goal of the player is to maximize its
cumulative reward <span class="math">\(R_T = \sum_{t = 1}^T r_{A(t)}(t)\)</span>.</p>
<p>Each arm is associated with a distribution <span class="math">\(\nu_k\)</span>, for
<span class="math">\(k = 1,\dots,K\)</span>, and the usual restriction is to consider
one-dimensional exponential family (it includes Gaussian, Exponential
and Bernoulli distributions), ie distributions parametered by their
means, <span class="math">\(\mu_k\)</span>. So the arm <span class="math">\(k\)</span>, <span class="math">\(r_k(t) \sim \nu_k\)</span>,
are iid, and assumed bounded in <span class="math">\([a,b] = [0,1]\)</span>.</p>
<p>For instance, arms can follow Bernoulli distributions, of means
<span class="math">\(\mu_1,\dots,\mu_K \in [0,1]\)</span>:
<span class="math">\(r_k(t) \sim \mathrm{Bern}(\mu_k)\)</span>, ie
<span class="math">\(\mathbb{P}(r_k(t) = 1) = \mu_k\)</span>.</p>
<p>Let <span class="math">\(N_k(t) = \sum_{\tau=1}^t \mathbb{1}(A(t) = k)\)</span> be the number
of times arm <span class="math">\(k\)</span> was selected up-to time <span class="math">\(t \geq 1\)</span>. The
empirical mean of arm <span class="math">\(k\)</span> is then defined as
<span class="math">\(\hat{\mu_k}(t) := \frac{\sum_{\tau=1}^t \mathbb{1}(A(t) = k) r_k(t) }{N_k(t)}\)</span>.</p>
</div>
<hr class="docutils" />
<div class="section" id="Importing-the-algorithms">
<h2>Importing the algorithms<a class="headerlink" href="#Importing-the-algorithms" title="Permalink to this headline">¬∂</a></h2>
<p>First, be sure to be in the main folder, and import <code class="docutils literal"><span class="pre">Evaluator</span></code> from
<code class="docutils literal"><span class="pre">Environment</span></code> package:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sys</span> <span class="k">import</span> <span class="n">path</span>
<span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Local imports</span>
<span class="kn">from</span> <span class="nn">Environment</span> <span class="k">import</span> <span class="n">Evaluator</span><span class="p">,</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
<p>We also need arms, for instance <code class="docutils literal"><span class="pre">Bernoulli</span></code>-distributed arm:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Import arms</span>
<span class="kn">from</span> <span class="nn">Arms</span> <span class="k">import</span> <span class="n">Bernoulli</span>
</pre></div>
</div>
</div>
<p>And finally we need some single-player Reinforcement Learning
algorithms. I focus here on the <code class="docutils literal"><span class="pre">UCB</span></code> index policy, and the base class
<code class="docutils literal"><span class="pre">IndexPolicy</span></code> will be used to easily define another algorithm.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Import algorithms</span>
<span class="kn">from</span> <span class="nn">Policies</span> <span class="k">import</span> <span class="n">UCB</span><span class="p">,</span> <span class="n">UCBalpha</span>
<span class="kn">from</span> <span class="nn">Policies.IndexPolicy</span> <span class="k">import</span> <span class="n">IndexPolicy</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="The-UCB-algorithm">
<h2>The <code class="docutils literal"><span class="pre">UCB</span></code> algorithm<a class="headerlink" href="#The-UCB-algorithm" title="Permalink to this headline">¬∂</a></h2>
<p>First, we can check the documentation of the <code class="docutils literal"><span class="pre">UCB</span></code> class, implementing
the <strong>Upper-Confidence Bounds algorithm</strong>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Just improving the ?? in Jupyter. Thanks to https://nbviewer.jupyter.org/gist/minrk/7715212</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">IPython.core</span> <span class="k">import</span> <span class="n">page</span>
<span class="k">def</span> <span class="nf">myprint</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;text/plain&#39;</span><span class="p">])</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">KeyError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">page</span><span class="o">.</span><span class="n">page</span> <span class="o">=</span> <span class="n">myprint</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span>UCB<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> UCB<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>
The UCB policy for bounded bandits.
Reference: [Lai &amp; Robbins, 1985].
<span class="ansi-red-fg">Init docstring:</span>
New generic index policy.

- nbArms: the number of arms,
- lower, amplitude: lower value and known amplitude of the rewards.
<span class="ansi-red-fg">File:</span>           ~/SMPyBandits.git/Policies/UCB.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<p>Let us quickly have a look to the code of the <code class="docutils literal"><span class="pre">UCB</span></code> policy imported
above.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span>UCB<span class="o">??</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> UCB<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Source:</span>
<span class="ansi-green-fg">class</span> UCB<span class="ansi-blue-fg">(</span>IndexPolicy<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
    <span class="ansi-blue-fg">&#34;&#34;&#34; The UCB policy for bounded bandits.</span>
<span class="ansi-blue-fg">    Reference: [Lai &amp; Robbins, 1985].</span>
<span class="ansi-blue-fg">    &#34;&#34;&#34;</span>

    <span class="ansi-green-fg">def</span> computeIndex<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> arm<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        <span class="ansi-blue-fg">r&#34;&#34;&#34; Compute the current index, at time t and after :math:`N_k(t)` pulls of arm k:</span>

<span class="ansi-blue-fg">        .. math:: I_k(t) = \frac{X_k(t)}{N_k(t)} + \sqrt{\frac{2 \log(t)}{N_k(t)}}.</span>
<span class="ansi-blue-fg">        &#34;&#34;&#34;</span>
        <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>
            <span class="ansi-green-fg">return</span> float<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;+inf&#39;</span><span class="ansi-blue-fg">)</span>
        <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
            <span class="ansi-green-fg">return</span> <span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>rewards<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> sqrt<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span> <span class="ansi-blue-fg">*</span> log<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>t<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>

    <span class="ansi-green-fg">def</span> computeAllIndex<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        <span class="ansi-blue-fg">&#34;&#34;&#34; Compute the current indexes for all arms, in a vectorized manner.&#34;&#34;&#34;</span>
        indexes <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>rewards <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> np<span class="ansi-blue-fg">.</span>sqrt<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span> <span class="ansi-blue-fg">*</span> np<span class="ansi-blue-fg">.</span>log<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>t<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">)</span>
        indexes<span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>pulls <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> float<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;+inf&#39;</span><span class="ansi-blue-fg">)</span>
        self<span class="ansi-blue-fg">.</span>index <span class="ansi-blue-fg">=</span> indexes
<span class="ansi-red-fg">File:</span>           ~/SMPyBandits.git/Policies/UCB.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<p>This policy is defined by inheriting from <code class="docutils literal"><span class="pre">IndexPolicy</span></code>, which is a
generic class already implementing all the methods (<code class="docutils literal"><span class="pre">choice()</span></code> to get
<span class="math">\(A(t) \in \{1,\dots,K\}\)</span>, etc). The only method defined in this
class is the <code class="docutils literal"><span class="pre">computeIndex(arm)</span></code> method, which here uses a UCB index:
the empirical mean plus a confidence width term (hence the name ‚Äúupper
confidence bound‚Äù).</p>
<p>For the classical <code class="docutils literal"><span class="pre">UCB</span></code> algorithm, with <span class="math">\(\alpha=4\)</span>, the index is
computed in two parts:</p>
<ul class="simple">
<li>the empirical mean:
<span class="math">\(\hat{\mu}_k(t) := \frac{\sum_{\tau=1}^t \mathbb{1}(A(t) = k) r_k(t) }{N_k(t)}\)</span>,
computed as <code class="docutils literal"><span class="pre">rewards[k]</span> <span class="pre">/</span> <span class="pre">pulls[k]</span></code> in the code,</li>
<li>the upper confidence bound,
<span class="math">\(B_k(t) := \sqrt{\frac{\alpha \log(t)}{2 N_k(t)}}\)</span>, computed as
<code class="docutils literal"><span class="pre">sqrt((2</span> <span class="pre">*</span> <span class="pre">log(t))</span> <span class="pre">/</span> <span class="pre">pulls[k]</span></code> in the code.</li>
</ul>
<p>Then the index <span class="math">\(X_k(t) = \hat{\mu}_k(t) + B_k(t)\)</span> is used to
decide which arm to select at time <span class="math">\(t+1\)</span>:</p>
<div class="math">
\[A(t+1) = \arg\max_k X_k(t).\]</div>
<p>The simple <code class="docutils literal"><span class="pre">UCB1</span></code> algorithm uses <span class="math">\(\alpha = 4\)</span>, but empirically
<span class="math">\(\alpha = 1\)</span> is known to work better.</p>
</div>
<div class="section" id="The-EmpiricalMeans-algorithm">
<h2>The <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> algorithm<a class="headerlink" href="#The-EmpiricalMeans-algorithm" title="Permalink to this headline">¬∂</a></h2>
<p>We can write a new bandit algorithm quite easily with my framework. For
simple index-based policy, we simply need to write a
<code class="docutils literal"><span class="pre">computeIndex(arm)</span></code> method, as presented above.</p>
<p>The <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> algorithm will be simpler than <code class="docutils literal"><span class="pre">UCB</span></code>, as the
decision will only be based on the empirical means
<span class="math">\(\hat{\mu}_k(t)\)</span>:</p>
<div class="math">
\[A(t+1) = \arg\max_k \hat{\mu}_k(t).\]</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span>IndexPolicy<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> IndexPolicy<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>      Class that implements a generic index policy.
<span class="ansi-red-fg">Init docstring:</span>
New generic index policy.

- nbArms: the number of arms,
- lower, amplitude: lower value and known amplitude of the rewards.
<span class="ansi-red-fg">File:</span>           ~/SMPyBandits.git/Policies/IndexPolicy.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<p>Inheriting from this class makes the job easier:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">EmpiricalMeans</span><span class="p">(</span><span class="n">IndexPolicy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; The naive Empirical Means policy for bounded bandits.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">computeIndex</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arm</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;+inf&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span>EmpiricalMeans<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> EmpiricalMeans<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>      The naive Empirical Means policy for bounded bandits.
<span class="ansi-red-fg">Init docstring:</span>
New generic index policy.

- nbArms: the number of arms,
- lower, amplitude: lower value and known amplitude of the rewards.
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Creating-some-MAB-problems">
<h2>Creating some MAB problems<a class="headerlink" href="#Creating-some-MAB-problems" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="Parameters-for-the-simulation">
<h3>Parameters for the simulation<a class="headerlink" href="#Parameters-for-the-simulation" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><span class="math">\(T = 10000\)</span> is the time horizon,</li>
<li><span class="math">\(N = 100\)</span> is the number of repetitions,</li>
<li><code class="docutils literal"><span class="pre">N_JOBS</span> <span class="pre">=</span> <span class="pre">4</span></code> is the number of cores used to parallelize the code.</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">REPETITIONS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">N_JOBS</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Some-MAB-problem-with-Bernoulli-arms">
<h3>Some MAB problem with Bernoulli arms<a class="headerlink" href="#Some-MAB-problem-with-Bernoulli-arms" title="Permalink to this headline">¬∂</a></h3>
<p>We consider in this example <span class="math">\(3\)</span> problems, with <code class="docutils literal"><span class="pre">Bernoulli</span></code> arms,
of different means.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">ENVIRONMENTS</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># 1)  Bernoulli arms</span>
        <span class="p">{</span>   <span class="c1"># A very easy problem, but it is used in a lot of articles</span>
            <span class="s2">&quot;arm_type&quot;</span><span class="p">:</span> <span class="n">Bernoulli</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>   <span class="c1"># An other problem, best arm = last, with three groups: very bad arms (0.01, 0.02), middle arms (0.3 - 0.6) and very good arms (0.78, 0.8, 0.82)</span>
            <span class="s2">&quot;arm_type&quot;</span><span class="p">:</span> <span class="n">Bernoulli</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.795</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.805</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>   <span class="c1"># A very hard problem, as used in [Capp√© et al, 2012]</span>
            <span class="s2">&quot;arm_type&quot;</span><span class="p">:</span> <span class="n">Bernoulli</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
        <span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Some-RL-algorithms">
<h3>Some RL algorithms<a class="headerlink" href="#Some-RL-algorithms" title="Permalink to this headline">¬∂</a></h3>
<p>We simply want to compare the <span class="math">\(\mathrm{UCB}_1\)</span> algorithm (<code class="docutils literal"><span class="pre">UCB</span></code>)
against the <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> algorithm, defined above.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">POLICIES</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># --- UCB1 algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UCB</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- UCB alpha algorithm with alpha=1/2</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UCBalpha</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.5</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="c1"># --- EmpiricalMeans algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">EmpiricalMeans</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
<p>So the complete configuration for the problem will be this dictionary:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># --- Duration of the experiment</span>
    <span class="s2">&quot;horizon&quot;</span><span class="p">:</span> <span class="n">HORIZON</span><span class="p">,</span>
    <span class="c1"># --- Number of repetition of the experiment (to have an average)</span>
    <span class="s2">&quot;repetitions&quot;</span><span class="p">:</span> <span class="n">REPETITIONS</span><span class="p">,</span>
    <span class="c1"># --- Parameters for the use of joblib.Parallel</span>
    <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="n">N_JOBS</span><span class="p">,</span>    <span class="c1"># = nb of CPU cores</span>
    <span class="s2">&quot;verbosity&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>      <span class="c1"># Max joblib verbosity</span>
    <span class="c1"># --- Arms</span>
    <span class="s2">&quot;environment&quot;</span><span class="p">:</span> <span class="n">ENVIRONMENTS</span><span class="p">,</span>
    <span class="c1"># --- Algorithms</span>
    <span class="s2">&quot;policies&quot;</span><span class="p">:</span> <span class="n">POLICIES</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">configuration</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[12]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>{&#39;environment&#39;: [{&#39;arm_type&#39;: Arms.Bernoulli.Bernoulli,
   &#39;params&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},
  {&#39;arm_type&#39;: Arms.Bernoulli.Bernoulli,
   &#39;params&#39;: [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.795, 0.8, 0.805]},
  {&#39;arm_type&#39;: Arms.Bernoulli.Bernoulli,
   &#39;params&#39;: [0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1]}],
 &#39;horizon&#39;: 10000,
 &#39;n_jobs&#39;: 4,
 &#39;policies&#39;: [{&#39;archtype&#39;: Policies.UCB.UCB, &#39;params&#39;: {}},
  {&#39;archtype&#39;: Policies.UCBalpha.UCBalpha, &#39;params&#39;: {&#39;alpha&#39;: 0.5}},
  {&#39;archtype&#39;: __main__.EmpiricalMeans, &#39;params&#39;: {}}],
 &#39;repetitions&#39;: 100,
 &#39;verbosity&#39;: 6}
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Creating-the-Evaluator-object">
<h2>Creating the <code class="docutils literal"><span class="pre">Evaluator</span></code> object<a class="headerlink" href="#Creating-the-Evaluator-object" title="Permalink to this headline">¬∂</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of policies in this comparison: 3
Time horizon: 10000
Number of repetitions: 100
Sampling rate DELTA_T_SAVE: 1
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary &#39;configuration&#39; = {&#39;arm_type&#39;: &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]} ...
 - with &#39;arm_type&#39; = &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;
 - with &#39;params&#39; = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
 - with &#39;arms&#39; = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.9
 - with &#39;minArm&#39; = 0.1

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 ...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary &#39;configuration&#39; = {&#39;arm_type&#39;: &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.795, 0.8, 0.805]} ...
 - with &#39;arm_type&#39; = &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;
 - with &#39;params&#39; = [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.795, 0.8, 0.805]
 - with &#39;arms&#39; = [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.795), B(0.8), B(0.805)]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.805
 - with &#39;minArm&#39; = 0.01

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 ...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary &#39;configuration&#39; = {&#39;arm_type&#39;: &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1]} ...
 - with &#39;arm_type&#39; = &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;
 - with &#39;params&#39; = [0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1]
 - with &#39;arms&#39; = [B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.1)]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.1
 - with &#39;minArm&#39; = 0.01

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 ...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
Number of environments to try: 3
</pre></div></div>
</div>
</div>
<div class="section" id="Solving-the-problem">
<h2>Solving the problem<a class="headerlink" href="#Solving-the-problem" title="Permalink to this headline">¬∂</a></h2>
<p>Now we can simulate all the <span class="math">\(3\)</span> environments. That part can take
some time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">envId</span><span class="p">,</span> <span class="n">env</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">envs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Problems&quot;</span><span class="p">):</span>
    <span class="c1"># Evaluate just that env</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">startOneEnv</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Evaluating environment: &lt;MAB{&#39;minArm&#39;: 0.10000000000000001, &#39;nbArms&#39;: 9, &#39;arms&#39;: [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)], &#39;maxArm&#39;: 0.90000000000000002}&gt;
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;__main__.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...

- Evaluating policy #1/3: UCB ...

Estimated order by the policy UCB after 10000 steps: [1 0 4 5 7 6 2 3 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 90.47% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 88.84% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Mean distance from optimal ordering: 72.60% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.0s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.4s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #2/3: UCB($\alpha=0.5$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   11.5s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB($\alpha=0.5$) after 10000 steps: [2 0 1 5 3 4 6 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 99.65% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 99.91% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==&gt; Mean distance from optimal ordering: 89.39% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.9s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.3s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   13.4s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #3/3: EmpiricalMeans ...

Estimated order by the policy EmpiricalMeans after 10000 steps: [0 2 4 1 5 6 7 3 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 98.41% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==&gt; Mean distance from optimal ordering: 86.33% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.8s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.5s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Evaluating environment: &lt;MAB{&#39;minArm&#39;: 0.01, &#39;nbArms&#39;: 9, &#39;arms&#39;: [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.795), B(0.8), B(0.805)], &#39;maxArm&#39;: 0.80500000000000005}&gt;
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;__main__.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...

- Evaluating policy #1/3: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   10.6s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB after 10000 steps: [1 3 4 2 5 0 6 8 7] ...
  ==&gt; Optimal arm identification: 99.38% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 65.43% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 96.29% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 95.76% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 81.04% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.8s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.9s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #2/3: UCB($\alpha=0.5$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   11.4s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB($\alpha=0.5$) after 10000 steps: [0 1 2 3 5 4 7 8 6] ...
  ==&gt; Optimal arm identification: 98.76% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 85.19% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 99.82% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 99.98% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==&gt; Mean distance from optimal ordering: 90.69% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.0s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.0s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #3/3: EmpiricalMeans ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   12.9s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy EmpiricalMeans after 10000 steps: [0 1 3 4 5 6 8 2 7] ...
  ==&gt; Optimal arm identification: 99.38% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 98.77% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 97.02% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==&gt; Mean distance from optimal ordering: 85.98% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.9s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.0s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Evaluating environment: &lt;MAB{&#39;minArm&#39;: 0.01, &#39;nbArms&#39;: 9, &#39;arms&#39;: [B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.1)], &#39;maxArm&#39;: 0.10000000000000001}&gt;
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;__main__.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;__main__.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...

- Evaluating policy #1/3: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   11.2s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB after 10000 steps: [3 5 0 2 1 6 8 4 7] ...
  ==&gt; Optimal arm identification: 50.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 50.62% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 85.56% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 87.50% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 44.44% (relative success)...
  ==&gt; Mean distance from optimal ordering: 67.03% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.8s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.1s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #2/3: UCB($\alpha=0.5$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   13.6s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy UCB($\alpha=0.5$) after 10000 steps: [0 7 4 6 3 1 2 5 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 45.68% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 46.84% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 54.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Mean distance from optimal ordering: 50.52% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.1s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.4s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   19.0s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

- Evaluating policy #3/3: EmpiricalMeans ...

Estimated order by the policy EmpiricalMeans after 10000 steps: [0 1 2 3 4 5 6 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Kendell Tau distance from optimal ordering: 99.98% (relative success)...
  ==&gt; Spearman    distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 100.00% (relative success)...
  ==&gt; Mean distance from optimal ordering: 100.00% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.4s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.4s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   14.8s finished
</pre></div></div>
</div>
</div>
<div class="section" id="Plotting-the-results">
<h2>Plotting the results<a class="headerlink" href="#Plotting-the-results" title="Permalink to this headline">¬∂</a></h2>
<p>And finally, visualize them, with the plotting method of a <code class="docutils literal"><span class="pre">Evaluator</span></code>
object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="n">envId</span><span class="p">):</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">printFinalRanking</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">semilogx</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">meanRegret</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotBestArmPulls</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="First-problem">
<h3>First problem<a class="headerlink" href="#First-problem" title="Permalink to this headline">¬∂</a></h3>
<p><span class="math">\(\mu = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]\)</span>
is an easy problem.</p>
<p><span class="math">\(\mathrm{UCB}_{\alpha=1/2}\)</span> performs very well here, and
<code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> is quite inefficient.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #0 :
- Policy &#39;UCB($\alpha=0.5$)&#39;    was ranked      1 / 3 for this simulation (last regret = 48.99).
- Policy &#39;UCB&#39;  was ranked      2 / 3 for this simulation (last regret = 328.08).
- Policy &#39;EmpiricalMeans&#39;       was ranked      3 / 3 for this simulation (last regret = 365.61).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_1.png" src="../_images/notebooks_Do_we_even_need_UCB_54_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_3.png" src="../_images/notebooks_Do_we_even_need_UCB_54_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_5.png" src="../_images/notebooks_Do_we_even_need_UCB_54_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_6.png" src="../_images/notebooks_Do_we_even_need_UCB_54_6.png" />
</div>
</div>
</div>
<div class="section" id="Second-problem">
<h3>Second problem<a class="headerlink" href="#Second-problem" title="Permalink to this headline">¬∂</a></h3>
<p><span class="math">\(\mu = [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.795), B(0.8), B(0.805)]\)</span>
is harder. There is <span class="math">\(3\)</span> good arms, very close in term of mean
rewards.</p>
<p>We could think that <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> will perform even more poorly
here, but in fact although <span class="math">\(\mathrm{UCB}_{\alpha=1/2}\)</span> is more
efficient in term of best arm identification, <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> is
better in term of rewards as it simply focussed on the best arms,
without trying to differente between the best <span class="math">\(3\)</span> arms.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #1 :
- Policy &#39;UCB($\alpha=0.5$)&#39;    was ranked      1 / 3 for this simulation (last regret = 72.965).
- Policy &#39;EmpiricalMeans&#39;       was ranked      2 / 3 for this simulation (last regret = 129.855).
- Policy &#39;UCB&#39;  was ranked      3 / 3 for this simulation (last regret = 236.885).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_1.png" src="../_images/notebooks_Do_we_even_need_UCB_57_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_3.png" src="../_images/notebooks_Do_we_even_need_UCB_57_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_5.png" src="../_images/notebooks_Do_we_even_need_UCB_57_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_6.png" src="../_images/notebooks_Do_we_even_need_UCB_57_6.png" />
</div>
</div>
</div>
<div class="section" id="Third-problem">
<h3>Third problem<a class="headerlink" href="#Third-problem" title="Permalink to this headline">¬∂</a></h3>
<p><span class="math">\(\mu = [B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.1)]\)</span>
is another ‚Äúhard‚Äù problem.</p>
<p>This time, <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code> is clearly worse than <code class="docutils literal"><span class="pre">UCBalpha</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #2 :
- Policy &#39;UCB($\alpha=0.5$)&#39;    was ranked      1 / 3 for this simulation (last regret = 162.84).
- Policy &#39;EmpiricalMeans&#39;       was ranked      2 / 3 for this simulation (last regret = 391.55).
- Policy &#39;UCB&#39;  was ranked      3 / 3 for this simulation (last regret = 484.38).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_60_1.png" src="../_images/notebooks_Do_we_even_need_UCB_60_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_60_3.png" src="../_images/notebooks_Do_we_even_need_UCB_60_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_60_5.png" src="../_images/notebooks_Do_we_even_need_UCB_60_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_60_6.png" src="../_images/notebooks_Do_we_even_need_UCB_60_6.png" />
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¬∂</a></h2>
<p>This small notebook presented the Multi-Armed Bandit problem, as well as
the well-known UCB policy, and a simpler policy just based on empirical
means.</p>
<p>We illustrated and compared the performance of two UCB algorithms
against <code class="docutils literal"><span class="pre">EmpiricalMeans</span></code>, on 3 different Bernoulli problems, and it
appeared clearly that the confidence bound term in UCB is really useful,
even for extremely simple Bernoulli problems.</p>
<hr class="docutils" />
<blockquote>
<div>That‚Äôs it for this demo!</div></blockquote>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Example_of_a_small_Single-Player_Simulation.html" class="btn btn-neutral float-right" title="Table of Contents" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Easily_creating_MAB_problems.html" class="btn btn-neutral" title="Table of Contents" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2018, Lilian Besson (Naereen).
      Last updated on 16 Jul 2018, 14h.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.9.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>