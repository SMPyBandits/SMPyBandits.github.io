

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-38514290-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Table of Contents &mdash; SMPyBandits 0.9.5 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Table of Contents" href="Example_of_a_small_Single-Player_Simulation.html" />
    <link rel="prev" title="Table of Contents" href="Easily_creating_MAB_problems.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SMPyBandits
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html"><em>SMPyBandits</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/modules.html">SMPyBandits modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../How_to_run_the_code.html">How to run the code ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PublicationsWithSMPyBandits.html">List of research publications using Lilian Besson‚Äôs SMPyBandits project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Aggregation.html"><strong>Policy aggregation algorithms</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../MultiPlayers.html"><strong>Multi-players simulation environment</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../DoublingTrick.html"><strong>Doubling Trick for Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../SparseBandits.html"><strong>Structure and Sparsity of Stochastic Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../NonStationaryBandits.html"><strong>Non-Stationary Stochastic Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../API.html">Short documentation of the API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../About_parallel_computations.html">About parallel computations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TODO.html">üí• TODO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plots/README.html">Some illustrations for this project</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">Jupyter Notebooks üìì by Naereen &#64; GitHub</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="list.html">List of notebooks for SMPyBandits</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html#Easily-creating-MAB-problems">Easily creating MAB problems</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?"><em>Do we even need a smart learning algorithm? Is UCB useless?</em></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Notations-for-the-arms">Notations for the arms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Importing-the-algorithms">Importing the algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-UCB-algorithm">The <code class="docutils literal notranslate"><span class="pre">UCB</span></code> algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#The-EmpiricalMeans-algorithm">The <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Creating-some-MAB-problems">Creating some MAB problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Parameters-for-the-simulation">Parameters for the simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Some-MAB-problem-with-Bernoulli-arms">Some MAB problem with Bernoulli arms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Some-RL-algorithms">Some RL algorithms</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Creating-the-Evaluator-object">Creating the <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code> object</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Solving-the-problem">Solving the problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Plotting-the-results">Plotting the results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#First-problem">First problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Second-problem">Second problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Third-problem">Third problem</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html#An-example-of-a-small-Single-Player-simulation">An example of a small Single-Player simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-Centralized-Algorithms">An example of a small Multi-Player simulation, with Centralized Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-rhoRand-and-Selfish,-for-different-algorithms">An example of a small Multi-Player simulation, with rhoRand and Selfish, for different algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="Unsupervised_Learning_for_Bandit_problem.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Unsupervised_Learning_for_Bandit_problem.html#Trying-to-use-Unsupervised-Learning-algorithms-for-a-Gaussian-bandit-problem">Trying to use Unsupervised Learning algorithms for a Gaussian bandit problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html#Trying-to-use-Black-Box-Bayesian-optimization-algorithms-for-a-Gaussian-bandit-problem">Trying to use Black-Box Bayesian optimization algorithms for a Gaussian bandit problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.html#Lai-&amp;-Robbins-lower-bound-for-stochastic-bandit-with-full-restart-points">Lai &amp; Robbins lower-bound for stochastic bandit with full restart points</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exploring_different_doubling_tricks_for_different_kinds_of_regret_bounds.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Exploring_different_doubling_tricks_for_different_kinds_of_regret_bounds.html#Exploring-different-doubling-tricks-for-different-kinds-of-regret-bounds">Exploring different doubling tricks for different kinds of regret bounds</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Requirements-and-helper-functions">Requirements and helper functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Python-implementations-of-some-statistical-tests">Python implementations of some statistical tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Comparing-the-different-implementations">Comparing the different implementations</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#More-simulations-and-some-plots">More simulations and some plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Exploring-the-parameters-of-change-point-detection-algorithms:-how-to-tune-them?">Exploring the parameters of change point detection algorithms: how to tune them?</a></li>
<li class="toctree-l2"><a class="reference internal" href="Experiments_of_statistical_tests_for_piecewise_stationary_bandit.html#Conclusions">Conclusions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Demonstrations_of_Single-Player_Simulations_for_Non-Stationary-Bandits.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Demonstrations_of_Single-Player_Simulations_for_Non-Stationary-Bandits.html#Demonstrations-of-Single-Player-Simulations-for-Non-Stationary-Bandits">Demonstrations of Single-Player Simulations for Non-Stationary-Bandits</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Profiling.html">A note on execution times, speed and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uml_diagrams/README.html">UML diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logs/README.html"><code class="docutils literal notranslate"><span class="pre">logs</span></code> files</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SMPyBandits</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="list.html">List of notebooks for SMPyBandits</a> &raquo;</li>
        
      <li>Table of Contents</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Do_we_even_need_UCB.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Table-of-Contents">
<h1>Table of Contents<a class="headerlink" href="#Table-of-Contents" title="Permalink to this headline">¬∂</a></h1>
<p><div class="lev1 toc-item"><p>1&nbsp;&nbsp;Do we even need a smart learning algorithm? Is UCB useless?</p>
</div><div class="lev2 toc-item"><p>1.1&nbsp;&nbsp;Notations for the arms</p>
</div><div class="lev2 toc-item"><p>1.2&nbsp;&nbsp;Importing the algorithms</p>
</div><div class="lev2 toc-item"><p>1.3&nbsp;&nbsp;The UCB algorithm</p>
</div><div class="lev2 toc-item"><p>1.4&nbsp;&nbsp;The EmpiricalMeans algorithm</p>
</div><div class="lev2 toc-item"><p>1.5&nbsp;&nbsp;Creating some MAB problems</p>
</div><div class="lev3 toc-item"><p>1.5.1&nbsp;&nbsp;Parameters for the simulation</p>
</div><div class="lev3 toc-item"><p>1.5.2&nbsp;&nbsp;Some MAB problem with Bernoulli arms</p>
</div><div class="lev3 toc-item"><p>1.5.3&nbsp;&nbsp;Some RL algorithms</p>
</div><div class="lev2 toc-item"><p>1.6&nbsp;&nbsp;Creating the Evaluator object</p>
</div><div class="lev2 toc-item"><p>1.7&nbsp;&nbsp;Solving the problem</p>
</div><div class="lev2 toc-item"><p>1.8&nbsp;&nbsp;Plotting the results</p>
</div><div class="lev3 toc-item"><p>1.8.1&nbsp;&nbsp;First problem</p>
</div><div class="lev3 toc-item"><p>1.8.2&nbsp;&nbsp;Second problem</p>
</div><div class="lev3 toc-item"><p>1.8.3&nbsp;&nbsp;Third problem</p>
</div><div class="lev2 toc-item"><p>1.9&nbsp;&nbsp;Conclusion</p>
</div></div>
<div class="section" id="Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?">
<h1><em>Do we even need a smart learning algorithm? Is UCB useless?</em><a class="headerlink" href="#Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?" title="Permalink to this headline">¬∂</a></h1>
<p>This short notebook demonstrates that ‚Äúsmart‚Äù Multi-Armed Bandits learning algorithms, like UCB, are indeed needed to learn the distribution of arms, even in the simplest case.</p>
<p>We will use an example of a small Single-Player simulation, and compare the <code class="docutils literal notranslate"><span class="pre">UCB</span></code> algorithm with a naive ‚Äúmax empirical reward‚Äù algorithm. The goal is to illustrate that introducing an exploration term (the confidence width), like what is done in UCB and similar algorithms, really helps learning and improves performance.</p>
<hr class="docutils" />
<div class="section" id="Notations-for-the-arms">
<h2>Notations for the arms<a class="headerlink" href="#Notations-for-the-arms" title="Permalink to this headline">¬∂</a></h2>
<p>To remind the usual notations, there is a fixed number <span class="math notranslate nohighlight">\(K \geq 1\)</span> of levers, or ‚Äúarms‚Äù, and a player has to select one lever at each discrete times <span class="math notranslate nohighlight">\(t \geq 1, t \in \mathbb{N}\)</span>, ie <span class="math notranslate nohighlight">\(k = A(t)\)</span>. Selecting an arm <span class="math notranslate nohighlight">\(k\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> will yield a (random) <em>reward</em>, <span class="math notranslate nohighlight">\(r_k(t)\)</span>, and the goal of the player is to maximize its cumulative reward <span class="math notranslate nohighlight">\(R_T = \sum_{t = 1}^T r_{A(t)}(t)\)</span>.</p>
<p>Each arm is associated with a distribution <span class="math notranslate nohighlight">\(\nu_k\)</span>, for <span class="math notranslate nohighlight">\(k = 1,\dots,K\)</span>, and the usual restriction is to consider one-dimensional exponential family (it includes Gaussian, Exponential and Bernoulli distributions), ie distributions parametered by their means, <span class="math notranslate nohighlight">\(\mu_k\)</span>. So the arm <span class="math notranslate nohighlight">\(k\)</span>, <span class="math notranslate nohighlight">\(r_k(t) \sim \nu_k\)</span>, are iid, and assumed bounded in <span class="math notranslate nohighlight">\([a,b] = [0,1]\)</span>.</p>
<p>For instance, arms can follow Bernoulli distributions, of means <span class="math notranslate nohighlight">\(\mu_1,\dots,\mu_K \in [0,1]\)</span>: <span class="math notranslate nohighlight">\(r_k(t) \sim \mathrm{Bern}(\mu_k)\)</span>, ie <span class="math notranslate nohighlight">\(\mathbb{P}(r_k(t) = 1) = \mu_k\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(N_k(t) = \sum_{\tau=1}^t \mathbb{1}(A(t) = k)\)</span> be the number of times arm <span class="math notranslate nohighlight">\(k\)</span> was selected up-to time <span class="math notranslate nohighlight">\(t \geq 1\)</span>. The empirical mean of arm <span class="math notranslate nohighlight">\(k\)</span> is then defined as <span class="math notranslate nohighlight">\(\hat{\mu_k}(t) := \frac{\sum_{\tau=1}^t \mathbb{1}(A(t) = k) r_k(t) }{N_k(t)}\)</span>.</p>
</div>
<hr class="docutils" />
<div class="section" id="Importing-the-algorithms">
<h2>Importing the algorithms<a class="headerlink" href="#Importing-the-algorithms" title="Permalink to this headline">¬∂</a></h2>
<p>First, be sure to be in the main folder, and import <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code> from <code class="docutils literal notranslate"><span class="pre">Environment</span></code> package:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Local imports</span>
<span class="kn">from</span> <span class="nn">SMPyBandits.Environment</span> <span class="k">import</span> <span class="n">Evaluator</span><span class="p">,</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Info: Using the Jupyter notebook version of the tqdm() decorator, tqdm_notebook() ...
</pre></div></div>
</div>
<p>We also need arms, for instance <code class="docutils literal notranslate"><span class="pre">Bernoulli</span></code>-distributed arm:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Import arms</span>
<span class="kn">from</span> <span class="nn">SMPyBandits.Arms</span> <span class="k">import</span> <span class="n">Bernoulli</span>
</pre></div>
</div>
</div>
<p>And finally we need some single-player Reinforcement Learning algorithms. I focus here on the <code class="docutils literal notranslate"><span class="pre">UCB</span></code> index policy, and the base class <code class="docutils literal notranslate"><span class="pre">IndexPolicy</span></code> will be used to easily define another algorithm.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Import algorithms</span>
<span class="kn">from</span> <span class="nn">SMPyBandits.Policies</span> <span class="k">import</span> <span class="n">UCB</span><span class="p">,</span> <span class="n">UCBalpha</span><span class="p">,</span> <span class="n">EmpiricalMeans</span>
<span class="kn">from</span> <span class="nn">SMPyBandits.Policies.IndexPolicy</span> <span class="k">import</span> <span class="n">IndexPolicy</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="The-UCB-algorithm">
<h2>The <code class="docutils literal notranslate"><span class="pre">UCB</span></code> algorithm<a class="headerlink" href="#The-UCB-algorithm" title="Permalink to this headline">¬∂</a></h2>
<p>First, we can check the documentation of the <code class="docutils literal notranslate"><span class="pre">UCB</span></code> class, implementing the <strong>Upper-Confidence Bounds algorithm</strong>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Just improving the ?? in Jupyter. Thanks to https://nbviewer.jupyter.org/gist/minrk/7715212</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">IPython.core</span> <span class="k">import</span> <span class="n">page</span>
<span class="k">def</span> <span class="nf">myprint</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;text/plain&#39;</span><span class="p">])</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">KeyError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">page</span><span class="o">.</span><span class="n">page</span> <span class="o">=</span> <span class="n">myprint</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>UCB<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> UCB<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>
The UCB policy for bounded bandits.

- Reference: [Lai &amp; Robbins, 1985].
<span class="ansi-red-fg">Init docstring:</span>
New generic index policy.

- nbArms: the number of arms,
- lower, amplitude: lower value and known amplitude of the rewards.
<span class="ansi-red-fg">File:</span>           /tmp/SMPyBandits/notebooks/venv3/lib/python3.6/site-packages/SMPyBandits/Policies/UCB.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<p>Let us quickly have a look to the code of the <code class="docutils literal notranslate"><span class="pre">UCB</span></code> policy imported above.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>UCB<span class="o">??</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> UCB<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Source:</span>
<span class="ansi-green-fg">class</span> UCB<span class="ansi-blue-fg">(</span>IndexPolicy<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
    <span class="ansi-blue-fg">&#34;&#34;&#34; The UCB policy for bounded bandits.</span>

<span class="ansi-blue-fg">    - Reference: [Lai &amp; Robbins, 1985].</span>
<span class="ansi-blue-fg">    &#34;&#34;&#34;</span>

    <span class="ansi-green-fg">def</span> computeIndex<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> arm<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        <span class="ansi-blue-fg">r&#34;&#34;&#34; Compute the current index, at time t and after :math:`N_k(t)` pulls of arm k:</span>

<span class="ansi-blue-fg">        .. math:: I_k(t) = \frac{X_k(t)}{N_k(t)} + \sqrt{\frac{2 \log(t)}{N_k(t)}}.</span>
<span class="ansi-blue-fg">        &#34;&#34;&#34;</span>
        <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>
            <span class="ansi-green-fg">return</span> float<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;+inf&#39;</span><span class="ansi-blue-fg">)</span>
        <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
            <span class="ansi-green-fg">return</span> <span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>rewards<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> sqrt<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span> <span class="ansi-blue-fg">*</span> log<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>t<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>

    <span class="ansi-green-fg">def</span> computeAllIndex<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        <span class="ansi-blue-fg">&#34;&#34;&#34; Compute the current indexes for all arms, in a vectorized manner.&#34;&#34;&#34;</span>
        indexes <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>rewards <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> np<span class="ansi-blue-fg">.</span>sqrt<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span> <span class="ansi-blue-fg">*</span> np<span class="ansi-blue-fg">.</span>log<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>t<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">)</span>
        indexes<span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>pulls <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> float<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;+inf&#39;</span><span class="ansi-blue-fg">)</span>
        self<span class="ansi-blue-fg">.</span>index<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> indexes
<span class="ansi-red-fg">File:</span>           /tmp/SMPyBandits/notebooks/venv3/lib/python3.6/site-packages/SMPyBandits/Policies/UCB.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<p>This policy is defined by inheriting from <code class="docutils literal notranslate"><span class="pre">IndexPolicy</span></code>, which is a generic class already implementing all the methods (<code class="docutils literal notranslate"><span class="pre">choice()</span></code> to get <span class="math notranslate nohighlight">\(A(t) \in \{1,\dots,K\}\)</span>, etc). The only method defined in this class is the <code class="docutils literal notranslate"><span class="pre">computeIndex(arm)</span></code> method, which here uses a UCB index: the empirical mean plus a confidence width term (hence the name ‚Äúupper confidence bound‚Äù).</p>
<p>For the classical <code class="docutils literal notranslate"><span class="pre">UCB</span></code> algorithm, with <span class="math notranslate nohighlight">\(\alpha=4\)</span>, the index is computed in two parts:</p>
<ul class="simple">
<li>the empirical mean: <span class="math notranslate nohighlight">\(\hat{\mu}_k(t) := \frac{\sum_{\tau=1}^t \mathbb{1}(A(t) = k) r_k(t) }{N_k(t)}\)</span>, computed as <code class="docutils literal notranslate"><span class="pre">rewards[k]</span> <span class="pre">/</span> <span class="pre">pulls[k]</span></code> in the code,</li>
<li>the upper confidence bound, <span class="math notranslate nohighlight">\(B_k(t) := \sqrt{\frac{\alpha \log(t)}{2 N_k(t)}}\)</span>, computed as <code class="docutils literal notranslate"><span class="pre">sqrt((2</span> <span class="pre">*</span> <span class="pre">log(t))</span> <span class="pre">/</span> <span class="pre">pulls[k]</span></code> in the code.</li>
</ul>
<p>Then the index <span class="math notranslate nohighlight">\(X_k(t) = \hat{\mu}_k(t) + B_k(t)\)</span> is used to decide which arm to select at time <span class="math notranslate nohighlight">\(t+1\)</span>:</p>
<div class="math notranslate nohighlight">
\[A(t+1) = \arg\max_k X_k(t).\]</div>
<p>The simple <code class="docutils literal notranslate"><span class="pre">UCB1</span></code> algorithm uses <span class="math notranslate nohighlight">\(\alpha = 4\)</span>, but empirically <span class="math notranslate nohighlight">\(\alpha = 1\)</span> is known to work better.</p>
</div>
<div class="section" id="The-EmpiricalMeans-algorithm">
<h2>The <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> algorithm<a class="headerlink" href="#The-EmpiricalMeans-algorithm" title="Permalink to this headline">¬∂</a></h2>
<p>We can write a new bandit algorithm quite easily with my framework. For simple index-based policy, we simply need to write a <code class="docutils literal notranslate"><span class="pre">computeIndex(arm)</span></code> method, as presented above.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> algorithm will be simpler than <code class="docutils literal notranslate"><span class="pre">UCB</span></code>, as the decision will only be based on the empirical means <span class="math notranslate nohighlight">\(\hat{\mu}_k(t)\)</span>:</p>
<div class="math notranslate nohighlight">
\[A(t+1) = \arg\max_k \hat{\mu}_k(t).\]</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>EmpiricalMeans<span class="o">?</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> EmpiricalMeans<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Docstring:</span>      The naive Empirical Means policy for bounded bandits: like UCB but without a bias correction term. Note that it is equal to UCBalpha with alpha=0, only quicker.
<span class="ansi-red-fg">Init docstring:</span>
New generic index policy.

- nbArms: the number of arms,
- lower, amplitude: lower value and known amplitude of the rewards.
<span class="ansi-red-fg">File:</span>           /tmp/SMPyBandits/notebooks/venv3/lib/python3.6/site-packages/SMPyBandits/Policies/EmpiricalMeans.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>EmpiricalMeans<span class="o">??</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">Init signature:</span> EmpiricalMeans<span class="ansi-blue-fg">(</span>nbArms<span class="ansi-blue-fg">,</span> lower<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">,</span> amplitude<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1.0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-red-fg">Source:</span>
<span class="ansi-green-fg">class</span> EmpiricalMeans<span class="ansi-blue-fg">(</span>IndexPolicy<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
    <span class="ansi-blue-fg">&#34;&#34;&#34; The naive Empirical Means policy for bounded bandits: like UCB but without a bias correction term. Note that it is equal to UCBalpha with alpha=0, only quicker.&#34;&#34;&#34;</span>

    <span class="ansi-green-fg">def</span> computeIndex<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> arm<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        <span class="ansi-blue-fg">r&#34;&#34;&#34; Compute the current index, at time t and after :math:`N_k(t)` pulls of arm k:</span>

<span class="ansi-blue-fg">        .. math:: I_k(t) = \frac{X_k(t)}{N_k(t)}.</span>
<span class="ansi-blue-fg">        &#34;&#34;&#34;</span>
        <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>
            <span class="ansi-green-fg">return</span> float<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;+inf&#39;</span><span class="ansi-blue-fg">)</span>
        <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
            <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>rewards<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls<span class="ansi-blue-fg">[</span>arm<span class="ansi-blue-fg">]</span>

    <span class="ansi-green-fg">def</span> computeAllIndex<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
        <span class="ansi-blue-fg">&#34;&#34;&#34; Compute the current indexes for all arms, in a vectorized manner.&#34;&#34;&#34;</span>
        indexes <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>rewards <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>pulls
        indexes<span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>pulls <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> float<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;+inf&#39;</span><span class="ansi-blue-fg">)</span>
        self<span class="ansi-blue-fg">.</span>index<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> indexes
<span class="ansi-red-fg">File:</span>           /tmp/SMPyBandits/notebooks/venv3/lib/python3.6/site-packages/SMPyBandits/Policies/EmpiricalMeans.py
<span class="ansi-red-fg">Type:</span>           type

</pre></div></div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Creating-some-MAB-problems">
<h2>Creating some MAB problems<a class="headerlink" href="#Creating-some-MAB-problems" title="Permalink to this headline">¬∂</a></h2>
<div class="section" id="Parameters-for-the-simulation">
<h3>Parameters for the simulation<a class="headerlink" href="#Parameters-for-the-simulation" title="Permalink to this headline">¬∂</a></h3>
<ul class="simple">
<li><span class="math notranslate nohighlight">\(T = 10000\)</span> is the time horizon,</li>
<li><span class="math notranslate nohighlight">\(N = 100\)</span> is the number of repetitions,</li>
<li><code class="docutils literal notranslate"><span class="pre">N_JOBS</span> <span class="pre">=</span> <span class="pre">4</span></code> is the number of cores used to parallelize the code.</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">REPETITIONS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">N_JOBS</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Some-MAB-problem-with-Bernoulli-arms">
<h3>Some MAB problem with Bernoulli arms<a class="headerlink" href="#Some-MAB-problem-with-Bernoulli-arms" title="Permalink to this headline">¬∂</a></h3>
<p>We consider in this example <span class="math notranslate nohighlight">\(3\)</span> problems, with <code class="docutils literal notranslate"><span class="pre">Bernoulli</span></code> arms, of different means.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ENVIRONMENTS</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># 1)  Bernoulli arms</span>
        <span class="p">{</span>   <span class="c1"># A very easy problem, but it is used in a lot of articles</span>
            <span class="s2">&quot;arm_type&quot;</span><span class="p">:</span> <span class="n">Bernoulli</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>   <span class="c1"># An other problem, best arm = last, with three groups: very bad arms (0.01, 0.02), middle arms (0.3 - 0.6) and very good arms (0.78, 0.8, 0.82)</span>
            <span class="s2">&quot;arm_type&quot;</span><span class="p">:</span> <span class="n">Bernoulli</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.795</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.805</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>   <span class="c1"># A very hard problem, as used in [Capp√© et al, 2012]</span>
            <span class="s2">&quot;arm_type&quot;</span><span class="p">:</span> <span class="n">Bernoulli</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
        <span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Some-RL-algorithms">
<h3>Some RL algorithms<a class="headerlink" href="#Some-RL-algorithms" title="Permalink to this headline">¬∂</a></h3>
<p>We simply want to compare the <span class="math notranslate nohighlight">\(\mathrm{UCB}_1\)</span> algorithm (<code class="docutils literal notranslate"><span class="pre">UCB</span></code>) against the <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> algorithm, defined above.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">POLICIES</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># --- UCB1 algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UCB</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
        <span class="c1"># --- UCB alpha algorithm with alpha=1/2</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">UCBalpha</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.5</span>
            <span class="p">}</span>
        <span class="p">},</span>
        <span class="c1"># --- EmpiricalMeans algorithm</span>
        <span class="p">{</span>
            <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">EmpiricalMeans</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{}</span>
        <span class="p">},</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
<p>So the complete configuration for the problem will be this dictionary:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># --- Duration of the experiment</span>
    <span class="s2">&quot;horizon&quot;</span><span class="p">:</span> <span class="n">HORIZON</span><span class="p">,</span>
    <span class="c1"># --- Number of repetition of the experiment (to have an average)</span>
    <span class="s2">&quot;repetitions&quot;</span><span class="p">:</span> <span class="n">REPETITIONS</span><span class="p">,</span>
    <span class="c1"># --- Parameters for the use of joblib.Parallel</span>
    <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="n">N_JOBS</span><span class="p">,</span>    <span class="c1"># = nb of CPU cores</span>
    <span class="s2">&quot;verbosity&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>      <span class="c1"># Max joblib verbosity</span>
    <span class="c1"># --- Arms</span>
    <span class="s2">&quot;environment&quot;</span><span class="p">:</span> <span class="n">ENVIRONMENTS</span><span class="p">,</span>
    <span class="c1"># --- Algorithms</span>
    <span class="s2">&quot;policies&quot;</span><span class="p">:</span> <span class="n">POLICIES</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">configuration</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>{&#39;horizon&#39;: 10000,
 &#39;repetitions&#39;: 100,
 &#39;n_jobs&#39;: 4,
 &#39;verbosity&#39;: 6,
 &#39;environment&#39;: [{&#39;arm_type&#39;: SMPyBandits.Arms.Bernoulli.Bernoulli,
   &#39;params&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},
  {&#39;arm_type&#39;: SMPyBandits.Arms.Bernoulli.Bernoulli,
   &#39;params&#39;: [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.795, 0.8, 0.805]},
  {&#39;arm_type&#39;: SMPyBandits.Arms.Bernoulli.Bernoulli,
   &#39;params&#39;: [0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1]}],
 &#39;policies&#39;: [{&#39;archtype&#39;: SMPyBandits.Policies.UCB.UCB, &#39;params&#39;: {}},
  {&#39;archtype&#39;: SMPyBandits.Policies.UCBalpha.UCBalpha,
   &#39;params&#39;: {&#39;alpha&#39;: 0.5}},
  {&#39;archtype&#39;: SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans,
   &#39;params&#39;: {}}]}
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Creating-the-Evaluator-object">
<h2>Creating the <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code> object<a class="headerlink" href="#Creating-the-Evaluator-object" title="Permalink to this headline">¬∂</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of policies in this comparison: 3
Time horizon: 10000
Number of repetitions: 100
Sampling rate for plotting, delta_t_plot: 1
Number of jobs for parallelization: 4
Using this dictionary to create a new environment:
 {&#39;arm_type&#39;: &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}


Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary &#39;configuration&#39; = {&#39;arm_type&#39;: &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]} ...
 - with &#39;arm_type&#39; = &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;
 - with &#39;params&#39; = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
 - with &#39;arms&#39; = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]
 - with &#39;means&#39; = [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.9
 - with &#39;minArm&#39; = 0.1

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 ...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
 - with &#39;arms&#39; represented as: $[B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)^*]$
Using this dictionary to create a new environment:
 {&#39;arm_type&#39;: &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.795, 0.8, 0.805]}


Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary &#39;configuration&#39; = {&#39;arm_type&#39;: &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.795, 0.8, 0.805]} ...
 - with &#39;arm_type&#39; = &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;
 - with &#39;params&#39; = [0.01, 0.02, 0.3, 0.4, 0.5, 0.6, 0.795, 0.8, 0.805]
 - with &#39;arms&#39; = [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.795), B(0.8), B(0.805)]
 - with &#39;means&#39; = [0.01  0.02  0.3   0.4   0.5   0.6   0.795 0.8   0.805]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.805
 - with &#39;minArm&#39; = 0.01

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 ...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
 - with &#39;arms&#39; represented as: $[B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.795), B(0.8), B(0.805)^*]$
Using this dictionary to create a new environment:
 {&#39;arm_type&#39;: &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1]}


Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary &#39;configuration&#39; = {&#39;arm_type&#39;: &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1]} ...
 - with &#39;arm_type&#39; = &lt;class &#39;SMPyBandits.Arms.Bernoulli.Bernoulli&#39;&gt;
 - with &#39;params&#39; = [0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.05, 0.05, 0.1]
 - with &#39;arms&#39; = [B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.1)]
 - with &#39;means&#39; = [0.01 0.01 0.01 0.02 0.02 0.02 0.05 0.05 0.1 ]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.1
 - with &#39;minArm&#39; = 0.01

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 ...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
 - with &#39;arms&#39; represented as: $[B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.1)^*]$
Number of environments to try: 3
</pre></div></div>
</div>
</div>
<div class="section" id="Solving-the-problem">
<h2>Solving the problem<a class="headerlink" href="#Solving-the-problem" title="Permalink to this headline">¬∂</a></h2>
<p>Now we can simulate all the <span class="math notranslate nohighlight">\(3\)</span> environments. That part can take some time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">envId</span><span class="p">,</span> <span class="n">env</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">envs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Problems&quot;</span><span class="p">):</span>
    <span class="c1"># Evaluate just that env</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">startOneEnv</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "9fa517346b454c3393f1e8c043413499", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


Evaluating environment: MAB(nbArms: 9, arms: [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)], minArm: 0.1, maxArm: 0.9)
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...



- Evaluating policy #1/3: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "703a292bea9a4b6a997c4a4d29741b76", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    4.2s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   11.7s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   28.5s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #2/3: UCB($\alpha=0.5$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "7adfb75a99ab430495f50d7044323eb3", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.7s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   11.0s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   24.9s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #3/3: EmpiricalMeans ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "9a2b6e431de8478693a82b65444c6b9c", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.1s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.4s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   20.5s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


Evaluating environment: MAB(nbArms: 9, arms: [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.795), B(0.8), B(0.805)], minArm: 0.01, maxArm: 0.805)
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...



- Evaluating policy #1/3: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "fc600f5ca49f4c73be3c2a14db9c9a1e", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.7s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   14.0s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   24.3s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #2/3: UCB($\alpha=0.5$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ccd94c429fd142f89b7f07e30940ee07", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.6s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    9.7s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   22.6s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #3/3: EmpiricalMeans ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b602c8eab2e54294a8c3f56f0c5cb3e6", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.3s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.4s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   20.2s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


Evaluating environment: MAB(nbArms: 9, arms: [B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.1)], minArm: 0.01, maxArm: 0.1)
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCB.UCB&#39;&gt;, &#39;params&#39;: {}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.UCBalpha.UCBalpha&#39;&gt;, &#39;params&#39;: {&#39;alpha&#39;: 0.5}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;SMPyBandits.Policies.EmpiricalMeans.EmpiricalMeans&#39;&gt;, &#39;params&#39;: {}} ...



- Evaluating policy #1/3: UCB ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "986a18086f154cb0b05bb878c9739c48", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.4s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.7s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   17.9s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #2/3: UCB($\alpha=0.5$) ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f3704cc89a394e15b5b3a8a301cc455a", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.4s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.8s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   17.3s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #3/3: EmpiricalMeans ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "1ab06092efd849da83da1ad241f0e14e", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    1.0s
[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.9s
[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   14.1s finished
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
</div>
<div class="section" id="Plotting-the-results">
<h2>Plotting the results<a class="headerlink" href="#Plotting-the-results" title="Permalink to this headline">¬∂</a></h2>
<p>And finally, visualize them, with the plotting method of a <code class="docutils literal notranslate"><span class="pre">Evaluator</span></code> object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="n">envId</span><span class="p">):</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">printFinalRanking</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">semilogx</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">meanRegret</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">plotBestArmPulls</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="First-problem">
<h3>First problem<a class="headerlink" href="#First-problem" title="Permalink to this headline">¬∂</a></h3>
<p><span class="math notranslate nohighlight">\(\mu = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]\)</span> is an easy problem.</p>
<p><span class="math notranslate nohighlight">\(\mathrm{UCB}_{\alpha=1/2}\)</span> performs very well here, and <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> is quite inefficient.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #0 :
- Policy &#39;UCB($\alpha=0.5$)&#39;    was ranked      1 / 3 for this simulation (last regret = 51.636).
- Policy &#39;UCB&#39;  was ranked      2 / 3 for this simulation (last regret = 330.67).
- Policy &#39;EmpiricalMeans&#39;       was ranked      3 / 3 for this simulation (last regret = 384.94).
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ModuleNotFoundError</span>                       Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-24-2a63b4dfab0c&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>plotAll<span class="ansi-blue-fg">(</span>evaluation<span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-15-8b5020fc41bc&gt;</span> in <span class="ansi-cyan-fg">plotAll</span><span class="ansi-blue-fg">(evaluation, envId)</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-green-fg">def</span> plotAll<span class="ansi-blue-fg">(</span>evaluation<span class="ansi-blue-fg">,</span> envId<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>     evaluation<span class="ansi-blue-fg">.</span>printFinalRanking<span class="ansi-blue-fg">(</span>envId<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">     </span>evaluation<span class="ansi-blue-fg">.</span>plotRegrets<span class="ansi-blue-fg">(</span>envId<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span>     evaluation<span class="ansi-blue-fg">.</span>plotRegrets<span class="ansi-blue-fg">(</span>envId<span class="ansi-blue-fg">,</span> semilogx<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>     evaluation<span class="ansi-blue-fg">.</span>plotRegrets<span class="ansi-blue-fg">(</span>envId<span class="ansi-blue-fg">,</span> meanRegret<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/tmp/SMPyBandits/notebooks/venv3/lib/python3.6/site-packages/SMPyBandits/Environment/Evaluator.py</span> in <span class="ansi-cyan-fg">plotRegrets</span><span class="ansi-blue-fg">(self, envId, savefig, meanReward, plotSTD, plotMaxMin, semilogx, semilogy, loglog, normalizedRegret, drawUpperBound, moreAccurate)</span>
<span class="ansi-green-intense-fg ansi-bold">    552</span>         self<span class="ansi-blue-fg">.</span>_xlabel<span class="ansi-blue-fg">(</span>envId<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">r&#34;Time steps $t = 1...T$, horizon $T = {}${}&#34;</span><span class="ansi-blue-fg">.</span>format<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>horizon<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>signature<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    553</span>         lowerbound <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>envs<span class="ansi-blue-fg">[</span>envId<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>lowerbound<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 554</span><span class="ansi-red-fg">         </span>lowerbound_sparse <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>envs<span class="ansi-blue-fg">[</span>envId<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>lowerbound_sparse<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    555</span>         <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> <span class="ansi-blue-fg">(</span>semilogx <span class="ansi-green-fg">or</span> semilogy <span class="ansi-green-fg">or</span> loglog<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    556</span>             print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;\nThis MAB problem has: \n - a [Lai &amp; Robbins] complexity constant C(mu) = {:.3g} for 1-player problem... \n - a Optimal Arm Identification factor H_OI(mu) = {:.2%} ...&#34;</span><span class="ansi-blue-fg">.</span>format<span class="ansi-blue-fg">(</span>lowerbound<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>envs<span class="ansi-blue-fg">[</span>envId<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>hoifactor<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># DEBUG</span>

<span class="ansi-green-fg">/tmp/SMPyBandits/notebooks/venv3/lib/python3.6/site-packages/SMPyBandits/Environment/MAB.py</span> in <span class="ansi-cyan-fg">lowerbound_sparse</span><span class="ansi-blue-fg">(self, sparsity)</span>
<span class="ansi-green-intense-fg ansi-bold">    261</span>
<span class="ansi-green-intense-fg ansi-bold">    262</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 263</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">from</span> Policies<span class="ansi-blue-fg">.</span>OSSB <span class="ansi-green-fg">import</span> solve_optimization_problem__sparse_bandits
<span class="ansi-green-intense-fg ansi-bold">    264</span>             ci <span class="ansi-blue-fg">=</span> solve_optimization_problem__sparse_bandits<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>means<span class="ansi-blue-fg">,</span> sparsity<span class="ansi-blue-fg">=</span>sparsity<span class="ansi-blue-fg">,</span> only_strong_or_weak<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    265</span>             <span class="ansi-red-fg"># now we use these ci to compute the lower-bound</span>

<span class="ansi-red-fg">ModuleNotFoundError</span>: No module named &#39;Policies&#39;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_51_2.png" src="../_images/notebooks_Do_we_even_need_UCB_51_2.png" />
</div>
</div>
</div>
<div class="section" id="Second-problem">
<h3>Second problem<a class="headerlink" href="#Second-problem" title="Permalink to this headline">¬∂</a></h3>
<p><span class="math notranslate nohighlight">\(\mu = [B(0.01), B(0.02), B(0.3), B(0.4), B(0.5), B(0.6), B(0.795), B(0.8), B(0.805)]\)</span> is harder. There is <span class="math notranslate nohighlight">\(3\)</span> good arms, very close in term of mean rewards.</p>
<p>We could think that <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> will perform even more poorly here, but in fact although <span class="math notranslate nohighlight">\(\mathrm{UCB}_{\alpha=1/2}\)</span> is more efficient in term of best arm identification, <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> is better in term of rewards as it simply focussed on the best arms, without trying to differente between the best <span class="math notranslate nohighlight">\(3\)</span> arms.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #1 :
- Policy &#39;UCB($\alpha=0.5$)&#39;    was ranked      1 / 3 for this simulation (last regret = 72.965).
- Policy &#39;EmpiricalMeans&#39;       was ranked      2 / 3 for this simulation (last regret = 129.855).
- Policy &#39;UCB&#39;  was ranked      3 / 3 for this simulation (last regret = 236.885).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_1.png" src="../_images/notebooks_Do_we_even_need_UCB_54_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_3.png" src="../_images/notebooks_Do_we_even_need_UCB_54_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 101 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 55.39% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_5.png" src="../_images/notebooks_Do_we_even_need_UCB_54_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_54_6.png" src="../_images/notebooks_Do_we_even_need_UCB_54_6.png" />
</div>
</div>
</div>
<div class="section" id="Third-problem">
<h3>Third problem<a class="headerlink" href="#Third-problem" title="Permalink to this headline">¬∂</a></h3>
<p><span class="math notranslate nohighlight">\(\mu = [B(0.01), B(0.01), B(0.01), B(0.02), B(0.02), B(0.02), B(0.05), B(0.05), B(0.1)]\)</span> is another ‚Äúhard‚Äù problem.</p>
<p>This time, <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code> is clearly worse than <code class="docutils literal notranslate"><span class="pre">UCBalpha</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #2 :
- Policy &#39;UCB($\alpha=0.5$)&#39;    was ranked      1 / 3 for this simulation (last regret = 162.84).
- Policy &#39;EmpiricalMeans&#39;       was ranked      2 / 3 for this simulation (last regret = 391.55).
- Policy &#39;UCB&#39;  was ranked      3 / 3 for this simulation (last regret = 484.38).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_1.png" src="../_images/notebooks_Do_we_even_need_UCB_57_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_3.png" src="../_images/notebooks_Do_we_even_need_UCB_57_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 14.5 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 82.11% ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_5.png" src="../_images/notebooks_Do_we_even_need_UCB_57_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Do_we_even_need_UCB_57_6.png" src="../_images/notebooks_Do_we_even_need_UCB_57_6.png" />
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¬∂</a></h2>
<p>This small notebook presented the Multi-Armed Bandit problem, as well as the well-known UCB policy, and a simpler policy just based on empirical means.</p>
<p>We illustrated and compared the performance of two UCB algorithms against <code class="docutils literal notranslate"><span class="pre">EmpiricalMeans</span></code>, on 3 different Bernoulli problems, and it appeared clearly that the confidence bound term in UCB is really useful, even for extremely simple Bernoulli problems.</p>
<hr class="docutils" />
<blockquote>
<div>That‚Äôs it for this demo!</div></blockquote>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Example_of_a_small_Single-Player_Simulation.html" class="btn btn-neutral float-right" title="Table of Contents" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Easily_creating_MAB_problems.html" class="btn btn-neutral float-left" title="Table of Contents" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2018, Lilian Besson (Naereen)
      <span class="lastupdated">
        Last updated on 19 Jun 2019, 19h.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>