

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <script type="text/javascript">

            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-38514290-2']);
            _gaq.push(['_trackPageview']);

            (function() {
                var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
                var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
            })();
            </script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Table of Contents &mdash; SMPyBandits 0.9.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="SMPyBandits 0.9.2 documentation" href="../index.html"/>
        <link rel="up" title="List of notebooks for SMPyBandits documentation" href="list.html"/>
        <link rel="next" title="A note on execution times, speed and profiling" href="../Profiling.html"/>
        <link rel="prev" title="Table of Contents" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> SMPyBandits
          

          
            
            <img src="../_static/logo.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html"><em>SMPyBandits</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="../docs/modules.html">SMPyBandits modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../How_to_run_the_code.html">How to run the code ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PublicationsWithSMPyBandits.html">List of research publications using Lilian Besson&#8217;s SMPyBandits project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Aggregation.html"><strong>Policy aggregation algorithms</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../MultiPlayers.html"><strong>Multi-players simulation environment</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../DoublingTrick.html"><strong>Doubling Trick for Multi-Armed Bandits</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../API.html">Short documentation of the API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TODO.html">ðŸ’¥ TODO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plots/README.html">Some illustrations for this project</a></li>
<li class="toctree-l1"><a class="reference internal" href="README.html">Jupyter Notebooks ðŸ““ by Naereen &#64; GitHub</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="list.html">List of notebooks for SMPyBandits documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Easily_creating_MAB_problems.html#Easily-creating-MAB-problems">Easily creating MAB problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="Do_we_even_need_UCB.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Do_we_even_need_UCB.html#Do-we-even-need-a-smart-learning-algorithm?-Is-UCB-useless?"><em>Do we even need a smart learning algorithm? Is UCB useless?</em></a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Single-Player_Simulation.html#An-example-of-a-small-Single-Player-simulation">An example of a small Single-Player simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_Centralized_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-Centralized-Algorithms">An example of a small Multi-Player simulation, with Centralized Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Example_of_a_small_Multi-Player_Simulation__with_rhoRand_and_Selfish_Algorithms.html#An-example-of-a-small-Multi-Player-simulation,-with-rhoRand-and-Selfish,-for-different-algorithms">An example of a small Multi-Player simulation, with rhoRand and Selfish, for different algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="Unsupervised_Learning_for_Bandit_problem.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="Unsupervised_Learning_for_Bandit_problem.html#Trying-to-use-Unsupervised-Learning-algorithms-for-a-Gaussian-bandit-problem">Trying to use Unsupervised Learning algorithms for a Gaussian bandit problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html#Trying-to-use-Black-Box-Bayesian-optimization-algorithms-for-a-Gaussian-bandit-problem">Trying to use Black-Box Bayesian optimization algorithms for a Gaussian bandit problem</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Table of Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Lai-&amp;-Robbins-lower-bound-for-stochastic-bandit-with-full-restart-points">Lai &amp; Robbins lower-bound for stochastic bandit with full restart points</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Creating-the-problem">Creating the problem</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Parameters-for-the-simulation">Parameters for the simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Some-MAB-problem-with-Bernoulli-arms">Some MAB problem with Bernoulli arms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Some-RL-algorithms">Some RL algorithms</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Creating-the-Evaluator-object">Creating the <code class="docutils literal"><span class="pre">Evaluator</span></code> object</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Solving-the-problem">Solving the problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Plotting-the-results">Plotting the results</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Visualisation-the-lower-bound-for-algorithms-that-restart-at-breaking-points">Visualisation the lower-bound for algorithms that restart at breaking points</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Seeing-the-lower-bound-on-the-regret-plot">Seeing the lower-bound on the regret plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Profiling.html">A note on execution times, speed and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uml_diagrams/README.html">UML diagrams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logs/README.html"><code class="docutils literal"><span class="pre">logs/</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">On Github Issues and Pull Requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SMPyBandits</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="list.html">List of notebooks for SMPyBandits documentation</a> &raquo;</li>
        
      <li>Table of Contents</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notebooks/Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="Table-of-Contents">
<h1>Table of Contents<a class="headerlink" href="#Table-of-Contents" title="Permalink to this headline">Â¶</a></h1>
<p><div class="lev1 toc-item"><p>1&nbsp;&nbsp;Lai &amp; Robbins lower-bound for stochastic bandit with full restart
points</p>
</div><div class="lev2 toc-item"><p>1.1&nbsp;&nbsp;Creating the problem</p>
</div><div class="lev3 toc-item"><p>1.1.1&nbsp;&nbsp;Parameters for the simulation</p>
</div><div class="lev3 toc-item"><p>1.1.2&nbsp;&nbsp;Some MAB problem with Bernoulli arms</p>
</div><div class="lev3 toc-item"><p>1.1.3&nbsp;&nbsp;Some RL algorithms</p>
</div><div class="lev2 toc-item"><p>1.2&nbsp;&nbsp;Creating the Evaluator object</p>
</div><div class="lev2 toc-item"><p>1.3&nbsp;&nbsp;Solving the problem</p>
</div><div class="lev2 toc-item"><p>1.4&nbsp;&nbsp;Plotting the results</p>
</div><div class="lev2 toc-item"><p>1.5&nbsp;&nbsp;Visualisation the lower-bound for algorithms that restart at
breaking points</p>
</div><div class="lev2 toc-item"><p>1.6&nbsp;&nbsp;Seeing the lower-bound on the regret plot</p>
</div><div class="lev2 toc-item"><p>1.7&nbsp;&nbsp;Conclusion</p>
</div></div>
<hr class="docutils" />
<div class="section" id="Lai-&amp;-Robbins-lower-bound-for-stochastic-bandit-with-full-restart-points">
<h1>Lai &amp; Robbins lower-bound for stochastic bandit with full restart points<a class="headerlink" href="#Lai-&-Robbins-lower-bound-for-stochastic-bandit-with-full-restart-points" title="Permalink to this headline">Â¶</a></h1>
<p>First, be sure to be in the main folder, and import <code class="docutils literal"><span class="pre">Evaluator</span></code> from
<code class="docutils literal"><span class="pre">Environment</span></code> package:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sys</span> <span class="k">import</span> <span class="n">path</span>
<span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Local imports</span>
<span class="kn">from</span> <span class="nn">Environment</span> <span class="k">import</span> <span class="n">Evaluator</span><span class="p">,</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">Environment.plotsettings</span> <span class="k">import</span> <span class="n">legend</span><span class="p">,</span> <span class="n">makemarkers</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 - Setting dpi of all figures to 110 ...
 - Setting &#39;figsize&#39; of all figures to (19.8, 10.8) ...
Info: Using the Jupyter notebook version of the tqdm() decorator, tqdm_notebook() ...
</pre></div></div>
</div>
<p>We also need arms, for instance <code class="docutils literal"><span class="pre">Bernoulli</span></code>-distributed arm:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Import arms</span>
<span class="kn">from</span> <span class="nn">Arms</span> <span class="k">import</span> <span class="n">Bernoulli</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Info: numba.jit seems to be available.
</pre></div></div>
</div>
<p>And finally we need some single-player Reinforcement Learning
algorithms:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Import algorithms</span>
<span class="kn">from</span> <span class="nn">Policies</span> <span class="k">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Info: numba.jit seems to be available.
</pre></div></div>
</div>
<hr class="docutils" />
<div class="section" id="Creating-the-problem">
<h2>Creating the problem<a class="headerlink" href="#Creating-the-problem" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="Parameters-for-the-simulation">
<h3>Parameters for the simulation<a class="headerlink" href="#Parameters-for-the-simulation" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><span class="math">\(T = 20000\)</span> is the time horizon,</li>
<li><span class="math">\(N = 40\)</span> is the number of repetitions,</li>
<li><code class="docutils literal"><span class="pre">N_JOBS</span> <span class="pre">=</span> <span class="pre">4</span></code> is the number of cores used to parallelize the code.</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">HORIZON</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">REPETITIONS</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">N_JOBS</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Some-MAB-problem-with-Bernoulli-arms">
<h3>Some MAB problem with Bernoulli arms<a class="headerlink" href="#Some-MAB-problem-with-Bernoulli-arms" title="Permalink to this headline">Â¶</a></h3>
<p>We consider in this example <span class="math">\(3\)</span> problems, with <code class="docutils literal"><span class="pre">Bernoulli</span></code> arms,
of different means.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">ENVIRONMENTS</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># 1)  Bernoulli arms</span>
        <span class="p">{</span>   <span class="c1"># A very easy problem, but it is used in a lot of articles</span>
            <span class="s2">&quot;arm_type&quot;</span><span class="p">:</span> <span class="n">Bernoulli</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Some-RL-algorithms">
<h3>Some RL algorithms<a class="headerlink" href="#Some-RL-algorithms" title="Permalink to this headline">Â¶</a></h3>
<p>We compare some policies that use the
<code class="docutils literal"><span class="pre">`DoublingTrickWrapper</span></code> &lt;<a class="reference external" href="https://smpybandits.github.io/docs/Policies.DoublingTrickWrapper.html#module-Policies.DoublingTrickWrapper">https://smpybandits.github.io/docs/Policies.DoublingTrickWrapper.html#module-Policies.DoublingTrickWrapper</a>&gt;`__
policy, with a common growing scheme.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">NEXT_HORIZONS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># next_horizon__arithmetic,</span>
    <span class="n">next_horizon__geometric</span><span class="p">,</span>
    <span class="c1"># next_horizon__exponential,</span>
    <span class="c1"># next_horizon__exponential_slow,</span>
    <span class="n">next_horizon__exponential_generic</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">POLICIES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># --- Doubling trick algorithm</span>
    <span class="p">{</span>
        <span class="s2">&quot;archtype&quot;</span><span class="p">:</span> <span class="n">DoublingTrickWrapper</span><span class="p">,</span>
        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;next_horizon&quot;</span><span class="p">:</span> <span class="n">next_horizon</span><span class="p">,</span>
            <span class="s2">&quot;full_restart&quot;</span><span class="p">:</span> <span class="n">full_restart</span><span class="p">,</span>
            <span class="s2">&quot;policy&quot;</span><span class="p">:</span> <span class="n">policy</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="n">policy</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">UCBH</span><span class="p">,</span>
        <span class="n">MOSSH</span><span class="p">,</span>
        <span class="n">klUCBPlusPlus</span><span class="p">,</span>
        <span class="n">ApproximatedFHGittins</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">full_restart</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="kc">True</span><span class="p">,</span>
        <span class="c1"># False,</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">next_horizon</span> <span class="ow">in</span> <span class="n">NEXT_HORIZONS</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<p>Complete configuration for the problem:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># --- Duration of the experiment</span>
    <span class="s2">&quot;horizon&quot;</span><span class="p">:</span> <span class="n">HORIZON</span><span class="p">,</span>
    <span class="c1"># --- Number of repetition of the experiment (to have an average)</span>
    <span class="s2">&quot;repetitions&quot;</span><span class="p">:</span> <span class="n">REPETITIONS</span><span class="p">,</span>
    <span class="c1"># --- Parameters for the use of joblib.Parallel</span>
    <span class="s2">&quot;n_jobs&quot;</span><span class="p">:</span> <span class="n">N_JOBS</span><span class="p">,</span>    <span class="c1"># = nb of CPU cores</span>
    <span class="s2">&quot;verbosity&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>      <span class="c1"># Max joblib verbosity</span>
    <span class="c1"># --- Arms</span>
    <span class="s2">&quot;environment&quot;</span><span class="p">:</span> <span class="n">ENVIRONMENTS</span><span class="p">,</span>
    <span class="c1"># --- Algorithms</span>
    <span class="s2">&quot;policies&quot;</span><span class="p">:</span> <span class="n">POLICIES</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">configuration</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[10]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>{&#39;environment&#39;: [{&#39;arm_type&#39;: Arms.Bernoulli.Bernoulli,
   &#39;params&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}],
 &#39;horizon&#39;: 20000,
 &#39;n_jobs&#39;: 4,
 &#39;policies&#39;: [{&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__geometric&gt;,
    &#39;policy&#39;: Policies.UCBH.UCBH}},
  {&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__exponential_generic&gt;,
    &#39;policy&#39;: Policies.UCBH.UCBH}},
  {&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__geometric&gt;,
    &#39;policy&#39;: Policies.MOSSH.MOSSH}},
  {&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__exponential_generic&gt;,
    &#39;policy&#39;: Policies.MOSSH.MOSSH}},
  {&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__geometric&gt;,
    &#39;policy&#39;: Policies.klUCBPlusPlus.klUCBPlusPlus}},
  {&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__exponential_generic&gt;,
    &#39;policy&#39;: Policies.klUCBPlusPlus.klUCBPlusPlus}},
  {&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__geometric&gt;,
    &#39;policy&#39;: Policies.ApproximatedFHGittins.ApproximatedFHGittins}},
  {&#39;archtype&#39;: Policies.DoublingTrickWrapper.DoublingTrickWrapper,
   &#39;params&#39;: {&#39;full_restart&#39;: True,
    &#39;next_horizon&#39;: &lt;function Policies.DoublingTrickWrapper.next_horizon__exponential_generic&gt;,
    &#39;policy&#39;: Policies.ApproximatedFHGittins.ApproximatedFHGittins}}],
 &#39;repetitions&#39;: 40,
 &#39;verbosity&#39;: 6}
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="Creating-the-Evaluator-object">
<h2>Creating the <code class="docutils literal"><span class="pre">Evaluator</span></code> object<a class="headerlink" href="#Creating-the-Evaluator-object" title="Permalink to this headline">Â¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">(</span><span class="n">configuration</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Number of policies in this comparison: 8
Time horizon: 20000
Number of repetitions: 40
Sampling rate for plotting, delta_t_plot: 50
Number of jobs for parallelization: 4


Creating a new MAB problem ...
  Reading arms of this MAB problem from a dictionnary &#39;configuration&#39; = {&#39;arm_type&#39;: &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;, &#39;params&#39;: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]} ...
 - with &#39;arm_type&#39; = &lt;class &#39;Arms.Bernoulli.Bernoulli&#39;&gt;
 - with &#39;params&#39; = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
 - with &#39;arms&#39; = [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)]
 - with &#39;means&#39; = [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]
 - with &#39;nbArms&#39; = 9
 - with &#39;maxArm&#39; = 0.9
 - with &#39;minArm&#39; = 0.1

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 ...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
 - with &#39;arms&#39; represented as: $[B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)^*]$
Number of environments to try: 1
</pre></div></div>
</div>
</div>
<div class="section" id="Solving-the-problem">
<h2>Solving the problem<a class="headerlink" href="#Solving-the-problem" title="Permalink to this headline">Â¶</a></h2>
<p>Now we can simulate all the <span class="math">\(3\)</span> environments. That part can take
some time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">envId</span><span class="p">,</span> <span class="n">env</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">evaluation</span><span class="o">.</span><span class="n">envs</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Problems&quot;</span><span class="p">):</span>
    <span class="c1"># Evaluate just that env</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">startOneEnv</span><span class="p">(</span><span class="n">envId</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "cba99c933e80425082058595276c7b79", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


Evaluating environment: MAB(nbArms: 9, arms: [B(0.1), B(0.2), B(0.3), B(0.4), B(0.5), B(0.6), B(0.7), B(0.8), B(0.9)], minArm: 0.1, maxArm: 0.9)
- Adding policy #1 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.UCBH.UCBH&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][0]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.UCBH.UCBH&#39;&gt;}} ...
- Adding policy #2 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.UCBH.UCBH&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][1]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.UCBH.UCBH&#39;&gt;}} ...
- Adding policy #3 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.MOSSH.MOSSH&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][2]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.MOSSH.MOSSH&#39;&gt;}} ...
- Adding policy #4 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.MOSSH.MOSSH&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][3]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.MOSSH.MOSSH&#39;&gt;}} ...
- Adding policy #5 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.klUCBPlusPlus.klUCBPlusPlus&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][4]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.klUCBPlusPlus.klUCBPlusPlus&#39;&gt;}} ...
- Adding policy #6 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.klUCBPlusPlus.klUCBPlusPlus&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][5]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.klUCBPlusPlus.klUCBPlusPlus&#39;&gt;}} ...
- Adding policy #7 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.ApproximatedFHGittins.ApproximatedFHGittins&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][6]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__geometric at 0x7f8c7ea81d90&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.ApproximatedFHGittins.ApproximatedFHGittins&#39;&gt;}} ...
- Adding policy #8 = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.ApproximatedFHGittins.ApproximatedFHGittins&#39;&gt;}} ...
  Creating this policy from a dictionnary &#39;self.cfg[&#39;policies&#39;][7]&#39; = {&#39;archtype&#39;: &lt;class &#39;Policies.DoublingTrickWrapper.DoublingTrickWrapper&#39;&gt;, &#39;params&#39;: {&#39;next_horizon&#39;: &lt;function next_horizon__exponential_generic at 0x7f8c7ea8f048&gt;, &#39;full_restart&#39;: True, &#39;policy&#39;: &lt;class &#39;Policies.ApproximatedFHGittins.ApproximatedFHGittins&#39;&gt;}} ...



- Evaluating policy #1/8: DT($T_0=100$, geom seq, restart)[UCB-H($\alpha=1$)] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e42b94b821a24b43a6c39b09417c50f9", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, geom seq, restart)[UCB-H($T=25600$, $\alpha=1$)] after 20000 steps: [3 5 1 2 4 0 6 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 65.43% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 66.05% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    3.1s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   14.4s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   14.4s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #2/8: DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[UCB-H($\alpha=1$)] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "8d79449f28a54c9bb6daf4250909a856", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[UCB-H($T=3276800$, $\alpha=1$)] after 20000 steps: [1 4 0 2 5 3 7 6 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Mean distance from optimal ordering: 62.96% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.8s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   14.5s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   14.5s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #3/8: DT($T_0=100$, geom seq, restart)[MOSS-H] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "3d07d3a3e0f24fe296cbca81adb6dc75", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, geom seq, restart)[MOSS-H($T=25600$)] after 20000 steps: [0 1 4 3 6 5 2 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 73.46% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.8s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   14.6s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   14.6s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #4/8: DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[MOSS-H] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ba2437ac08de4398a487e99fff0a95b3", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[MOSS-H($T=3276800$)] after 20000 steps: [2 3 0 1 6 4 7 5 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 65.43% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Mean distance from optimal ordering: 60.49% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    3.4s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   15.2s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   15.2s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #5/8: DT($T_0=100$, geom seq, restart)[KLUCB$^{++}$] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e0ffa13b82404bb1a97d147e1695006b", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, geom seq, restart)[KLUCB$^{++}$($T=25600$)] after 20000 steps: [0 4 1 2 5 7 3 6 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 66.67% (relative success)...
  ==&gt; Mean distance from optimal ordering: 68.52% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    6.4s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   33.1s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   33.1s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #6/8: DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[KLUCB$^{++}$] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "444504644d754622806885dbc8dd1d8d", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[KLUCB$^{++}$($T=3276800$)] after 20000 steps: [0 1 6 5 2 3 4 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 70.37% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==&gt; Mean distance from optimal ordering: 74.07% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    6.9s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   37.4s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   37.4s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #7/8: DT($T_0=100$, geom seq, restart)[ApprFHG($\alpha=0.5$)] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "08f05b3ef54e4454a68d319e753cb18f", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, geom seq, restart)[ApprFHG($T=25600$, $\alpha=0.5$)] after 20000 steps: [0 1 5 2 3 4 7 6 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 80.25% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 77.78% (relative success)...
  ==&gt; Mean distance from optimal ordering: 79.01% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    3.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   16.2s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   16.2s finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>



- Evaluating policy #8/8: DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[ApprFHG($\alpha=0.5$)] ...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a118e320c9bb454a83f993e718d9e2d7", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Estimated order by the policy DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[ApprFHG($T=3276800$, $\alpha=0.5$)] after 20000 steps: [1 3 0 6 5 4 2 7 8] ...
  ==&gt; Optimal arm identification: 100.00% (relative success)...
  ==&gt; Manhattan   distance from optimal ordering: 65.43% (relative success)...
  ==&gt; Gestalt     distance from optimal ordering: 55.56% (relative success)...
  ==&gt; Mean distance from optimal ordering: 60.49% (relative success)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="stderr output_area docutils container">
<div class="highlight"><pre>
[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    3.1s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   16.5s remaining:    0.0s
[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:   16.5s finished
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
</div>
<div class="section" id="Plotting-the-results">
<h2>Plotting the results<a class="headerlink" href="#Plotting-the-results" title="Permalink to this headline">Â¶</a></h2>
<p>And finally, visualize them, with the plotting method of a <code class="docutils literal"><span class="pre">Evaluator</span></code>
object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="n">envId</span><span class="p">):</span>
    <span class="n">evaluation</span><span class="o">.</span><span class="n">printFinalRanking</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">plotRegrets</span><span class="p">(</span><span class="n">envId</span><span class="p">)</span>
    <span class="c1"># evaluation.plotRegrets(envId, semilogx=True)</span>
    <span class="c1"># evaluation.plotRegrets(envId, meanRegret=True)</span>
    <span class="c1"># evaluation.plotBestArmPulls(envId)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #0 :
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[ApprFHG($\alpha=0.5$)]&#39; was ranked      1 / 8 for this simulation (last regret = 148.29).
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[KLUCB$^{++}$]&#39;  was ranked      2 / 8 for this simulation (last regret = 209.7).
- Policy &#39;DT($T_0=100$, geom seq, restart)[ApprFHG($\alpha=0.5$)]&#39;      was ranked      3 / 8 for this simulation (last regret = 224.32).
- Policy &#39;DT($T_0=100$, geom seq, restart)[KLUCB$^{++}$]&#39;       was ranked      4 / 8 for this simulation (last regret = 332.43).
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[UCB-H($\alpha=1$)]&#39;     was ranked      5 / 8 for this simulation (last regret = 335.25).
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[MOSS-H]&#39;        was ranked      6 / 8 for this simulation (last regret = 350.03).
- Policy &#39;DT($T_0=100$, geom seq, restart)[MOSS-H]&#39;     was ranked      7 / 8 for this simulation (last regret = 512.74).
- Policy &#39;DT($T_0=100$, geom seq, restart)[UCB-H($\alpha=1$)]&#39;  was ranked      8 / 8 for this simulation (last regret = 515.23).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_25_1.png" src="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_25_1.png" />
</div>
</div>
</div>
<div class="section" id="Visualisation-the-lower-bound-for-algorithms-that-restart-at-breaking-points">
<h2>Visualisation the lower-bound for algorithms that restart at breaking points<a class="headerlink" href="#Visualisation-the-lower-bound-for-algorithms-that-restart-at-breaking-points" title="Permalink to this headline">Â¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">DEFAULT_FIRST_HORIZON</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">def</span> <span class="nf">lower_bound_with_breakpoints</span><span class="p">(</span><span class="n">next_horizon</span><span class="p">,</span> <span class="n">horizon</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span>
                                 <span class="n">first_horizon</span><span class="o">=</span><span class="n">DEFAULT_FIRST_HORIZON</span><span class="p">,</span>
                                 <span class="n">fig</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">points</span><span class="p">,</span> <span class="n">gap</span> <span class="o">=</span> <span class="n">breakpoints</span><span class="p">(</span><span class="n">next_horizon</span><span class="p">,</span> <span class="n">first_horizon</span><span class="p">,</span> <span class="n">horizon</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">horizon</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># Durty estimate</span>
    <span class="k">for</span> <span class="n">estimate_horizon</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">estimate_horizon</span> <span class="o">&lt;=</span> <span class="n">horizon</span><span class="p">:</span>
            <span class="n">before_breakpoint</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X</span> <span class="o">==</span> <span class="n">estimate_horizon</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">lower_bound_before_breakpoint</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">before_breakpoint</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;At time </span><span class="si">{}</span><span class="s2">, lowerbound was </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">estimate_horizon</span><span class="p">,</span> <span class="n">lower_bound_before_breakpoint</span><span class="p">))</span>
            <span class="n">after</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">X</span> <span class="o">&gt;=</span> <span class="n">estimate_horizon</span><span class="p">)</span>
            <span class="n">Y</span><span class="p">[</span><span class="n">after</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">after</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">before_breakpoint</span><span class="p">])</span> <span class="o">+</span> <span class="n">lower_bound_before_breakpoint</span>
    <span class="k">if</span> <span class="n">fig</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># new figure if needed</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time steps t=1..T, $T = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">horizon</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Regret lower-bound&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Lai &amp; Robbins lower-bound for problem with $K=</span><span class="si">{}</span><span class="s2">$ arms and $C_K=</span><span class="si">{:.3g}</span><span class="s2">$</span><span class="se">\n</span><span class="s2">And doubling trick with restart points (</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">nbArms</span><span class="p">,</span> <span class="n">env</span><span class="o">.</span><span class="n">lowerbound</span><span class="p">(),</span> <span class="n">next_horizon</span><span class="o">.</span><span class="n">__latex_name__</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># https://stackoverflow.com/a/26845924/</span>
        <span class="n">ax_legend</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax_legend</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>
    <span class="n">complexity</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">lowerbound</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">complexity</span> <span class="o">*</span> <span class="n">Y</span><span class="p">,</span>
            <span class="s1">&#39;k--&#39;</span> <span class="k">if</span> <span class="n">marker</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">k--&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">marker</span><span class="p">),</span>
            <span class="n">markevery</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LB, DT restart (</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">next_horizon</span><span class="o">.</span><span class="n">__latex_name__</span><span class="p">))</span>
    <span class="n">legend</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">_</span> <span class="o">=</span> <span class="n">lower_bound_with_breakpoints</span><span class="p">(</span><span class="n">next_horizon__exponential_generic</span><span class="p">,</span> <span class="n">HORIZON</span><span class="p">,</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">envs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
At time 100, lowerbound was 4.59511985013459
At time 100, lowerbound was 4.59511985013459
At time 200, lowerbound was 9.20029003612268
At time 800, lowerbound was 15.597219691338827
At time 12800, lowerbound was 24.989881620108964
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_28_1.png" src="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_28_1.png" />
</div>
</div>
</div>
<div class="section" id="Seeing-the-lower-bound-on-the-regret-plot">
<h2>Seeing the lower-bound on the regret plot<a class="headerlink" href="#Seeing-the-lower-bound-on-the-regret-plot" title="Permalink to this headline">Â¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plotAll</span><span class="p">(</span><span class="n">evaluation</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Final ranking for this environment #0 :
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[ApprFHG($\alpha=0.5$)]&#39; was ranked      1 / 8 for this simulation (last regret = 148.29).
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[KLUCB$^{++}$]&#39;  was ranked      2 / 8 for this simulation (last regret = 209.7).
- Policy &#39;DT($T_0=100$, geom seq, restart)[ApprFHG($\alpha=0.5$)]&#39;      was ranked      3 / 8 for this simulation (last regret = 224.32).
- Policy &#39;DT($T_0=100$, geom seq, restart)[KLUCB$^{++}$]&#39;       was ranked      4 / 8 for this simulation (last regret = 332.43).
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[UCB-H($\alpha=1$)]&#39;     was ranked      5 / 8 for this simulation (last regret = 335.25).
- Policy &#39;DT($T_0=100$, exp $\alpha=2$, $\beta=2$ seq, restart)[MOSS-H]&#39;        was ranked      6 / 8 for this simulation (last regret = 350.03).
- Policy &#39;DT($T_0=100$, geom seq, restart)[MOSS-H]&#39;     was ranked      7 / 8 for this simulation (last regret = 512.74).
- Policy &#39;DT($T_0=100$, geom seq, restart)[UCB-H($\alpha=1$)]&#39;  was ranked      8 / 8 for this simulation (last regret = 515.23).

This MAB problem has:
 - a [Lai &amp; Robbins] complexity constant C(mu) = 7.52 for 1-player problem...
 - a Optimal Arm Identification factor H_OI(mu) = 48.89% ...
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_30_1.png" src="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_30_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">markers</span> <span class="o">=</span> <span class="n">makemarkers</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">NEXT_HORIZONS</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">next_horizon</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">NEXT_HORIZONS</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">lower_bound_with_breakpoints</span><span class="p">(</span><span class="n">next_horizon</span><span class="p">,</span> <span class="n">HORIZON</span><span class="p">,</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">envs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">markers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
At time 100, lowerbound was 4.59511985013459
At time 200, lowerbound was 9.20029003612268
At time 400, lowerbound was 14.498607402670718
At time 800, lowerbound was 20.4900719497787
At time 1600, lowerbound was 27.174683677446627
At time 3200, lowerbound was 34.5524425856745
At time 6400, lowerbound was 42.62334867446232
At time 12800, lowerbound was 51.38740194381008
At time 100, lowerbound was 4.59511985013459
At time 100, lowerbound was 4.59511985013459
At time 200, lowerbound was 9.20029003612268
At time 800, lowerbound was 15.597219691338827
At time 12800, lowerbound was 24.989881620108964
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_33_0.png" src="../_images/notebooks_Lai_Robbins_Lower_Bound_for_Doubling_Trick_with_Restarting_Algorithms_33_0.png" />
</div>
</div>
</div>
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">Â¶</a></h2>
<p>Thatâ€™s it for today, folks!</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Profiling.html" class="btn btn-neutral float-right" title="A note on execution times, speed and profiling" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="BlackBox_Bayesian_Optimization_for_Bandit_problems.html" class="btn btn-neutral" title="Table of Contents" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2018, Lilian Besson (Naereen).
      Last updated on 21 Mar 2018, 11h.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.9.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>